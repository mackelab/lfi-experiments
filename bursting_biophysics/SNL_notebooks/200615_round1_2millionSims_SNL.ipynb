{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyknos/nflows/nn/nde\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sbi.inference import prepare_for_sbi, SNLE\n",
    "from sbi.simulators.linear_gaussian import diagonal_linear_gaussian\n",
    "import sbi.utils as sbi_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load theta and x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.load('../results/cleaned_up_data2.npz', allow_pickle=True)\n",
    "\n",
    "x = torch.as_tensor(data['data'], dtype=torch.float32)\n",
    "theta = torch.as_tensor(data['params'], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1992007, 35])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from parameter_setup import load_ground_truth_params, load_prior_min, load_prior_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data to standardize - needed to standardize x_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#standardize_vals = np.load('../results/standardize_vals.npz')\n",
    "#x_mean = standardize_vals['data_mean']\n",
    "#x_std = standardize_vals['data_std']\n",
    "#\n",
    "#theta_mean = standardize_vals['theta_mean']\n",
    "#theta_std = standardize_vals['theta_std']\n",
    "\n",
    "x_mean = x.mean(dim=0)\n",
    "x_std = x.std(dim=0)\n",
    "\n",
    "theta_mean = theta.mean(dim=0)\n",
    "theta_std = theta.std(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = (x-x_mean) / x_std\n",
    "theta = (theta-theta_mean) / theta_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load x_o (which I got from running the simulator with Arco's ground truth params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_o = torch.as_tensor(np.load('../results/observation/x_o_new_ss.npz')['x_o'], dtype=torch.float32)\n",
    "\n",
    "x_o = (x_o - x_mean) / x_std\n",
    "x_o = x_o.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dummy simulator and dummy prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dummy_simulator(theta):\n",
    "    return torch.ones(1,35)\n",
    "\n",
    "dummy_prior = sbi_utils.BoxUniform(torch.as_tensor(load_prior_min()), torch.as_tensor(load_prior_max()))\n",
    "_bound = torch.sqrt(torch.as_tensor(3.))\n",
    "dummy_prior_norm = sbi_utils.BoxUniform(-_bound*torch.ones(35), _bound*torch.ones(35))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sbi.utils.get_nn_models import likelihood_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simulator, prior, x_shape = prepare_for_sbi(dummy_simulator, dummy_prior_norm)\n",
    "\n",
    "nsf = likelihood_nn(\n",
    "    model='nsf',\n",
    "    theta_shape=prior.sample().shape,\n",
    "    x_o_shape=x_shape,\n",
    "    hidden_features=200,\n",
    "    flow_num_transforms=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inference = SNLE(\n",
    "    simulator, \n",
    "    prior,\n",
    "    x_shape,\n",
    "    external_data=(theta, x), # todo: remove the [:1000] to train on all datasamples\n",
    "    mcmc_method='slice', \n",
    "    density_estimator=nsf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Zero-length parameter theta implies zero simulations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network successfully converged after 61 epochs.\n"
     ]
    }
   ],
   "source": [
    "posterior = inference(\n",
    "    num_rounds=1,\n",
    "    num_simulations_per_round=0,\n",
    "    batch_size=100, # default is 50\n",
    "    stop_after_epochs=10, # default is 20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "#with open('../results/posteriors/200619_PosteriorSNL.pickle', 'wb') as handle:\n",
    "#    pickle.dump(posterior, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run VI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sbi.utils.get_nn_models import get_vi_net\n",
    "from sbi.utils.vi import train_vi, train_mle\n",
    "import torch\n",
    "import sbi.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../bFlows')\n",
    "from bflows.utils.neural_net.get_bounded_flows import get_bflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vi_net = get_vi_net(parameter_dim=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "posterior = posterior.set_default_x(x_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:    tensor(288.1560, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(282.3391, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(277.1024, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(277.8388, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(276.3999, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(271.5084, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(266.5534, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(258.0864, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(246.4940, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(242.9842, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(233.4880, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(225.9792, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(214.7915, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(203.1809, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(194.5982, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(189.3927, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(174.6635, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(167.0130, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(161.6831, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(156.1572, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(153.7185, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(151.0146, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(146.3461, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(142.4650, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(142.8996, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(142.4815, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(141.0500, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(139.2431, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(136.8878, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(135.3803, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(132.6614, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(132.0639, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(128.9485, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(126.8281, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(127.6051, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(126.3207, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(125.8974, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(124.2128, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(122.6590, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(120.2671, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(119.0456, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(120.1747, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(117.5484, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(117.9736, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(116.7602, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(115.2989, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(114.2965, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(113.0748, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(113.5313, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(113.3212, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(113.3918, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(112.8754, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(113.0799, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(112.5729, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(111.8533, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(110.2161, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(108.6320, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(109.4107, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(109.0290, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(110.1524, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(110.7146, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(108.9686, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(109.7374, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(107.7861, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(107.7347, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(108.4118, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(107.5982, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(107.7179, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(107.4621, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(107.0266, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(107.4988, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(107.9872, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(108.4257, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(108.8489, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(108.0546, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(106.1535, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(107.4104, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(106.1303, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(106.3488, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(106.9224, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(107.1259, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(106.0253, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(106.7364, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(106.0289, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(107.3690, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(106.8352, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(107.5494, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(107.6795, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(109.0942, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(108.3979, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(107.0464, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(105.7741, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(106.3313, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(106.1263, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(106.5868, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(106.3062, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(106.9482, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(107.0048, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(106.2949, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(105.8161, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(105.6463, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(106.1978, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(104.9534, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(106.5340, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(106.8746, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(107.4073, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(106.0596, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(106.7901, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(105.6904, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(106.0255, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(105.9102, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(105.3203, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(106.8134, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(106.3886, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(106.3434, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(106.2018, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(104.9801, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(104.7338, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(104.6448, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(105.8631, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(104.1439, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(104.1017, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(104.9269, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(104.1277, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(103.5620, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(104.9996, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(105.8017, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(106.3883, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(105.9029, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(104.3877, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(105.1003, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(104.3853, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(104.2533, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(104.9837, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(104.3994, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(104.4268, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(104.2941, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(103.7648, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(103.7723, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(103.8672, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(104.5775, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.9231, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(103.5177, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(103.9577, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(104.1084, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(103.7628, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(104.9378, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(103.5311, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(103.7318, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(104.3036, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(103.8719, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(103.4643, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(103.4821, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(104.0198, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(103.7908, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(103.3270, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(103.6608, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(104.4200, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(103.6972, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(103.4184, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(103.6962, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(103.7269, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(103.6778, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(103.7347, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(103.5487, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(103.2449, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.5814, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.2510, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(103.7589, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(103.3298, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.9071, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.6775, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.6614, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.9921, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(103.1040, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(103.6527, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.8956, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.8873, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(103.2275, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.3115, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.4944, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.8412, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(103.5357, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.6716, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(103.1609, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.7182, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(103.2787, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.4571, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(103.4154, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(103.2068, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.8174, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.5391, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.8305, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(103.1460, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(103.4756, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.6584, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.2625, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(103.0788, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.9221, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(103.0846, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.7954, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.4171, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.1906, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.5760, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.3663, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.6425, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.7011, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.2978, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.2670, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.4886, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.1404, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.5598, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.4587, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.0951, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.5359, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.5131, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.2196, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.3220, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.8089, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.0331, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(100.7976, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.6131, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.0398, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.0169, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.1792, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.6160, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.7828, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.1177, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.4196, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.8043, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.1617, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.7139, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.0724, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.6013, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.8524, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.2152, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.9427, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.7241, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.9547, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.2432, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.0776, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.0365, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.3341, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.6887, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(100.5357, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(100.1504, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(100.9972, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.2641, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.4692, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.7215, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.0892, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.6830, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.0688, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(100.9295, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.8208, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.5476, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.4730, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.4941, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.4049, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(100.8123, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.6930, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.3442, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.0205, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.6443, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.2094, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.5719, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(100.8106, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(100.8987, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(100.4278, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(100.6995, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(100.6752, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(100.6973, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.2831, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(100.7335, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(100.1561, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.1607, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(100.9979, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.5878, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.1823, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(100.5439, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.3117, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.1921, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(100.6404, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(100.7887, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(100.4831, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(100.5649, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(100.2930, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(99.7939, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(100.2730, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(99.8926, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(100.3083, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(100.7836, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(100.3916, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(100.7442, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.9633, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.4271, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.3226, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.3978, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(100.5737, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.2554, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.5209, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.9438, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.9062, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(103.0698, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.2914, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.3404, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.0167, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(100.9470, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.2447, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.2783, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.3500, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.0779, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(100.8180, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(100.9176, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(99.9040, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(100.7941, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(100.9718, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.7483, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.2992, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.1416, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(102.5806, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(100.8989, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(100.8538, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(100.5205, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(100.2254, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.2289, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.4198, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(101.3068, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(100.4520, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(99.9148, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(100.5607, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(100.0791, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(100.9271, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(100.3664, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(100.3879, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(100.0775, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(100.0604, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(100.1188, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "vi_net_ = get_bflow('nsf_uncond_bounded', prior=prior, context=x_o, num_coupling=10, hidden_features=200)\n",
    "trained_vi_net = train_vi(vi_net_, posterior, batch_size=500, stop_after_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../results/posteriors/200622_PosteriorSNL_VI_bigger_net.pickle', 'wb') as handle:\n",
    "    pickle.dump(trained_vi_net, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../results/posteriors/200619_PosteriorSNL.pickle', 'rb') as handle:\n",
    "    posterior = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../results/posteriors/200622_PosteriorSNL_VI_bigger_net.pickle', 'rb') as handle:\n",
    "    trained_vi_net = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new iter, 0\n",
      "new iter, 1\n",
      "new iter, 2\n",
      "new iter, 3\n",
      "new iter, 4\n",
      "new iter, 5\n",
      "new iter, 6\n",
      "new iter, 7\n",
      "new iter, 8\n",
      "new iter, 9\n"
     ]
    }
   ],
   "source": [
    "s = []\n",
    "num_iter = 10\n",
    "num_samples_per_iter = 100\n",
    "\n",
    "for k in range(num_iter):\n",
    "    print(\"new iter,\", k)\n",
    "    samples = trained_vi_net.sample(num_samples_per_iter).detach()\n",
    "\n",
    "    # denormalize the samples\n",
    "    samples = samples * theta_std + theta_mean\n",
    "\n",
    "    # convert to list for pickling\n",
    "    samples_list = samples.numpy().tolist()\n",
    "    \n",
    "    s.append(samples_list)\n",
    "s = np.asarray(s)\n",
    "s = s.reshape(num_iter*num_samples_per_iter, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s_list = s.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[153.89227294921875, 0.0027115624397993088, 372.8607177734375, 0.010375545360147953, 69.41265869140625, 0.048087283968925476, 0.0026321839541196823, 0.0006303301779553294, 0.0004713560629170388, 0.0791434645652771, 0.005769587121903896, 0.0015482520684599876, 0.0005826402339152992, 0.6991331577301025, 0.8772251009941101, 0.07872308790683746, 0.09880457818508148, 0.016081983223557472, 3.8968148231506348, 1.993944525718689, 0.004224236123263836, 0.0005351114086806774, 0.0011797824408859015, 0.032208073884248734, 0.0747133120894432, 0.01910850591957569, 0.3716028034687042, -1.5042496919631958, 0.5754405856132507, 1.4862384796142578, 3.199645652784966e-05, 3.615632886067033e-05, 4.4804663048125803e-05, 2.8752843718393706e-05, 1.2623975276947021]\n"
     ]
    }
   ],
   "source": [
    "print(s_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#with open('../results/samples/200622_PosteriorSNL_VI_samples.pickle', 'wb') as handle:\n",
    "#    pickle.dump(s_list, handle, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gt_params = [137.862136034238,\n",
    " 0.0005793520824526776,\n",
    " 199.1298048149789,\n",
    " 0.0006108049075983062,\n",
    " 152.1647419393015,\n",
    " 0.00742430653684668,\n",
    " 0.0010965218089651857,\n",
    " 0.0008186770602065786,\n",
    " 0.00011435310571497434,\n",
    " 0.0022763084379226854,\n",
    " 0.0036986082079423594,\n",
    " 0.00013883334761566004,\n",
    " 3.2474860530531394e-06,\n",
    " 0.005426837416265438,\n",
    " 0.10568666421909532,\n",
    " 0.04812676692103998,\n",
    " 0.094826660872338,\n",
    " 0.013854989311151315,\n",
    " 3.9010342040060975,\n",
    " 3.8851157748263354,\n",
    " 0.009964343408409574,\n",
    " 0.006000497448875096,\n",
    " 0.0012602755616811401,\n",
    " 0.01392240648099882,\n",
    " 0.06283710421562513,\n",
    " 6.68382138396179e-05,\n",
    " 0.08311048073340864,\n",
    " -2.9836949894223825,\n",
    " 1.9642986130169147,\n",
    " 1.2999358521956366,\n",
    " 4.4931548434199036e-05,\n",
    " 2.062212836678345e-05,\n",
    " 4.22059843297412e-05,\n",
    " 2.2409802171891654e-05,\n",
    " 1.7109080877160283]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gt_params_norm = (torch.as_tensor(gt_params) - theta_mean) / theta_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples = trained_vi_net.sample(10000).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probs = np.exp(posterior.log_prob(samples, x=x_o).detach().numpy())\n",
    "prob_of_gt = np.exp(posterior.log_prob(gt_params_norm.unsqueeze(0), x=x_o).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x7fda7b373610>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(5,5))\n",
    "_ = plt.hist(probs, bins=100)\n",
    "ax.axvline(prob_of_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-43.4859])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_prior_norm.log_prob(gt_params_norm.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior predictives\n",
    "Has to be done in a different virtual env with python 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "sbi",
   "language": "python",
   "name": "sbi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
