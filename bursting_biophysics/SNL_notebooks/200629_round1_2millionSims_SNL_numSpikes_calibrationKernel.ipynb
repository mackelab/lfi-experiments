{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyknos/nflows/nn/nde\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sbi.inference import prepare_for_sbi, SNLE, SNPE\n",
    "from sbi.simulators.linear_gaussian import diagonal_linear_gaussian\n",
    "import sbi.utils as sbi_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load theta and x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('../results/cleaned_up_data_onlyNumSpikes_calibrationKernel.npz', allow_pickle=True)\n",
    "\n",
    "x = torch.as_tensor(data['data'], dtype=torch.float32)\n",
    "theta = torch.as_tensor(data['params'], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x[:, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([728700, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parameter_setup import load_ground_truth_params, load_prior_min, load_prior_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data to standardize - needed to standardize x_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize_vals = np.load('../results/standardize_vals.npz')\n",
    "#x_mean = standardize_vals['data_mean']\n",
    "#x_std = standardize_vals['data_std']\n",
    "#\n",
    "#theta_mean = standardize_vals['theta_mean']\n",
    "#theta_std = standardize_vals['theta_std']\n",
    "\n",
    "x_mean = x.mean(dim=0)\n",
    "x_std = x.std(dim=0)\n",
    "\n",
    "theta_mean = theta.mean(dim=0)\n",
    "theta_std = theta.std(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (x-x_mean) / x_std\n",
    "theta = (theta-theta_mean) / theta_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load x_o (which I got from running the simulator with Arco's ground truth params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 3.0000e+00, -7.3972e+01,  3.1537e-03, -7.0379e+01,  2.5909e+02,\n",
      "         2.7430e+00,  1.3598e+01,  1.0000e+00, -7.0373e+01,  2.5281e-03,\n",
      "        -5.4636e+01,  9.4801e+02,  7.5035e-01,  1.9276e+00,  1.0000e+00,\n",
      "        -7.3972e+01,  3.1537e-03, -7.3567e+01,  2.9432e+01,  1.0631e+01,\n",
      "         1.5560e+02,  0.0000e+00, -7.0373e+01,  2.5281e-03, -6.9793e+01,\n",
      "         2.8696e+01,  4.8228e+00,  2.8244e+01,  1.0000e+00, -6.8981e+01,\n",
      "         2.4896e-03, -6.8497e+01,  2.7113e+01,  4.6703e+00,  2.6055e+01])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x_o = torch.as_tensor(np.load('../results/observation/x_o_new_ss.npz')['x_o'], dtype=torch.float32)\n",
    "print(x_o)\n",
    "x_o = x_o[:1]\n",
    "x_o = (x_o - x_mean) / x_std\n",
    "x_o = x_o.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.0126]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dummy simulator and dummy prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_simulator(theta):\n",
    "    return torch.ones(1,1)\n",
    "\n",
    "dummy_prior = sbi_utils.BoxUniform(torch.as_tensor(load_prior_min()), torch.as_tensor(load_prior_max()))\n",
    "_bound = torch.sqrt(torch.as_tensor(3.))\n",
    "dummy_prior_norm = sbi_utils.BoxUniform(-_bound*torch.ones(35), _bound*torch.ones(35))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbi.utils.get_nn_models import likelihood_nn, posterior_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/anaconda3/envs/sbi/lib/python3.8/site-packages/nflows/transforms/standard.py:62: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"_shift\", torch.tensor(shift if (shift is not None) else 0.0)\n",
      "/home/michael/anaconda3/envs/sbi/lib/python3.8/site-packages/nflows/transforms/standard.py:65: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"_scale\", torch.tensor(scale if (scale is not None) else 1.0)\n"
     ]
    }
   ],
   "source": [
    "simulator, prior, x_shape = prepare_for_sbi(dummy_simulator, dummy_prior_norm)\n",
    "\n",
    "#nsf = likelihood_nn(\n",
    "#    model='nsf',\n",
    "#    theta_shape=prior.sample().shape,\n",
    "#    x_o_shape=x_shape,\n",
    "#    hidden_features=100,\n",
    "#    flow_num_transforms=10,\n",
    "#)\n",
    "\n",
    "nsf_posterior = posterior_nn(\n",
    "    model='nsf',\n",
    "    prior=prior,\n",
    "    x_o_shape=x_shape,\n",
    "    hidden_features=100,\n",
    "    flow_num_transforms=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4203],\n",
       "        [-0.4203],\n",
       "        [-0.4203],\n",
       "        ...,\n",
       "        [-0.4203],\n",
       "        [-0.4203],\n",
       "        [ 2.2962]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference = SNPE(\n",
    "    simulator, \n",
    "    prior,\n",
    "    x_shape,\n",
    "    external_data=(theta, x), # todo: remove the [:1000] to train on all datasamples\n",
    "    mcmc_method='slice', \n",
    "    density_estimator=nsf_posterior\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Zero-length parameter theta implies zero simulations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network successfully converged after 17 epochs.\n"
     ]
    }
   ],
   "source": [
    "posterior = inference(\n",
    "    num_rounds=1,\n",
    "    num_simulations_per_round=0,\n",
    "    batch_size=100, # default is 50\n",
    "    stop_after_epochs=5, # default is 20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../results/posteriors/200630_PosteriorSNPE_onlyBurst.pickle', 'wb') as handle:\n",
    "    pickle.dump(posterior, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run VI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbi.utils.get_nn_models import get_vi_net\n",
    "from sbi.utils.vi import train_vi, train_mle\n",
    "import torch\n",
    "import sbi.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../bFlows')\n",
    "from bflows.utils.neural_net.get_bounded_flows import get_bflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vi_net = get_vi_net(parameter_dim=35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temper the posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_o = torch.as_tensor(np.load('../results/observation/x_o_new_ss.npz')['x_o'], dtype=torch.float32)\n",
    "x_o = x_o[:1]\n",
    "x_o[0] = 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_o = (x_o - x_mean) / x_std\n",
    "#x_o = x_o.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.2962])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the VI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Observed data shape (torch.Size([1, 1])) must match the shape of simulated data x (torch.Size([1])).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-c60de9bfe261>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mposterior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mposterior\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_default_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_o\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/sbi/sbi/inference/posterior.py\u001b[0m in \u001b[0;36mset_default_x\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;31m`\u001b[0m\u001b[0mNeuralPosterior\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mwill\u001b[0m \u001b[0muse\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexplicitly\u001b[0m \u001b[0mpassed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0mprocessed_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_x_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_if_posterior_was_focused_on_different_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessed_x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/sbi/sbi/user_input/user_input_checks.py\u001b[0m in \u001b[0;36mprocess_x\u001b[0;34m(x, x_shape)\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[0minput_x_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m     assert input_x_shape == x_shape, (\n\u001b[0m\u001b[1;32m    488\u001b[0m         \u001b[0;34mf\"Observed data shape ({input_x_shape}) must match \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0;34mf\"the shape of simulated data x ({x_shape}).\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Observed data shape (torch.Size([1, 1])) must match the shape of simulated data x (torch.Size([1]))."
     ]
    }
   ],
   "source": [
    "posterior = posterior.set_default_x(x_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/Documents/sbi/sbi/inference/posterior.py:247: UserWarning: The log probability from SNL is only correct up to a normalizing constant.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:    tensor(-14.2404, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-14.4094, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-16.4963, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-16.4763, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-16.6338, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-17.8953, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-18.9877, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-20.0535, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-21.3349, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-22.1420, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-23.1822, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-23.6044, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-23.6771, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-22.7450, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-23.1938, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-22.0302, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-23.3385, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-23.1001, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-24.5272, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-24.6427, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.3471, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.6167, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-26.3961, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-26.3099, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-26.9860, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-27.3794, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-27.2084, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-27.8302, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-27.5999, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-28.2749, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-28.0282, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-28.1545, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-28.5683, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-28.6275, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-29.1017, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-29.1084, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-20000030., grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-29.6177, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-29.8766, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-29.9596, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-30.0853, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-30.1394, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-30.0496, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-30.6782, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-30.7090, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-30.6095, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-30.3200, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-30.6416, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-30.4047, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-30.6026, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-30.7022, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-30.6770, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-30.7970, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-30.7788, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-30.7358, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-30.9807, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-30.6004, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-30.8274, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-30.7541, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-31.2342, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-31.2349, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-31.0913, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-30.9958, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-30.8478, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-31.0054, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-30.9714, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-30.9239, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-31.1800, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-31.1701, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-31.5354, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-31.4550, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-31.1810, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-31.5402, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-31.3204, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-31.2366, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-31.1587, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-31.5271, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-31.0903, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-31.6326, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-31.4759, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-31.1585, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-31.4585, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-31.0617, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-31.1456, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-31.2995, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-31.3735, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-31.6748, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "vi_net_ = get_bflow('nsf_uncond_bounded', prior=prior, context=x_o, num_coupling=10, hidden_features=200)\n",
    "trained_vi_net = train_vi(vi_net_, posterior, batch_size=500, stop_after_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../results/posteriors/200622_PosteriorSNL_VI_NumSpikes_calibrated.pickle', 'wb') as handle:\n",
    "    pickle.dump(trained_vi_net, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../results/posteriors/200623_PosteriorSNL_NumSpikes_calibration.pickle', 'rb') as handle:\n",
    "    posterior = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../results/posteriors/200622_PosteriorSNL_VI_NumSpikes_calibrated.pickle', 'rb') as handle:\n",
    "    trained_vi_net = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new iter, 0\n",
      "new iter, 1\n",
      "new iter, 2\n",
      "new iter, 3\n",
      "new iter, 4\n",
      "new iter, 5\n",
      "new iter, 6\n",
      "new iter, 7\n",
      "new iter, 8\n",
      "new iter, 9\n"
     ]
    }
   ],
   "source": [
    "s = []\n",
    "num_iter = 10\n",
    "num_samples_per_iter = 1000\n",
    "\n",
    "for k in range(num_iter):\n",
    "    print(\"new iter,\", k)\n",
    "    samples = trained_vi_net.sample(num_samples_per_iter).detach()\n",
    "\n",
    "    # denormalize the samples\n",
    "    samples = samples * theta_std + theta_mean\n",
    "\n",
    "    # convert to list for pickling\n",
    "    samples_list = samples.numpy().tolist()\n",
    "    \n",
    "    s.append(samples_list)\n",
    "s = np.asarray(s)\n",
    "s = s.reshape(num_iter*num_samples_per_iter, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_list = s.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[138.39794921875, 0.02207452617585659, 191.3704833984375, 0.00734819658100605, 167.87359619140625, 0.02498830109834671, 0.0015383628197014332, 0.0009792555356398225, 5.1614217227324843e-05, 0.15563201904296875, 0.005237556528300047, 0.006436765193939209, 0.0005208734073676169, 0.6840335130691528, 0.22224026918411255, 0.08310504257678986, 0.09946738183498383, 0.018469423055648804, 2.5847198963165283, 1.9917058944702148, 0.006798768416047096, 0.0031093622092157602, 0.004890249110758305, 0.009707055985927582, 0.07212281227111816, 0.03332272171974182, 0.12162593007087708, -1.772070050239563, 1.5487139225006104, 0.3148680329322815, 9.596590825822204e-05, 3.699894296005368e-05, 7.657681271666661e-05, 4.940806684317067e-05, 0.8023563623428345]\n"
     ]
    }
   ],
   "source": [
    "print(s_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../results/samples/200629_PosteriorSNL_NumSpikesCalibrated_VI_samples.pickle', 'wb') as handle:\n",
    "    pickle.dump(s_list, handle, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_params = [137.862136034238,\n",
    " 0.0005793520824526776,\n",
    " 199.1298048149789,\n",
    " 0.0006108049075983062,\n",
    " 152.1647419393015,\n",
    " 0.00742430653684668,\n",
    " 0.0010965218089651857,\n",
    " 0.0008186770602065786,\n",
    " 0.00011435310571497434,\n",
    " 0.0022763084379226854,\n",
    " 0.0036986082079423594,\n",
    " 0.00013883334761566004,\n",
    " 3.2474860530531394e-06,\n",
    " 0.005426837416265438,\n",
    " 0.10568666421909532,\n",
    " 0.04812676692103998,\n",
    " 0.094826660872338,\n",
    " 0.013854989311151315,\n",
    " 3.9010342040060975,\n",
    " 3.8851157748263354,\n",
    " 0.009964343408409574,\n",
    " 0.006000497448875096,\n",
    " 0.0012602755616811401,\n",
    " 0.01392240648099882,\n",
    " 0.06283710421562513,\n",
    " 6.68382138396179e-05,\n",
    " 0.08311048073340864,\n",
    " -2.9836949894223825,\n",
    " 1.9642986130169147,\n",
    " 1.2999358521956366,\n",
    " 4.4931548434199036e-05,\n",
    " 2.062212836678345e-05,\n",
    " 4.22059843297412e-05,\n",
    " 2.2409802171891654e-05,\n",
    " 1.7109080877160283]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_params_norm = (torch.as_tensor(gt_params) - theta_mean) / theta_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = trained_vi_net.sample(10000).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = posterior.log_prob(samples, x=x_o).detach().numpy()\n",
    "prob_of_gt = posterior.log_prob(gt_params_norm.unsqueeze(0), x=x_o).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x7f6c0b3b3f10>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(5,5))\n",
    "_ = plt.hist(probs, bins=100)\n",
    "ax.axvline(prob_of_gt, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-inf], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_of_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-43.4859])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_prior_norm.log_prob(gt_params_norm.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior predictives\n",
    "Has to be done in a different virtual env with python 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "sbi",
   "language": "python",
   "name": "sbi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
