{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sbi.inference import prepare_for_sbi, SNPE\n",
    "from sbi.simulators.linear_gaussian import diagonal_linear_gaussian\n",
    "import sbi.utils as sbi_utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load theta and x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('../../../arco_sims/cleaned_up_data.npz', allow_pickle=True)\n",
    "\n",
    "x = torch.as_tensor(data['data'], dtype=torch.float32)\n",
    "theta = torch.as_tensor(data['params'], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load prior min and max and gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parameter_setup import load_ground_truth_params, load_prior_min, load_prior_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load values to standardize x_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize_vals = np.load('../results/standardize_vals.npz')\n",
    "#x_mean = standardize_vals['data_mean']\n",
    "#x_std = standardize_vals['data_std']\n",
    "#\n",
    "#theta_mean = standardize_vals['theta_mean']\n",
    "#theta_std = standardize_vals['theta_std']\n",
    "\n",
    "x_mean = x.mean(dim=0)\n",
    "x_std = x.std(dim=0)\n",
    "\n",
    "theta_mean = theta.mean(dim=0)\n",
    "theta_std = theta.std(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (x-x_mean) / x_std\n",
    "theta = (theta-theta_mean) / theta_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load x_o (which I got from running the simulator with Arco's ground truth params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_o = torch.as_tensor(np.load('../results/observation/x_o.npz')['x_o'], dtype=torch.float32)\n",
    "\n",
    "x_o = (x_o - x_mean) / x_std\n",
    "x_o = x_o.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dummy simulator and dummy prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_simulator(theta):\n",
    "    return torch.ones(1,35)\n",
    "\n",
    "dummy_prior = sbi_utils.BoxUniform(torch.as_tensor(load_prior_min()), torch.as_tensor(load_prior_max()))\n",
    "_bound = torch.sqrt(torch.as_tensor(3.))\n",
    "dummy_prior_norm = sbi_utils.BoxUniform(-_bound*torch.ones(35), _bound*torch.ones(35))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator, prior, x_shape = prepare_for_sbi(dummy_simulator, dummy_prior_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bflows.utils.neural_net.get_bounded_flows import get_bflow\n",
    "\n",
    "boxFlow = get_bflow(\"nsf_bounded\", prior=dummy_prior_norm, context=x_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_datapoints = 10000\n",
    "inference = SNPE(\n",
    "    simulator,\n",
    "    prior, \n",
    "    x_shape,\n",
    "    density_estimator=boxFlow,\n",
    "    external_data=(theta[:num_datapoints], x[:num_datapoints]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Zero-length parameter theta implies zero simulations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training neural network. Epochs trained:  6\r"
     ]
    }
   ],
   "source": [
    "posterior = inference(\n",
    "    num_rounds=1,\n",
    "    num_simulations_per_round=0,\n",
    "    max_num_epochs=5,\n",
    "    z_score_x=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior = posterior.set_default_x(x=x_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9edcba053bcd488eab7c8395ae1b6df5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Drawing 10000 posterior samples', max=10000.0, style=Progâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "samples = posterior.sample((10000,), show_progress_bars=True)\n",
    "\n",
    "# denormalize the samples\n",
    "samples = samples * theta_std + theta_mean\n",
    "\n",
    "# convert to list for pickling\n",
    "samples_list = samples.numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../results/posteriors/200616_dummyPosteriorSNL.pickle', 'wb') as handle:\n",
    "    pickle.dump(posterior, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../results/samples/200616_dummyPosteriorSNL_samples.pickle', 'wb') as handle:\n",
    "    pickle.dump(samples_list, handle, protocol=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior predictives\n",
    "Has to be done in a different virtual env with python 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbi",
   "language": "python",
   "name": "sbi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
