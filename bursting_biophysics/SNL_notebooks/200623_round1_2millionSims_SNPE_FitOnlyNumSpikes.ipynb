{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sbi.inference import prepare_for_sbi, SNLE, SNPE\n",
    "from sbi.simulators.linear_gaussian import diagonal_linear_gaussian\n",
    "import sbi.utils as sbi_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load theta and x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.load('../results/cleaned_up_data_onlyNumSpikes.npz', allow_pickle=True)\n",
    "\n",
    "x = torch.as_tensor(data['data'], dtype=torch.float32)\n",
    "theta = torch.as_tensor(data['params'], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1994076, 5])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from parameter_setup import load_ground_truth_params, load_prior_min, load_prior_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data to standardize - needed to standardize x_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#standardize_vals = np.load('../results/standardize_vals.npz')\n",
    "#x_mean = standardize_vals['data_mean']\n",
    "#x_std = standardize_vals['data_std']\n",
    "#\n",
    "#theta_mean = standardize_vals['theta_mean']\n",
    "#theta_std = standardize_vals['theta_std']\n",
    "\n",
    "x_mean = x.mean(dim=0)\n",
    "x_std = x.std(dim=0)\n",
    "\n",
    "theta_mean = theta.mean(dim=0)\n",
    "theta_std = theta.std(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = (x-x_mean) / x_std\n",
    "theta = (theta-theta_mean) / theta_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load x_o (which I got from running the simulator with Arco's ground truth params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_o = torch.as_tensor(np.load('../results/observation/x_o_new_ss.npz')['x_o'], dtype=torch.float32)\n",
    "x_o = x_o[::7]\n",
    "x_o = (x_o - x_mean) / x_std\n",
    "x_o = x_o.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dummy simulator and dummy prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dummy_simulator(theta):\n",
    "    return torch.ones(1,5)\n",
    "\n",
    "dummy_prior = sbi_utils.BoxUniform(torch.as_tensor(load_prior_min()), torch.as_tensor(load_prior_max()))\n",
    "_bound = torch.sqrt(torch.as_tensor(3.))\n",
    "dummy_prior_norm = sbi_utils.BoxUniform(-_bound*torch.ones(35), _bound*torch.ones(35))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sbi.utils.get_nn_models import likelihood_nn, posterior_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/anaconda3/envs/sbi/lib/python3.8/site-packages/nflows/transforms/standard.py:62: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"_shift\", torch.tensor(shift if (shift is not None) else 0.0)\n",
      "/home/michael/anaconda3/envs/sbi/lib/python3.8/site-packages/nflows/transforms/standard.py:65: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"_scale\", torch.tensor(scale if (scale is not None) else 1.0)\n"
     ]
    }
   ],
   "source": [
    "simulator, prior, x_shape = prepare_for_sbi(dummy_simulator, dummy_prior_norm)\n",
    "\n",
    "nsf = likelihood_nn(\n",
    "    model='nsf',\n",
    "    theta_shape=prior.sample().shape,\n",
    "    x_o_shape=x_shape,\n",
    "    hidden_features=100,\n",
    "    flow_num_transforms=5,\n",
    ")\n",
    "\n",
    "nsf_posterior = posterior_nn(\n",
    "    model='nsf',\n",
    "    prior=prior,\n",
    "    x_o_shape=x_shape,\n",
    "    hidden_features=100,\n",
    "    flow_num_transforms=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inference = SNPE(\n",
    "    simulator, \n",
    "    prior,\n",
    "    x_shape,\n",
    "    external_data=(theta, x), # todo: remove the [:1000] to train on all datasamples\n",
    "    mcmc_method='slice', \n",
    "    density_estimator=nsf_posterior\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Zero-length parameter theta implies zero simulations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network successfully converged after 38 epochs.\n"
     ]
    }
   ],
   "source": [
    "posterior = inference(\n",
    "    num_rounds=1,\n",
    "    num_simulations_per_round=0,\n",
    "    batch_size=100, # default is 50\n",
    "    stop_after_epochs=5, # default is 20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../results/posteriors/200623_PosteriorSNPE_fitOnlyNumSpikes.pickle', 'wb') as handle:\n",
    "    pickle.dump(posterior, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run VI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sbi.utils.get_nn_models import get_vi_net\n",
    "from sbi.utils.vi import train_vi, train_mle\n",
    "import torch\n",
    "import sbi.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (get_bounded_flows.py, line 52)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/home/michael/anaconda3/envs/sbi/lib/python3.8/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3331\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-46-228902678dd5>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from bflows.utils.neural_net.get_bounded_flows import get_bflow\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"../../../bFlows/bflows/utils/neural_net/get_bounded_flows.py\"\u001b[0;36m, line \u001b[0;32m52\u001b[0m\n\u001b[0;31m    use_batch_norm=False,\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../../bFlows')\n",
    "from bflows.utils.neural_net.get_bounded_flows import get_bflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temper the posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_o = torch.as_tensor(np.load('../results/observation/x_o_new_ss.npz')['x_o'], dtype=torch.float32)\n",
    "x_o = x_o[::7]\n",
    "x_o[0] = 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_o = (x_o - x_mean) / x_std\n",
    "x_o = x_o.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.6027,  1.3153,  1.3030, -0.4727,  0.2522]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the VI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "posterior = posterior.set_default_x(x_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../results/posteriors/200623_PosteriorSNPE_fitOnlyNumSpikes.pickle', 'rb') as handle:\n",
    "    posterior = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new iter, 0\n",
      "new iter, 1\n",
      "new iter, 2\n",
      "new iter, 3\n",
      "new iter, 4\n",
      "new iter, 5\n",
      "new iter, 6\n",
      "new iter, 7\n",
      "new iter, 8\n",
      "new iter, 9\n"
     ]
    }
   ],
   "source": [
    "s = []\n",
    "num_iter = 10\n",
    "num_samples_per_iter = 1000\n",
    "\n",
    "for k in range(num_iter):\n",
    "    print(\"new iter,\", k)\n",
    "    samples = posterior.sample((num_samples_per_iter,))\n",
    "\n",
    "    # denormalize the samples\n",
    "    samples = samples * theta_std + theta_mean\n",
    "\n",
    "    # convert to list for pickling\n",
    "    samples_list = samples.numpy().tolist()\n",
    "    \n",
    "    s.append(samples_list)\n",
    "s = np.asarray(s)\n",
    "s = s.reshape(num_iter*num_samples_per_iter, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s_list = s.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[184.87274169921875, 0.032795608043670654, 866.86669921875, 0.024980919435620308, 214.65951538085938, 0.04490228742361069, 0.002000484149903059, 0.00020592767396010458, 0.00034289556788280606, 0.10562007874250412, 0.0034870579838752747, 0.0062654884532094, 0.00015373548376373947, 0.02225324511528015, 0.2154516577720642, 0.018768899142742157, 0.07078845053911209, 0.01912408135831356, 3.543728828430176, 3.351080894470215, 0.0015869250055402517, 0.008990748785436153, 0.00985052902251482, 0.021352890878915787, 0.08439171314239502, 0.02319522388279438, 0.9422140121459961, -1.3956375122070312, 1.5813851356506348, 1.268161654472351, 4.472703949431889e-05, 3.330173422000371e-05, 3.205982284271158e-05, 2.2045933292247355e-05, 1.3342845439910889]\n"
     ]
    }
   ],
   "source": [
    "print(s_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../results/samples/200622_PosteriorSNPE_onlyNumSpikes_samples.pickle', 'wb') as handle:\n",
    "    pickle.dump(s_list, handle, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gt_params = [137.862136034238,\n",
    " 0.0005793520824526776,\n",
    " 199.1298048149789,\n",
    " 0.0006108049075983062,\n",
    " 152.1647419393015,\n",
    " 0.00742430653684668,\n",
    " 0.0010965218089651857,\n",
    " 0.0008186770602065786,\n",
    " 0.00011435310571497434,\n",
    " 0.0022763084379226854,\n",
    " 0.0036986082079423594,\n",
    " 0.00013883334761566004,\n",
    " 3.2474860530531394e-06,\n",
    " 0.005426837416265438,\n",
    " 0.10568666421909532,\n",
    " 0.04812676692103998,\n",
    " 0.094826660872338,\n",
    " 0.013854989311151315,\n",
    " 3.9010342040060975,\n",
    " 3.8851157748263354,\n",
    " 0.009964343408409574,\n",
    " 0.006000497448875096,\n",
    " 0.0012602755616811401,\n",
    " 0.01392240648099882,\n",
    " 0.06283710421562513,\n",
    " 6.68382138396179e-05,\n",
    " 0.08311048073340864,\n",
    " -2.9836949894223825,\n",
    " 1.9642986130169147,\n",
    " 1.2999358521956366,\n",
    " 4.4931548434199036e-05,\n",
    " 2.062212836678345e-05,\n",
    " 4.22059843297412e-05,\n",
    " 2.2409802171891654e-05,\n",
    " 1.7109080877160283]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gt_params_norm = (torch.as_tensor(gt_params) - theta_mean) / theta_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples = posterior.sample((10000,)).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probs = posterior.log_prob(samples).detach().numpy()\n",
    "prob_of_gt = posterior.log_prob(gt_params_norm.unsqueeze(0)).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(5,5))\n",
    "_ = plt.hist(probs, bins=100)\n",
    "ax.axvline(prob_of_gt, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-43.4859])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_prior_norm.log_prob(gt_params_norm.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior predictives\n",
    "Has to be done in a different virtual env with python 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "sbi",
   "language": "python",
   "name": "sbi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
