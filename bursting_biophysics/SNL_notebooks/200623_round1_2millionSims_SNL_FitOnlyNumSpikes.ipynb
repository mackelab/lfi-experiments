{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyknos/nflows/nn/nde\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sbi.inference import prepare_for_sbi, SNLE\n",
    "from sbi.simulators.linear_gaussian import diagonal_linear_gaussian\n",
    "import sbi.utils as sbi_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load theta and x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.load('../results/cleaned_up_data_onlyNumSpikes.npz', allow_pickle=True)\n",
    "\n",
    "x = torch.as_tensor(data['data'], dtype=torch.float32)\n",
    "theta = torch.as_tensor(data['params'], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1994076, 5])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from parameter_setup import load_ground_truth_params, load_prior_min, load_prior_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data to standardize - needed to standardize x_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#standardize_vals = np.load('../results/standardize_vals.npz')\n",
    "#x_mean = standardize_vals['data_mean']\n",
    "#x_std = standardize_vals['data_std']\n",
    "#\n",
    "#theta_mean = standardize_vals['theta_mean']\n",
    "#theta_std = standardize_vals['theta_std']\n",
    "\n",
    "x_mean = x.mean(dim=0)\n",
    "x_std = x.std(dim=0)\n",
    "\n",
    "theta_mean = theta.mean(dim=0)\n",
    "theta_std = theta.std(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = (x-x_mean) / x_std\n",
    "theta = (theta-theta_mean) / theta_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load x_o (which I got from running the simulator with Arco's ground truth params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_o = torch.as_tensor(np.load('../results/observation/x_o_new_ss.npz')['x_o'], dtype=torch.float32)\n",
    "x_o = x_o[::7]\n",
    "x_o = (x_o - x_mean) / x_std\n",
    "x_o = x_o.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dummy simulator and dummy prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dummy_simulator(theta):\n",
    "    return torch.ones(1,5)\n",
    "\n",
    "dummy_prior = sbi_utils.BoxUniform(torch.as_tensor(load_prior_min()), torch.as_tensor(load_prior_max()))\n",
    "_bound = torch.sqrt(torch.as_tensor(3.))\n",
    "dummy_prior_norm = sbi_utils.BoxUniform(-_bound*torch.ones(35), _bound*torch.ones(35))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sbi.utils.get_nn_models import likelihood_nn, posterior_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simulator, prior, x_shape = prepare_for_sbi(dummy_simulator, dummy_prior_norm)\n",
    "\n",
    "nsf = likelihood_nn(\n",
    "    model='nsf',\n",
    "    theta_shape=prior.sample().shape,\n",
    "    x_o_shape=x_shape,\n",
    "    hidden_features=100,\n",
    "    flow_num_transforms=5,\n",
    ")\n",
    "\n",
    "nsf_posterior = posterior_nn(\n",
    "    model='nsf',\n",
    "    prior=prior,\n",
    "    x_o_shape=x_shape,\n",
    "    hidden_features=100,\n",
    "    flow_num_transforms=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inference = SNLE(\n",
    "    simulator, \n",
    "    prior,\n",
    "    x_shape,\n",
    "    external_data=(theta, x), # todo: remove the [:1000] to train on all datasamples\n",
    "    mcmc_method='slice', \n",
    "    density_estimator=nsf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Zero-length parameter theta implies zero simulations.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-3c51e3b58787>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m posterior = inference(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mnum_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mnum_simulations_per_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# default is 50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstop_after_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# default is 20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/sbi/sbi/inference/snle/snle_a.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, num_rounds, num_simulations_per_round, x_o, batch_size, learning_rate, validation_fraction, stop_after_epochs, max_num_epochs, clip_max_norm, exclude_invalid_x, discard_prior_samples, retrain_from_scratch_each_round)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \"\"\"\n\u001b[1;32m    129\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdel_entries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"self\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__class__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/sbi/sbi/inference/snle/snle_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, num_rounds, num_simulations_per_round, x_o, batch_size, learning_rate, validation_fraction, stop_after_epochs, max_num_epochs, clip_max_norm, exclude_invalid_x, discard_prior_samples, retrain_from_scratch_each_round)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0;31m# Fit neural likelihood to newly aggregated dataset.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             self._train(\n\u001b[0m\u001b[1;32m    184\u001b[0m                 \u001b[0mround_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mround_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/sbi/sbi/inference/snle/snle_base.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, round_, batch_size, learning_rate, validation_fraction, stop_after_epochs, max_num_epochs, clip_max_norm, discard_prior_samples, retrain_from_scratch_each_round)\u001b[0m\n\u001b[1;32m    283\u001b[0m                     \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m                 )\n\u001b[0;32m--> 285\u001b[0;31m                 \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_posterior\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sbi/lib/python3.8/site-packages/nflows/distributions/base.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, inputs, context)\u001b[0m\n\u001b[1;32m     38\u001b[0m                     \u001b[0;34m\"Number of input items must be equal to number of context items.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 )\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sbi/lib/python3.8/site-packages/nflows/flows/base.py\u001b[0m in \u001b[0;36m_log_prob\u001b[0;34m(self, inputs, context)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0membedded_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_embedding_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogabsdet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedded_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedded_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlog_prob\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlogabsdet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sbi/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sbi/lib/python3.8/site-packages/nflows/transforms/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, context)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mfuncs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cascade\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuncs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sbi/lib/python3.8/site-packages/nflows/transforms/base.py\u001b[0m in \u001b[0;36m_cascade\u001b[0;34m(inputs, funcs, context)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mtotal_logabsdet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfuncs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogabsdet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0mtotal_logabsdet\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlogabsdet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_logabsdet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sbi/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sbi/lib/python3.8/site-packages/nflows/transforms/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, context)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mfuncs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cascade\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuncs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sbi/lib/python3.8/site-packages/nflows/transforms/base.py\u001b[0m in \u001b[0;36m_cascade\u001b[0;34m(inputs, funcs, context)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mtotal_logabsdet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfuncs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogabsdet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0mtotal_logabsdet\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlogabsdet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_logabsdet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sbi/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sbi/lib/python3.8/site-packages/nflows/transforms/coupling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, context)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mtransform_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mtransform_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentity_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         transform_split, logabsdet = self._coupling_transform_forward(\n\u001b[1;32m     86\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sbi/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sbi/lib/python3.8/site-packages/nflows/nn/nets/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, context)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mtemps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0mtemps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mtemps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sbi/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sbi/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sbi/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "posterior = inference(\n",
    "    num_rounds=1,\n",
    "    num_simulations_per_round=0,\n",
    "    batch_size=100, # default is 50\n",
    "    stop_after_epochs=5, # default is 20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "#with open('../results/posteriors/200623_PosteriorSNL_fitOnlyNumSpikes.pickle', 'wb') as handle:\n",
    "#    pickle.dump(posterior, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run VI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sbi.utils.get_nn_models import get_vi_net\n",
    "from sbi.utils.vi import train_vi, train_mle\n",
    "import torch\n",
    "import sbi.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../bFlows')\n",
    "from bflows.utils.neural_net.get_bounded_flows import get_bflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vi_net = get_vi_net(parameter_dim=35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temper the posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_o = torch.as_tensor(np.load('../results/observation/x_o_new_ss.npz')['x_o'], dtype=torch.float32)\n",
    "x_o = x_o[::7]\n",
    "x_o[0] = 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_o = (x_o - x_mean) / x_std\n",
    "x_o = x_o.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.6027,  1.3153,  1.3030, -0.4727,  0.2522]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the VI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'posterior' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-c60de9bfe261>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mposterior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mposterior\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_default_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_o\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'posterior' is not defined"
     ]
    }
   ],
   "source": [
    "posterior = posterior.set_default_x(x_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/anaconda3/envs/sbi/lib/python3.8/site-packages/nflows/transforms/standard.py:62: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"_shift\", torch.tensor(shift if (shift is not None) else 0.0)\n",
      "/home/michael/anaconda3/envs/sbi/lib/python3.8/site-packages/nflows/transforms/standard.py:65: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"_scale\", torch.tensor(scale if (scale is not None) else 1.0)\n",
      "/home/michael/Documents/sbi/sbi/inference/posterior.py:247: UserWarning: The log probability from SNL is only correct up to a normalizing constant.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:    tensor(5.1340, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(4.4587, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(4.0894, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(2.2876, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(2.0384, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(1.4554, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(0.2480, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-2.4316, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-1.4526, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-4.3211, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-5.4996, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-6.5125, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-7.6798, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-9.6347, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-10.1122, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-9.7500, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-10.7089, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-13.2427, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-14.3338, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-15.4716, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-16.8149, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-17.3146, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-18.9380, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-18.9340, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-19.7791, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-19.7868, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-20.4597, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-20.5541, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-20.6439, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-21.4591, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-21.3199, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-21.7824, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-22.1337, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-22.9167, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-22.8393, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-23.3534, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-23.1593, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-23.4640, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-23.5473, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-23.3569, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-23.7836, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-23.8325, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-23.8615, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-24.3144, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-23.9955, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-23.9239, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-24.3695, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-24.1700, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-24.3834, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-24.3799, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-24.7942, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-24.6547, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-24.6199, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-24.5093, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-24.8465, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-24.9566, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-24.7587, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-24.9477, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.1044, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-24.9286, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-24.7542, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-24.8642, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-24.9271, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.0046, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-24.6451, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.0577, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-24.7845, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.0723, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-24.9518, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.1289, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-24.8035, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-24.8356, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-24.9667, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.1176, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.5994, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.4270, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.4160, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.3299, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.6846, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.3292, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.1829, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.2473, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.0402, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.2566, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.1362, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.4180, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.2784, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.2528, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.0984, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-24.7375, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.4761, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.2863, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.6056, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.5983, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.6086, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.7964, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.4859, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-24.8806, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.1452, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.0884, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-24.9838, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.3323, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.4547, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.5556, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.4385, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.3013, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.2419, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.2848, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.3976, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.6291, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.6886, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.8664, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.7861, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.7627, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.9962, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.6943, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.4838, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.0570, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.0730, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.3862, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.5556, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.6848, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.6127, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.6209, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.5168, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.2021, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.2233, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.2555, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.2601, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.4838, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.5571, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.7931, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.8380, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-20000024., grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.9792, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.8700, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.5086, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.2426, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.2669, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.5287, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.5211, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.9653, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.7624, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.8471, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.7053, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.6286, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.6287, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.4827, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.6247, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.7525, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.3297, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.7525, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-26.0681, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.8976, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.6175, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.7839, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.8612, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.7635, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.9362, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.5914, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.9486, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-26.0723, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.8287, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.6183, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.8391, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.7087, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.7599, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.8120, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.9537, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.8635, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-26.2005, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.9208, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-26.1784, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.8664, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.8956, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.7106, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.5640, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.9509, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.9033, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-26.0430, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-26.2677, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.9880, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-26.0477, grad_fn=<MeanBackward0>)\n",
      "loss:    tensor(-25.9240, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "vi_net_ = get_bflow('nsf_uncond_bounded', prior=prior, context=x_o, num_coupling=10, hidden_features=200)\n",
    "trained_vi_net = train_vi(vi_net_, posterior, batch_size=500, stop_after_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import pickle\n",
    "#with open('../results/posteriors/200622_PosteriorSNL_VI_onlyNumSpikes.pickle', 'wb') as handle:\n",
    "#    pickle.dump(trained_vi_net, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../results/posteriors/200623_PosteriorSNL_fitOnlyNumSpikes.pickle', 'rb') as handle:\n",
    "    posterior = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../results/posteriors/200622_PosteriorSNL_VI_onlyNumSpikes.pickle', 'rb') as handle:\n",
    "    trained_vi_net = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new iter, 0\n",
      "new iter, 1\n",
      "new iter, 2\n",
      "new iter, 3\n",
      "new iter, 4\n",
      "new iter, 5\n",
      "new iter, 6\n",
      "new iter, 7\n",
      "new iter, 8\n",
      "new iter, 9\n"
     ]
    }
   ],
   "source": [
    "s = []\n",
    "num_iter = 10\n",
    "num_samples_per_iter = 1000\n",
    "\n",
    "for k in range(num_iter):\n",
    "    print(\"new iter,\", k)\n",
    "    samples = trained_vi_net.sample(num_samples_per_iter).detach()\n",
    "\n",
    "    # denormalize the samples\n",
    "    samples = samples * theta_std + theta_mean\n",
    "\n",
    "    # convert to list for pickling\n",
    "    samples_list = samples.numpy().tolist()\n",
    "    \n",
    "    s.append(samples_list)\n",
    "s = np.asarray(s)\n",
    "s = s.reshape(num_iter*num_samples_per_iter, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s_list = s.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[77.65660095214844, 0.017694005742669106, 361.669189453125, 0.030409567058086395, 780.054443359375, 0.017275288701057434, 0.0019882633350789547, 0.0009202725486829877, 0.0006011490477249026, 0.16971954703330994, 0.004872288089245558, 0.004570601042360067, 0.0006421939469873905, 0.5887959599494934, 0.12079206109046936, 0.024282097816467285, 0.002401486039161682, 0.015494058839976788, 1.235221028327942, 3.075859546661377, 0.0009245360270142555, 0.00973385851830244, 0.006444841623306274, 0.02815038152039051, 0.04655549302697182, 0.024156933650374413, 0.5037880539894104, -1.8596181869506836, 1.0814356803894043, 0.42915838956832886, 6.254504842218012e-05, 4.5513846998801455e-05, 6.231456791283563e-05, 2.2453092242358252e-05, 0.8075348138809204]\n"
     ]
    }
   ],
   "source": [
    "print(s_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../results/samples/200622_PosteriorSNL_onlyNumSpikes_VI_samples.pickle', 'wb') as handle:\n",
    "    pickle.dump(s_list, handle, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gt_params = [137.862136034238,\n",
    " 0.0005793520824526776,\n",
    " 199.1298048149789,\n",
    " 0.0006108049075983062,\n",
    " 152.1647419393015,\n",
    " 0.00742430653684668,\n",
    " 0.0010965218089651857,\n",
    " 0.0008186770602065786,\n",
    " 0.00011435310571497434,\n",
    " 0.0022763084379226854,\n",
    " 0.0036986082079423594,\n",
    " 0.00013883334761566004,\n",
    " 3.2474860530531394e-06,\n",
    " 0.005426837416265438,\n",
    " 0.10568666421909532,\n",
    " 0.04812676692103998,\n",
    " 0.094826660872338,\n",
    " 0.013854989311151315,\n",
    " 3.9010342040060975,\n",
    " 3.8851157748263354,\n",
    " 0.009964343408409574,\n",
    " 0.006000497448875096,\n",
    " 0.0012602755616811401,\n",
    " 0.01392240648099882,\n",
    " 0.06283710421562513,\n",
    " 6.68382138396179e-05,\n",
    " 0.08311048073340864,\n",
    " -2.9836949894223825,\n",
    " 1.9642986130169147,\n",
    " 1.2999358521956366,\n",
    " 4.4931548434199036e-05,\n",
    " 2.062212836678345e-05,\n",
    " 4.22059843297412e-05,\n",
    " 2.2409802171891654e-05,\n",
    " 1.7109080877160283]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gt_params_norm = (torch.as_tensor(gt_params) - theta_mean) / theta_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples = trained_vi_net.sample(10000).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probs = posterior.log_prob(samples, x=x_o).detach().numpy()\n",
    "prob_of_gt = posterior.log_prob(gt_params_norm.unsqueeze(0), x=x_o).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x7f94f67b8a90>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUUAAAEvCAYAAADSG9NhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAASZ0lEQVR4nO3dfYxc113G8e+DDaYtiprIm2BshzXICnXCW7syASQUKYANreLwRyRXlFo0yLRyW0BUrU0kglRZCu9QIEGmDXVFqbEKKBah0GCIKqSkYfuSJk5qstRpso0bb4uACiRTpz/+mGs4bGa9uzOzL958P9Jo7v3dc+eeY1uPzp079zpVhSSp5+tWugOStJoYipLUMBQlqWEoSlLDUJSkhqEoSY31K92B+WzcuLHGx8dXuhuSWqdP996vu25l+zGET3ziE1+qqrHZ9VUfiuPj40xOTq50NyS1brqp9/7ggyvZi6Ek+Xy/uqfPktQwFCWpYShKUsNQlKSGoShJDUNRkhqGoiQ1DEVJahiKktSYNxST3JvkXJLH+2x7R5JKsrGpHUoyleR0kl1N/TVJHuu2vSdJRjcMSRqNhcwU3w/snl1MshX4EeCZprYD2Atc3+1zd5J13eZ7gP3A9u71os+UpJU2773PVfWxJON9Nv028E7gvqa2BzhWVeeBM0mmgJ1JngauqKqHAJJ8ALgV+MhQvZe05owfvP9Ftafveu2yHX+g7xST3AJ8oaoenbVpM/Bssz7d1TZ3y7PrkrSqLPopOUleDtwB/Gi/zX1qdYn6XMfYT+9Um2uvvXaxXZSkgQ0yU/x2YBvwaHdavAX4ZJJvpjcD3Nq03QI819W39Kn3VVVHqmqiqibGxl70uDNJWjKLDsWqeqyqrq6q8aoapxd4r66qLwIngL1JNiTZRu+CyiNVdRb4SpIbu6vOb+T/fxcpSavCQn6S8yHgIeC6JNNJbp+rbVWdAo4DTwB/Axyoqhe6zW8B3gtMAf+CF1kkrUILufr8+nm2j89aPwwc7tNuErhhkf2TpGXlHS2S1DAUJalhKEpSw1CUpIahKEkNQ1GSGoaiJDUMRUlqGIqS1DAUJalhKEpSw1CUpIahKEkNQ1GSGoaiJDUMRUlqGIqS1DAUJalhKEpSw1CUpIahKEkNQ1GSGoaiJDUMRUlqGIqS1DAUJalhKEpSw1CUpMa8oZjk3iTnkjze1H49yWeTfCbJXyZ5ZbPtUJKpJKeT7Grqr0nyWLftPUky+uFI0nAWMlN8P7B7Vu0B4Iaq+i7gn4FDAEl2AHuB67t97k6yrtvnHmA/sL17zf5MSVpx84ZiVX0M+NdZtY9W1YVu9WFgS7e8BzhWVeer6gwwBexMsgm4oqoeqqoCPgDcOqpBSNKorB/BZ7wJ+LNueTO9kLxouqt9tVueXZckAMYP3r/SXQCGvNCS5A7gAvDBi6U+zeoS9bk+d3+SySSTMzMzw3RRkhZl4FBMsg94HfCT3Skx9GaAW5tmW4DnuvqWPvW+qupIVU1U1cTY2NigXZSkRRsoFJPsBt4F3FJV/9VsOgHsTbIhyTZ6F1QeqaqzwFeS3NhddX4jcN+QfZekkZv3O8UkHwJuAjYmmQbupHe1eQPwQPfLmoer6s1VdSrJceAJeqfVB6rqhe6j3kLvSvbLgI90L0laVeYNxap6fZ/y+y7R/jBwuE99ErhhUb2TpGXmHS2S1DAUJalhKEpSw1CUpIahKEkNQ1GSGoaiJDUMRUlqGIqS1DAUJalhKEpSw1CUpMYonrwtSUuqfSr303e9dkmP5UxRkhqGoiQ1DEVJahiKktQwFCWpYShKUsNQlKSGoShJDUNRkhqGoiQ1DEVJahiKktQwFCWpYShKUsNQlKTGvKGY5N4k55I83tSuSvJAkqe69yubbYeSTCU5nWRXU39Nkse6be9JktEPR5KGs5CZ4vuB3bNqB4GTVbUdONmtk2QHsBe4vtvn7iTrun3uAfYD27vX7M+UpBU3byhW1ceAf51V3gMc7ZaPArc29WNVdb6qzgBTwM4km4ArquqhqirgA80+krRqDPrfEVxTVWcBqupskqu7+mbg4abddFf7arc8u95Xkv30ZpVce+21A3ZR0mrX/jcDq8WoL7T0+56wLlHvq6qOVNVEVU2MjY2NrHOSNJ9BQ/H57pSY7v1cV58GtjbttgDPdfUtfeqStKoMGoongH3d8j7gvqa+N8mGJNvoXVB5pDvV/kqSG7urzm9s9pGkVWPe7xSTfAi4CdiYZBq4E7gLOJ7kduAZ4DaAqjqV5DjwBHABOFBVL3Qf9RZ6V7JfBnyke0nSqjJvKFbV6+fYdPMc7Q8Dh/vUJ4EbFtU7SVpm3tEiSQ1DUZIahqIkNQxFSWoYipLUMBQlqWEoSlLDUJSkhqEoSQ1DUZIahqIkNQxFSWoYipLUMBQlqWEoSlLDUJSkhqEoSQ1DUZIahqIkNQxFSWoYipLUMBQlqWEoSlLDUJSkhqEoSQ1DUZIahqIkNYYKxSS/kORUkseTfCjJNya5KskDSZ7q3q9s2h9KMpXkdJJdw3dfkkZr4FBMshl4OzBRVTcA64C9wEHgZFVtB0526yTZ0W2/HtgN3J1k3XDdl6TRGvb0eT3wsiTrgZcDzwF7gKPd9qPArd3yHuBYVZ2vqjPAFLBzyONL0kgNHIpV9QXgN4BngLPAv1fVR4Frqups1+YscHW3y2bg2eYjpruaJK0aw5w+X0lv9rcN+BbgFUnecKld+tRqjs/en2QyyeTMzMygXZSkRRvm9PmHgTNVNVNVXwX+AvgB4PkkmwC693Nd+2lga7P/Fnqn2y9SVUeqaqKqJsbGxobooiQtzjCh+AxwY5KXJwlwM/AkcALY17XZB9zXLZ8A9ibZkGQbsB14ZIjjS9LIrR90x6r6eJIPA58ELgCfAo4A3wQcT3I7veC8rWt/Kslx4Imu/YGqemHI/ku6DI0fvH+luzCngUMRoKruBO6cVT5Pb9bYr/1h4PAwx5SkpeQdLZLUMBQlqWEoSlLDUJSkhqEoSQ1DUZIahqIkNQxFSWoYipLUMBQlqWEoSlLDUJSkhqEoSQ1DUZIahqIkNQxFSWoYipLUMBQlqWEoSlLDUJSkhqEoSQ1DUZIahqIkNQxFSWoYipLUMBQlqWEoSlLDUJSkxlChmOSVST6c5LNJnkzy/UmuSvJAkqe69yub9oeSTCU5nWTX8N2XpNEadqb4u8DfVNV3AN8NPAkcBE5W1XbgZLdOkh3AXuB6YDdwd5J1Qx5fkkZq4FBMcgXwQ8D7AKrqv6vq34A9wNGu2VHg1m55D3Csqs5X1RlgCtg56PElaSkMM1P8NmAG+OMkn0ry3iSvAK6pqrMA3fvVXfvNwLPN/tNdTZJWjWFCcT3wauCeqvpe4D/pTpXnkD616tsw2Z9kMsnkzMzMEF2UpMUZJhSngemq+ni3/mF6Ifl8kk0A3fu5pv3WZv8twHP9PriqjlTVRFVNjI2NDdFFSVqcgUOxqr4IPJvkuq50M/AEcALY19X2Afd1yyeAvUk2JNkGbAceGfT4krQU1g+5/9uADyb5BuBzwE/TC9rjSW4HngFuA6iqU0mO0wvOC8CBqnphyONL0kgNFYpV9Wlgos+mm+dofxg4PMwxJV2exg/ev9JdWBDvaJGkhqEoSQ1DUZIahqIkNQxFSWoYipLUMBQlqWEoSlLDUJSkhqEoSQ1DUZIahqIkNQxFSWoYipLUMBQlqWEoSlLDUJSkhqEoSQ1DUZIahqIkNQxFSWoYipLUMBQlXVbGD96/pP9dqqEoSQ1DUZIahqIkNQxFSWoYipLUGDoUk6xL8qkkf9WtX5XkgSRPde9XNm0PJZlKcjrJrmGPLUmjNoqZ4s8BTzbrB4GTVbUdONmtk2QHsBe4HtgN3J1k3QiOL0kjM1QoJtkCvBZ4b1PeAxztlo8Ctzb1Y1V1vqrOAFPAzmGOL0mjNuxM8XeAdwJfa2rXVNVZgO796q6+GXi2aTfd1V4kyf4kk0kmZ2ZmhuyiJC3cwKGY5HXAuar6xEJ36VOrfg2r6khVTVTVxNjY2KBdlKRFWz/Evj8I3JLkx4FvBK5I8ifA80k2VdXZJJuAc137aWBrs/8W4Lkhji9JIzfwTLGqDlXVlqoap3cB5e+r6g3ACWBf12wfcF+3fALYm2RDkm3AduCRgXsuSUtgmJniXO4Cjie5HXgGuA2gqk4lOQ48AVwADlTVC0twfEka2EhCsaoeBB7slr8M3DxHu8PA4VEcU9LlYSmfaLMUvKNFkhqGoiQ1DEVJahiKktQwFCWpYShKUsNQlKSGoShJDUNRkhqGoiQ1DEVJahiKktQwFCWpYShKUsNQlKSGoShJjaV48rakl7jL7cGyLWeKktQwFCWpYShKUsNQlKSGoShJDUNRkhqGoiQ1DEVJahiKktQwFCWpMXAoJtma5B+SPJnkVJKf6+pXJXkgyVPd+5XNPoeSTCU5nWTXKAYgSaM0zEzxAvCLVfUq4EbgQJIdwEHgZFVtB05263Tb9gLXA7uBu5OsG6bzkjRqAz8QoqrOAme75a8keRLYDOwBbuqaHQUeBN7V1Y9V1XngTJIpYCfw0KB9kLS6XM4PgrhoJN8pJhkHvhf4OHBNF5gXg/Pqrtlm4Nlmt+muJkmrxtChmOSbgD8Hfr6q/uNSTfvUao7P3J9kMsnkzMzMsF2UpAUbKhSTfD29QPxgVf1FV34+yaZu+ybgXFefBrY2u28Bnuv3uVV1pKomqmpibGxsmC5K0qIMc/U5wPuAJ6vqt5pNJ4B93fI+4L6mvjfJhiTbgO3AI4MeX5KWwjBP3v5B4KeAx5J8uqv9EnAXcDzJ7cAzwG0AVXUqyXHgCXpXrg9U1QtDHF+SRm6Yq8//SP/vCQFunmOfw8DhQY8pSUvN/6NF0lDWws9wWt7mJ0kNQ1GSGoaipIE8/Lkvr7lTZzAUJen/MRQlqWEoSlLDUJSkhqEoSQ1DUZIahqIkNbzNT9KCXfxd4rHPfXmFe7J0nClKUsNQlKSGoSipr/GD96/J2/jm43eKki7ppRaMzhQlqWEoSlLDUJSkhqEoSQ0vtEj634spT9/12hXuycK1F4BG2W9DUdL/eqldae7H02dJahiKktTw9Fl6ifJUuT9nipLUcKYovcQ4Q7w0Z4qS1Fj2mWKS3cDvAuuA91bVXcvdB+mlxtnhwi3rTDHJOuAPgB8DdgCvT7JjOfsgrVUv1Ud9jdpyzxR3AlNV9TmAJMeAPcATy9wPaU4rdXdHv0Br+7DQwDMYh7PcobgZeLZZnwa+b5QHmO/Wn2H+4c3X7uL2+Y7Rrz+D9HWxFvNn028siz32Qvs/15/5QvvQ78/wUrWFWg3hshr68FKTqlq+gyW3Abuq6me69Z8CdlbV22a12w/s71avA04vWyfntxH40kp3Yok5xrXBMV7at1bV2Ozics8Up4GtzfoW4LnZjarqCHBkuTq1GEkmq2pipfuxlBzj2uAYB7PcP8n5J2B7km1JvgHYC5xY5j5I0pyWdaZYVReSvBX4W3o/ybm3qk4tZx8k6VKW/XeKVfXXwF8v93FHaFWe1o+YY1wbHOMAlvVCiyStdt7mJ0kNQ3GBkvxKki8k+XT3+vFm26EkU0lOJ9m1kv0cVpJ3JKkkG5vamhhfkncn+Uz39/fRJN/SbFsrY/z1JJ/txvmXSV7ZbFsrY7wtyakkX0syMWvb8GOsKl8LeAG/AryjT30H8CiwAdgG/AuwbqX7O+AYt9K7CPZ5YOMaHN8VzfLbgT9cg2P8UWB9t/yrwK+uwTG+it7vlx8EJpr6SMboTHF4e4BjVXW+qs4AU/RuZ7wc/TbwTqD9onnNjK+q/qNZfQX/N861NMaPVtWFbvVher8FhrU1xierqt8NHSMZo6G4OG/tTkvuTXJlV+t36+Lm5e/acJLcAnyhqh6dtWlNjO+iJIeTPAv8JPDLXXlNjbHxJuAj3fJaHWNrJGP0IbONJH8HfHOfTXcA9wDvpje7eDfwm/T+0aVP+1V5SX+e8f0SvVOvF+3Wp7YqxweXHmNV3VdVdwB3JDkEvBW4kzU2xq7NHcAF4IMXd+vT/rIeY7/d+tQWPUZDsVFVP7yQdkn+CPirbnVBty6uBnONL8l30vsO5tEk0BvDJ5Ps5DIaHyz87xD4U+B+eqG4psaYZB/wOuDm6r5sY42NcQ4jGaOnzwuUZFOz+hPA493yCWBvkg1JtgHbgUeWu3/DqKrHqurqqhqvqnF6/7heXVVfZA2M76Ik25vVW4DPdstraYy7gXcBt1TVfzWb1swYL2EkY3SmuHC/luR76E3HnwZ+FqCqTiU5Tu+ZkBeAA1X1wor1csTW2PjuSnId8DV6V9jfDGtujL9P7+rrA92s/+GqevNaGmOSnwB+DxgD7k/y6araNaoxekeLJDU8fZakhqEoSQ1DUZIahqIkNQxFSWoYipLUMBQlqWEoSlLjfwBhSZQT7qoJ8QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(5,5))\n",
    "_ = plt.hist(probs, bins=100)\n",
    "ax.axvline(prob_of_gt, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-43.4859])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_prior_norm.log_prob(gt_params_norm.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior predictives\n",
    "Has to be done in a different virtual env with python 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "sbi",
   "language": "python",
   "name": "sbi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
