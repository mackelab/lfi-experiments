{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from delfi.utils.viz import plot_pdf\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from parameters import ParameterSet\n",
    "\n",
    "import delfi.distribution as dd\n",
    "import delfi.generator as dg\n",
    "import delfi.inference as infer\n",
    "import delfi.summarystats as ds\n",
    "import delfi.kernel as dk\n",
    "from delfi.simulator.BaseSimulator import BaseSimulator\n",
    "import delfi.utils.viz as dv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = ParameterSet({})\n",
    "\n",
    "params.seed = 239\n",
    "\n",
    "params.infer = ParameterSet({})\n",
    "params.infer.n_components = 1\n",
    "params.infer.n_hiddens = [10, 10]\n",
    "params.infer.pilot_samples = 100\n",
    "params.infer.svi = False\n",
    "params.infer.prior_norm = True\n",
    "\n",
    "params.run = ParameterSet({})\n",
    "params.run.n_train = 50000\n",
    "#params.run.minibatch = 100\n",
    "params.run.epochs = 20\n",
    "#params.run.lr = 0.02\n",
    "\n",
    "fontsize=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prior_mean = 2\n",
    "prior_var = 0.5\n",
    "\n",
    "prop_prior_mean=1.09090909\n",
    "prop_prior_var=0.11615753\n",
    "\n",
    "noise_var = 0.01\n",
    "\n",
    "gt = np.array([ 0.6 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gauss(x, mean, cov):\n",
    "    covi = np.linalg.inv(cov)\n",
    "    dots = np.einsum('...i,ij,...j', x - mean, covi, x - mean)\n",
    "    ret = 1 / np.sqrt(2 * np.pi * np.linalg.det(cov)) * np.exp(-0.5 * dots)\n",
    "    assert ret.shape == x.shape[:-1]\n",
    "    return ret\n",
    "\n",
    "class ForwardModel(BaseSimulator):\n",
    "    def __init__(self, seed=None):\n",
    "        super().__init__(dim_param=1, seed=seed)\n",
    "        self.noise_std = np.sqrt(noise_var)\n",
    "    \n",
    "    def gen_single(self, params):\n",
    "        means = self.get_means(params)\n",
    "        sample = means + self.noise_std * self.rng.normal(size=params.shape)\n",
    "        return { \"data\" :  np.array(sample) }\n",
    "    \n",
    "    def likelihood(self, x, params):\n",
    "        means = self.get_means(params)\n",
    "        diffs = means - x\n",
    "        ret = gauss(diffs.reshape(-1,1), [0], (self.noise_std ** 2) * np.eye(1))\n",
    "        return ret\n",
    "        \n",
    "    def get_means(self, params):\n",
    "        return np.sign(params) * (np.abs(params) ** (1/3))\n",
    "    \n",
    "    def get_mle(self, params):\n",
    "        return np.asarray(params) ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def init_g(seed):\n",
    "    \n",
    "\n",
    "    m = ForwardModel(seed=seed)\n",
    "    prior = dd.Gaussian(m=[prior_mean], S=[[prior_var]], seed=seed+1)\n",
    "    prop_prior = dd.Gaussian(m=[prop_prior_mean], S=[[prop_prior_var]], seed=seed+2)\n",
    "    s = ds.Identity(1)\n",
    "\n",
    "    return dg.Default(m, prior, s, seed=seed+3)\n",
    "\n",
    "g = init_g(params.seed)\n",
    "xobs = g.model.get_means(gt)\n",
    "\n",
    "params.run.n_train = 100000\n",
    "params.run.epochs = 200\n",
    "res = infer.SNPE(generator=g, obs=[xobs], verbose=True, **params.infer)\n",
    "\n",
    "logs, tds, posteriors = res.run(n_rounds=1, **params.run)\n",
    "\n",
    "posterior = posteriors[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = init_g(params.seed)\n",
    "g.prior = dd.Gaussian(m=[prop_prior_mean], S=[[prop_prior_var]], seed=params.seed+1234)\n",
    "\n",
    "params.run.n_train = 100000\n",
    "params.run.epochs = 200\n",
    "res_uncorr = infer.SNPE(generator=g, obs=[xobs], verbose=True, **params.infer)\n",
    "\n",
    "logs, tds, posteriors_uncorr = res_uncorr.run(n_rounds=1, **params.run)\n",
    "\n",
    "\n",
    "posterior_uncorr = posteriors_uncorr[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = init_g(params.seed)\n",
    "proposal = dd.Gaussian(m=[prop_prior_mean], S=[[prop_prior_var]], seed=params.seed+1234)\n",
    "\n",
    "res_SNPE = infer.SNPE(generator=g, obs=[xobs], verbose=True, convert_to_T=None, **params.infer)\n",
    "\n",
    "params.run.n_train = 100000\n",
    "params.run.epochs = 200\n",
    "\n",
    "logs, tds, posteriors_SNPE = res_SNPE.run(n_rounds=1, proposal = proposal, **params.run)\n",
    "\n",
    "posterior_SNPE = posteriors_SNPE[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9,9))\n",
    "\n",
    "###############################################################################\n",
    "# sampling from proposal prior and running forward model\n",
    "n_samp = 500\n",
    "np.random.seed(44)\n",
    "\n",
    "g = init_g(params.seed)\n",
    "g.proposal = dd.Gaussian(m=[prop_prior_mean], S=[[prop_prior_var]], seed=params.seed)\n",
    "theta_samp = (np.sqrt(prop_prior_var) * np.random.randn(n_samp) + prop_prior_mean).reshape(-1,1)\n",
    "x_samp = np.sqrt(noise_var) * np.random.randn(n_samp) + g.model.get_means(theta_samp).flatten()\n",
    "#theta_samp = (tds[-1][0].reshape(-1,1) * res_SNPE.params_std) + res_SNPE.params_mean\n",
    "#x_samp     = (tds[-1][1].reshape(-1,1) * res_SNPE.stats_std)  + res_SNPE.stats_mean\n",
    "\n",
    "theta_lims = [0, 3]\n",
    "thetas = np.linspace(theta_lims[0], theta_lims[1], 500)\n",
    "\n",
    "xlims = [0, g.model.get_means(theta_lims[1]) * 1.1]\n",
    "\n",
    "xs = np.linspace(xlims[0], xlims[1], 100)\n",
    "\n",
    "posts = [ res.predict([[x]]) for x in xs ]\n",
    "post_means = np.array([ post.xs[0].m[0] for post in posts ])\n",
    "post_vars = np.array([ post.xs[0].S[0,0] for post in posts ])\n",
    "\n",
    "posts_SNPE = [ res_SNPE.predict([[x]]) for x in xs ]\n",
    "post_means_SNPE = np.array([ post.xs[0].m[0] for post in posts_SNPE ])\n",
    "post_vars_SNPE = np.array([ post.xs[0].S[0,0] for post in posts_SNPE ])\n",
    "\n",
    "gs = gridspec.GridSpec(2, 3, width_ratios=[1, 3, 1], height_ratios=[4,1])\n",
    "\n",
    "prior_col = \"blue\"\n",
    "prop_prior_col = \"magenta\"\n",
    "post_col = \"blue\"\n",
    "post_uncorr_col = \"magenta\"\n",
    "\n",
    "# LEFTHAND SIDE\n",
    "axl = plt.subplot(gs[0,0])\n",
    "#plt.plot(prop_prior, yy, '--',color='0.55', label='proposal prior')\n",
    "plt.plot(g.prior.eval(thetas.reshape(-1,1), log=False), thetas, '--', c=prior_col, label='prior')\n",
    "plt.plot(g.proposal.eval(thetas.reshape(-1,1), log=False), thetas, c=prop_prior_col, label='proposal prior')\n",
    "\n",
    "axl.set_ylim(theta_lims)\n",
    "axl.set_yticks([])\n",
    "axl.set_xticks([])\n",
    "plt.ylabel(r'$\\theta$', fontsize=fontsize)\n",
    "axl.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05),  ncol=1, fontsize=fontsize)\n",
    "axl.spines['top'].set_visible(False)\n",
    "axl.spines['right'].set_visible(False)\n",
    "axr = plt.subplot(gs[0,2])\n",
    "\n",
    "\n",
    "\n",
    "# RIGHTHAND SIDE\n",
    "plt.plot(posterior.eval(thetas.reshape(-1,1), log=False), thetas, c=post_col, label='posterior')\n",
    "plt.plot(posterior_uncorr.eval(thetas.reshape(-1,1), log=False), thetas, \n",
    "         alpha=0.5, c=post_uncorr_col, label='uncorrected posterior \\n(posterior for proposal)')\n",
    "#    plt.plot(pp_post,yy,color=col_2, label='posterior')\n",
    "#plt.plot(pp_param,yy,color=col_3, label='parametrised posterior')\n",
    "axr.set_ylim(theta_lims)\n",
    "#ax.set_xticks([])\n",
    "axr.set_xticks([])\n",
    "plt.ylabel('')\n",
    "axr.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), ncol=1, fontsize=fontsize)\n",
    "#plt.legend(bbox_to_anchor=(1.25, 1), loc='upper right')\n",
    "\n",
    "\n",
    "hl, ll = axl.get_legend_handles_labels()\n",
    "hr, lr = axr.get_legend_handles_labels()\n",
    "axr.set_yticks([])\n",
    "axr.spines['top'].set_visible(False)\n",
    "axr.spines['right'].set_visible(False)\n",
    "\n",
    "axm = plt.subplot(gs[0,1])\n",
    "plt.ylabel('')\n",
    "\n",
    "iws = np.exp(g.prior.eval(theta_samp, log=True) - g.proposal.eval(theta_samp, log=True))\n",
    "\n",
    "# Draw true posterior\n",
    "plt.scatter(x_samp, theta_samp.flatten(), color='0.05', s=30 * np.log((1.1 - np.min(iws)) + iws), alpha=0.4)\n",
    "\n",
    "# Draw posterior means (in orange)\n",
    "std_col = plt.get_cmap(\"tab10\")(0)\n",
    "\n",
    "std_col = 'gray'\n",
    "\n",
    "plt.plot(xs,post_means, c=std_col, label='posterior', alpha=0.5)\n",
    "plt.plot(xs,post_means + 2 * np.sqrt(post_vars),ls='--', c=std_col, alpha=0.5)\n",
    "plt.plot(xs,post_means - 2 * np.sqrt(post_vars),ls='--', c=std_col, alpha=0.5)\n",
    "\n",
    "plt.fill_between(xs,post_means-2 * np.sqrt(post_vars),\n",
    "                 post_means+2 * np.sqrt(post_vars), facecolor=std_col,\n",
    "                 alpha=0.15)\n",
    "\n",
    "\n",
    "std_col = prop_prior_col\n",
    "\n",
    "plt.plot(xs,post_means_SNPE, c=std_col, label='SNPE')\n",
    "plt.plot(xs,post_means_SNPE + 2 * np.sqrt(post_vars_SNPE),ls='--', c=std_col)\n",
    "plt.plot(xs,post_means_SNPE - 2 * np.sqrt(post_vars_SNPE),ls='--', c=std_col)\n",
    "\n",
    "plt.fill_between(xs,post_means_SNPE-2 * np.sqrt(post_vars_SNPE),\n",
    "                 post_means_SNPE+2 * np.sqrt(post_vars_SNPE), facecolor=std_col,\n",
    "                 alpha=0.1)\n",
    "\n",
    "# Draw vertical lines around chosen point\n",
    "axm.axvline(xobs,lw=2, c='k')\n",
    "#     axm.vlines(obs_stats-eps, 0, axm.get_ylim()[1], lw=1, color='0.25')\n",
    "#     axm.vlines(obs_stats+eps, 0, axm.get_ylim()[1], lw=1, color='0.25')\n",
    "\n",
    "axm.set_xlim(xlims)\n",
    "axm.set_ylim(theta_lims)\n",
    "axm.set_xticks([])\n",
    "axm.set_yticks([])\n",
    "#plt.xlabel('x')\n",
    "#plt.legend(bbox_to_anchor=(0.0, 1), loc='upper left')\n",
    "\n",
    "#plt.xticks([xobs], [r'$x_{o}$'])\n",
    "\n",
    "#axm.set_xlabel(\"$x$\", fontsize=fontsize)\n",
    "axm.spines['top'].set_visible(False)\n",
    "axm.spines['right'].set_visible(False)\n",
    "\n",
    "axb = plt.subplot(gs[1,1])\n",
    "\n",
    "\n",
    "def compute_marginals(prop):\n",
    "    thetas = prop.gen(100000)\n",
    "    means = g.model.get_means(thetas)\n",
    "    \n",
    "    ret = means + np.sqrt(noise_var) * np.random.normal(size=thetas.shape)\n",
    "    return ret\n",
    "    \n",
    "prior_marg_samples = compute_marginals(g.prior)\n",
    "prop_prior_marg_samples = compute_marginals(g.proposal)\n",
    "\n",
    "from sklearn.neighbors.kde import KernelDensity\n",
    "\n",
    "prior_marg_density = KernelDensity(kernel='gaussian', \n",
    "                                   bandwidth=0.05 * (xlims[1] - xlims[0])).fit(prior_marg_samples)\n",
    "prop_prior_marg_density = KernelDensity(kernel='gaussian', \n",
    "                                       bandwidth=0.05 * (xlims[1] - xlims[0])).fit(prop_prior_marg_samples)\n",
    "\n",
    "plt.plot(xs, np.exp(prior_marg_density.score_samples(xs.reshape(-1,1))), '--', c=prior_col, label='prior')\n",
    "plt.plot(xs, np.exp(prop_prior_marg_density.score_samples(xs.reshape(-1,1))), c=prop_prior_col, label='prioposal prior')\n",
    "\n",
    "#plt.plot(xs, gen_mod.eval(xs.reshape(-1,1), log=False), color='0.0', label='marginal')\n",
    "\n",
    "axb.set_xlim(xlims)\n",
    "axb.set_xticks([])\n",
    "plt.xticks([xobs], [r'$x_{o}$'], fontsize=fontsize)\n",
    "axb.set_yticks([])\n",
    "\n",
    "axb.set_xlabel(\"$x$\", fontsize=fontsize)\n",
    "axb.set_ylabel(\"density\", fontsize=fontsize)\n",
    "axb.spines['top'].set_visible(False)\n",
    "axb.spines['right'].set_visible(False)\n",
    "#axb.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05),\n",
    " #          fancybox=True, shadow=True, ncol=1)\n",
    "axb.axvline(xobs, lw=2, c='k')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('CDE_with_proposal.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9,9))\n",
    "\n",
    "###############################################################################\n",
    "# sampling from proposal prior and running forward model\n",
    "n_samp = 1000\n",
    "np.random.seed(44)\n",
    "\n",
    "g = init_g(params.seed)\n",
    "g.proposal = dd.Gaussian(m=[prop_prior_mean], S=[[prop_prior_var]], seed=params.seed)\n",
    "theta_samp = (np.sqrt(prior_var) * np.random.randn(n_samp) + prior_mean).reshape(-1,1)\n",
    "x_samp = np.sqrt(noise_var) * np.random.randn(n_samp) + g.model.get_means(theta_samp).flatten()\n",
    "#theta_samp = (tds[-1][0].reshape(-1,1) * res_SNPE.params_std) + res_SNPE.params_mean\n",
    "#x_samp     = (tds[-1][1].reshape(-1,1) * res_SNPE.stats_std)  + res_SNPE.stats_mean\n",
    "\n",
    "theta_lims = [0, 3]\n",
    "thetas = np.linspace(theta_lims[0], theta_lims[1], 500)\n",
    "\n",
    "xlims = [0, g.model.get_means(theta_lims[1]) * 1.1]\n",
    "\n",
    "xs = np.linspace(xlims[0], xlims[1], 100)\n",
    "\n",
    "posts = [ res.predict([[x]]) for x in xs ]\n",
    "post_means = np.array([ post.xs[0].m[0] for post in posts ])\n",
    "post_vars = np.array([ post.xs[0].S[0,0] for post in posts ])\n",
    "\n",
    "posts_SNPE = [ res_SNPE.predict([[x]]) for x in xs ]\n",
    "post_means_SNPE = np.array([ post.xs[0].m[0] for post in posts_SNPE ])\n",
    "post_vars_SNPE = np.array([ post.xs[0].S[0,0] for post in posts_SNPE ])\n",
    "\n",
    "gs = gridspec.GridSpec(2, 3, width_ratios=[1, 3, 1], height_ratios=[4,1])\n",
    "\n",
    "prior_col = \"blue\"\n",
    "prop_prior_col = \"magenta\"\n",
    "post_col = \"blue\"\n",
    "post_uncorr_col = \"magenta\"\n",
    "\n",
    "# LEFTHAND SIDE\n",
    "axl = plt.subplot(gs[0,0])\n",
    "plt.plot(g.prior.eval(thetas.reshape(-1,1), log=False), thetas, '--', c=prior_col, label='prior')\n",
    "axl.set_ylim(theta_lims)\n",
    "axl.set_xlim(xlims)\n",
    "axl.set_yticks([])\n",
    "axl.set_xticks([])\n",
    "axl.spines['top'].set_visible(False)\n",
    "axl.spines['right'].set_visible(False)\n",
    "plt.ylabel(r'$\\theta$', fontsize=fontsize)\n",
    "plt.xlabel('prior', fontsize=fontsize)\n",
    "\n",
    "axr = plt.subplot(gs[0,2])\n",
    "\n",
    "# RIGHTHAND SIDE\n",
    "plt.plot(posterior.eval(thetas.reshape(-1,1), log=False), thetas, c=post_col, label='posterior')\n",
    "axr.set_ylim(theta_lims)\n",
    "axr.set_xticks([])\n",
    "axr.spines['top'].set_visible(False)\n",
    "axr.spines['right'].set_visible(False)\n",
    "plt.ylabel('')\n",
    "plt.xlabel('posterior', fontsize=fontsize)\n",
    "\n",
    "hl, ll = axl.get_legend_handles_labels()\n",
    "hr, lr = axr.get_legend_handles_labels()\n",
    "axr.set_yticks([])\n",
    "\n",
    "axm = plt.subplot(gs[0,1])\n",
    "plt.ylabel('')\n",
    "\n",
    "iws = np.exp(g.prior.eval(theta_samp, log=True) - g.proposal.eval(theta_samp, log=True))\n",
    "\n",
    "# Draw true posterior\n",
    "plt.scatter(x_samp, theta_samp.flatten(), color='0.05', s=5,alpha=0.4)\n",
    "\n",
    "# Draw posterior means (in orange)\n",
    "std_col = plt.get_cmap(\"tab10\")(0)\n",
    "\n",
    "std_col = 'gray'\n",
    "\n",
    "plt.plot(xs,post_means, c=std_col, label='posterior', alpha=0.5)\n",
    "plt.plot(xs,post_means + 2 * np.sqrt(post_vars),ls='--', c=std_col, alpha=0.5)\n",
    "plt.plot(xs,post_means - 2 * np.sqrt(post_vars),ls='--', c=std_col, alpha=0.5)\n",
    "\n",
    "plt.fill_between(xs,post_means-2 * np.sqrt(post_vars),\n",
    "                 post_means+2 * np.sqrt(post_vars), facecolor=std_col,\n",
    "                 alpha=0.15)\n",
    "\n",
    "\n",
    "# Draw vertical lines around chosen point\n",
    "axm.axvline(xobs,lw=2, c='k')\n",
    "\n",
    "\n",
    "axm.set_xlim(xlims)\n",
    "axm.set_ylim(theta_lims)\n",
    "axm.set_xticks([])\n",
    "axm.set_yticks([])\n",
    "axm.spines['top'].set_visible(False)\n",
    "axm.spines['right'].set_visible(False)\n",
    "\n",
    "axm.set_xlabel(\"$x$\", fontsize=fontsize)\n",
    "plt.xticks([xobs], [r'$x_{o}$'], fontsize=fontsize)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('CDE_with_prior.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# figures on different proposals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = '/home/marcel/Dropbox (mackelab)/team/Write/Posters/2018_Edinburgh/figures/col1/'\n",
    "from scipy.misc import logsumexp\n",
    "\n",
    "N = 1000\n",
    "N_show = 100\n",
    "\n",
    "seed = 47\n",
    "\n",
    "fig = plt.figure(figsize=(11.25,9))\n",
    "gs = gridspec.GridSpec(2, 3, width_ratios=[1,3,3], height_ratios=[4,1])\n",
    "\n",
    "from sklearn.neighbors.kde import KernelDensity\n",
    "\n",
    "def compute_marginals(prop, prior=None, N=1000):\n",
    "    thetas = prop.gen(N)\n",
    "    \n",
    "    means = g.model.get_means(thetas)\n",
    "    \n",
    "    ret = means + np.sqrt(noise_var) * np.random.normal(size=thetas.shape)\n",
    "    \n",
    "    if prior is None:\n",
    "        return ret\n",
    "    else:\n",
    "        iws = prior.eval(thetas, log=True) - prop.eval(thetas, log=True)\n",
    "        iws = np.exp( iws - logsumexp(iws) ) \n",
    "        return ret, iws\n",
    "\n",
    "def init_g(seed):\n",
    "    \n",
    "\n",
    "    m = ForwardModel(seed=seed)\n",
    "    prior = dd.Gaussian(m=[prior_mean], S=[[prior_var]], seed=seed+1)\n",
    "    prop_prior = dd.Gaussian(m=[prop_prior_mean], S=[[prop_prior_var]], seed=seed+2)\n",
    "    s = ds.Identity(1)\n",
    "\n",
    "    return dg.Default(m, prior, s, seed=seed+3)\n",
    "\n",
    "p_true = dd.Gaussian(m=0.8*np.ones(1), S=0.05*np.eye(1), seed = seed)\n",
    "obs_stats = 0.84343267 * np.ones((1,1))\n",
    "\n",
    "sig2s = np.linspace(np.sqrt(0.05), np.sqrt(0.5), 100)**2\n",
    "sig2s = sig2s[::-1][[25, 50, 75, 99]]\n",
    "ms    = np.linspace(0.8, 2., 100)\n",
    "ms    = ms[::-1][[25, 50, 75, 99]]\n",
    "\n",
    "\n",
    "clrs = ['g', 'c',  'm', 'r']\n",
    "linewidth=3.\n",
    "\n",
    "theta_lims = [0, 3]\n",
    "xx = np.linspace(theta_lims[0], theta_lims[1], 500).reshape(-1,1)\n",
    "g = init_g(seed)\n",
    "xlims = [0, g.model.get_means(theta_lims[1]) * 1.1]\n",
    "\n",
    "\n",
    "ax = plt.subplot(gs[0,1])\n",
    "std_col = 'gray'\n",
    "ax.plot(xs,post_means, c=std_col, label='posterior')\n",
    "ax.plot(xs,post_means + 2 * np.sqrt(post_vars),ls='--', c=std_col)\n",
    "ax.plot(xs,post_means - 2 * np.sqrt(post_vars),ls='--', c=std_col)\n",
    "plt.fill_between(xs,post_means-2 * np.sqrt(post_vars),\n",
    "                 post_means+2 * np.sqrt(post_vars), facecolor=std_col,\n",
    "                 alpha=0.15)\n",
    "\n",
    "\n",
    "for i in range(len(sig2s)):\n",
    "    \n",
    "    sig2 = sig2s[i]\n",
    "    m = ms[i]\n",
    "    p_prop = dd.Gaussian(m=m*np.ones(1), S = sig2*np.eye(1), seed=seed+1234+i)\n",
    "\n",
    "    g = init_g(seed)\n",
    "    g.proposal = p_prop\n",
    "    trn_data = g.gen(N)\n",
    "\n",
    "    print('Var[th] = ', trn_data[0].var())\n",
    "\n",
    "    ax = plt.subplot(gs[0,0])\n",
    "    ax.plot(  p_prop.eval(xx, log=False), xx, '-', color=clrs[i], linewidth=linewidth)\n",
    "\n",
    "    ax = plt.subplot(gs[0,1])\n",
    "    x_samp, theta_samp = trn_data[1][:N_show], trn_data[0][:N_show]\n",
    "    #ax.plot( x_samp, theta_samp, '.', color=clrs[i])    \n",
    "    iws = np.exp(g.prior.eval(theta_samp, log=True) - g.proposal.eval(theta_samp, log=True))\n",
    "    iws /= iws.sum()\n",
    "    ax.scatter(x_samp, theta_samp.flatten(), color=clrs[i], s=30 * np.log((1.1 - np.min(iws)) + 50*iws), alpha=0.4)\n",
    "    \n",
    "    liws = (g.prior.eval(trn_data[0]) - g.proposal.eval(trn_data[0]))\n",
    "    iws = np.exp(liws - logsumexp(liws))\n",
    "        \n",
    "    prop_prior_marg_samples, marg_iws = compute_marginals(g.proposal, g.prior)\n",
    "    prop_prior_marg_density = KernelDensity(kernel='gaussian', \n",
    "                                           bandwidth=0.05 * (xlims[1] - xlims[0])).fit(prop_prior_marg_samples)\n",
    "    iw_marg_density = KernelDensity(kernel='gaussian', \n",
    "                                    bandwidth=0.05 * (xlims[1] - xlims[0])).fit(prop_prior_marg_samples, \n",
    "                                                                                sample_weight=marg_iws)\n",
    "    ax = plt.subplot(gs[1,1])\n",
    "    ax.plot(xs, np.exp(iw_marg_density.score_samples(xs.reshape(-1,1))),  color=clrs[i], \n",
    "            label='importance weighted', linewidth=linewidth)    \n",
    "    ax = plt.subplot(gs[1,2])\n",
    "    ax.plot(xs, np.exp(prop_prior_marg_density.score_samples(xs.reshape(-1,1))), \n",
    "            c=clrs[i], alpha=0.5, label='proposal prior', linewidth=linewidth/2)\n",
    "    \n",
    "    \n",
    "ax = plt.subplot(gs[0,0])\n",
    "#ax.plot( p_true.eval(xx, log=False), xx, '-', color='k')\n",
    "ax.plot( g.prior.eval(xx, log=False), xx, '--', color='b', linewidth=linewidth)\n",
    "plt.ylabel(r'$\\theta$', fontsize=fontsize)\n",
    "plt.xlabel('density', fontsize=fontsize)\n",
    "#plt.box('off')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.yticks([])\n",
    "plt.xticks([])\n",
    "ax.set_ylim(theta_lims)\n",
    "\n",
    "ax = plt.subplot(gs[0,1])\n",
    "#plt.box('off')\n",
    "plt.xticks([xobs], [r'$x_{o}$'], fontsize=fontsize)\n",
    "plt.yticks([])\n",
    "ax.set_ylim(theta_lims)\n",
    "ax.set_xlim(xlims)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.axvline(xobs, lw=2, c='k')\n",
    "\n",
    "\n",
    "ax = plt.subplot(gs[1,1])\n",
    "prior_marg_samples = compute_marginals(g.prior)\n",
    "prior_marg_density = KernelDensity(kernel='gaussian', \n",
    "                                   bandwidth=0.05 * (xlims[1] - xlims[0])).fit(prior_marg_samples)\n",
    "ax.plot(xs, np.exp(prior_marg_density.score_samples(xs.reshape(-1,1))), '--', c='b', label='prior', linewidth=3)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_xlim(xlims)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "ax.axvline(xobs, lw=2, c='k')\n",
    "plt.ylabel('density', fontsize=fontsize)\n",
    "plt.xlabel(\"$x$\", fontsize=fontsize)\n",
    "plt.xticks([xobs], [r'$x_{o}$'], fontsize=fontsize)\n",
    "\n",
    "ax = plt.subplot(gs[1,2])\n",
    "prior_marg_samples = compute_marginals(g.prior)\n",
    "prior_marg_density = KernelDensity(kernel='gaussian', \n",
    "                                   bandwidth=0.05 * (xlims[1] - xlims[0])).fit(prior_marg_samples)\n",
    "ax.plot(xs, np.exp(prior_marg_density.score_samples(xs.reshape(-1,1))), '--', c='b', label='prior', linewidth=3)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_xlim(xlims)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "ax.axvline(xobs, lw=2, c='k')\n",
    "plt.ylabel('density', fontsize=fontsize)\n",
    "plt.ylabel('density', fontsize=fontsize)\n",
    "plt.xlabel(\"$x$\", fontsize=fontsize)\n",
    "plt.xticks([xobs], [r'$x_{o}$'], fontsize=fontsize)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(path + 'narrowness_vs_ess.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = '/home/marcel/Dropbox (mackelab)/team/Write/Posters/2018_Edinburgh/figures/col1/'\n",
    "from scipy.misc import logsumexp\n",
    "\n",
    "N = 1000\n",
    "N_show = 100\n",
    "\n",
    "seed = 47\n",
    "\n",
    "fig = plt.figure(figsize=(4.5, 4.5))\n",
    "gs = gridspec.GridSpec(1,1, width_ratios=[1], height_ratios=[1])\n",
    "\n",
    "from sklearn.neighbors.kde import KernelDensity\n",
    "\n",
    "def compute_marginals(prop, prior=None, N=10000):\n",
    "    thetas = prop.gen(N)\n",
    "    \n",
    "    means = g.model.get_means(thetas)\n",
    "    \n",
    "    ret = means + np.sqrt(noise_var) * np.random.normal(size=thetas.shape)\n",
    "    \n",
    "    if prior is None:\n",
    "        return ret\n",
    "    else:\n",
    "        iws = prior.eval(thetas, log=True) - prop.eval(thetas, log=True)\n",
    "        iws = np.exp( iws - logsumexp(iws) ) \n",
    "        return ret, iws\n",
    "\n",
    "def init_g(seed):\n",
    "    \n",
    "\n",
    "    m = ForwardModel(seed=seed)\n",
    "    prior = dd.Gaussian(m=[prior_mean], S=[[prior_var]], seed=seed+1)\n",
    "    prop_prior = dd.Gaussian(m=[prop_prior_mean], S=[[prop_prior_var]], seed=seed+2)\n",
    "    s = ds.Identity(1)\n",
    "\n",
    "    return dg.Default(m, prior, s, seed=seed+3)\n",
    "\n",
    "p_true = dd.Gaussian(m=0.8*np.ones(1), S=0.05*np.eye(1), seed = seed)\n",
    "obs_stats = 0.84343267 * np.ones((1,1))\n",
    "\n",
    "sig2s = np.linspace(np.sqrt(0.05), np.sqrt(0.5), 100)**2\n",
    "sig2s = sig2s[::-1][[25, 50, 75, 99]]\n",
    "ms    = np.linspace(0.8, 2., 100)\n",
    "ms    = ms[::-1][[25, 50, 75, 99]]\n",
    "\n",
    "\n",
    "clrs = ['g', 'c',  'm', 'r']\n",
    "linewidth=3.\n",
    "\n",
    "theta_lims = [0, 3]\n",
    "xx = np.linspace(theta_lims[0], theta_lims[1], 500).reshape(-1,1)\n",
    "g = init_g(seed)\n",
    "xlims = [0, g.model.get_means(theta_lims[1]) * 1.1]\n",
    "\n",
    "\n",
    "ax = plt.subplot(gs[0,0])\n",
    "ax.plot([1,N],[0,1], 'b--', label='prior', linewidth=linewidth)\n",
    "\n",
    "\n",
    "for i in range(len(sig2s)):\n",
    "    \n",
    "    sig2 = sig2s[i]\n",
    "    m = ms[i]\n",
    "    p_prop = dd.Gaussian(m=m*np.ones(1), S = sig2*np.eye(1), seed=seed+1234+i)\n",
    "\n",
    "    g = init_g(seed)\n",
    "    g.proposal = p_prop\n",
    "    trn_data = g.gen(N)\n",
    "\n",
    "    print('Var[th] = ', trn_data[0].var())\n",
    "    \n",
    "    ax = plt.subplot(gs[0,0])    \n",
    "    liws = (g.prior.eval(trn_data[0]) - g.proposal.eval(trn_data[0]))\n",
    "    iws = np.exp(liws - logsumexp(liws))\n",
    "    ax.plot(np.arange(iws.size)+1, np.cumsum(np.sort(iws)[::-1]), '-', color=clrs[i], linewidth=linewidth)\n",
    "    \n",
    "    ESS = 1./np.sum( (iws/iws.sum())**2 )\n",
    "    \n",
    "    if ESS > 100:\n",
    "        plt.text(N/2, (len(sig2s)-i-1)*0.1, str(np.round(ESS*10)/(10)), color=clrs[i], fontsize=fontsize)\n",
    "    else:\n",
    "        plt.text(N/2, (len(sig2s)-i-1)*0.1, str(np.round(ESS*100)/(100)), color=clrs[i], fontsize=fontsize)\n",
    "            \n",
    "\n",
    "ax = plt.subplot(gs[0,0])\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.xticks([1, N], ['1', 'N'], fontsize=fontsize)\n",
    "plt.yticks([0, 0.5, 1.], fontsize=fontsize)\n",
    "plt.text(N/2, (len(sig2s))*0.1, 'ESS (out of N='+str(N)+'):', color='k', fontsize=fontsize)\n",
    "plt.xlabel('number of samples (sorted)', fontsize=fontsize)\n",
    "plt.ylabel('cumulative importance weights', fontsize=fontsize)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(path + 'narrowness_vs_ess_inset.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import abc\n",
    "from delfi.utils.meta import ABCMetaDoc\n",
    "class My_Helper_Kernel(metaclass=ABCMetaDoc):\n",
    "    def __init__(self, obs, A, Z):\n",
    "        \"\"\"Temporary substitute for working Gaussian kernel class in delfi\n",
    "        Parameters\n",
    "        ----------\n",
    "        obs : 1 x dim\n",
    "            center of kernel\n",
    "        A : dim x dim or dim\n",
    "            kernel matrix (cf. precision matrix for Gaussian distributions)\n",
    "        Z : kernel log-normalizer\n",
    "        -----\n",
    "        Notes:\n",
    "        k(x) = exp( - (x-obs)' A (x-obs) + Z )\n",
    "        \"\"\"\n",
    "\n",
    "        assert obs.shape[0] == 1, 'obs.shape[0] must be 1'\n",
    "        assert obs.shape[1] >= 1, 'obs.shape[1] must be >= 1'\n",
    "\n",
    "        self.dim = obs.shape[1]\n",
    "        self.obs = obs\n",
    "\n",
    "        self.diag_A = False if A.ndim>1 else True        \n",
    "        self.A = A\n",
    "        self.Z = Z\n",
    "\n",
    "        if self.diag_A:\n",
    "            self.B = np.sqrt(A)\n",
    "        else:\n",
    "            self.B = np.linalg.cholesky(A)\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def kernel(u):\n",
    "        pass        \n",
    "\n",
    "\n",
    "    def eval(self, x):\n",
    "        \"\"\"Kernel for loss calibration\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : N x dim\n",
    "            points at which to evaluate kernel\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        weights : N x 1\n",
    "            normalized to be 1. for x = obs\n",
    "        \"\"\"\n",
    "        assert x.shape[0] >= 1, 'x.shape[0] needs to be >= 1'\n",
    "        assert x.shape[1] == self.dim, 'x.shape[1] needs to be == self.obs'\n",
    "\n",
    "        if self.diag_A:\n",
    "            z = (x-self.obs) * self.B.reshape(1,-1)\n",
    "            out = np.exp( -(z*z).sum(axis=1) + self.Z)\n",
    "        else:\n",
    "            z = (x-self.obs).dot(self.B)\n",
    "            out = np.exp( -(z*z).sum(axis=1) + self.Z)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.misc import logsumexp\n",
    "from delfi.kernel.Kernel_learning import kernel_opt\n",
    "\n",
    "\n",
    "path = '/home/marcel/Dropbox (mackelab)/team/Write/Posters/2018_Edinburgh/figures/col3/'\n",
    "N = 1000\n",
    "N_show = 1000\n",
    "\n",
    "\n",
    "gs = gridspec.GridSpec(1, 4, width_ratios=[2,4,5,4], height_ratios=[1])\n",
    "\n",
    "def init_g(seed):\n",
    "    \n",
    "\n",
    "    m = ForwardModel(seed=seed)\n",
    "    prior = dd.Gaussian(m=[prior_mean], S=[[prior_var]], seed=seed+1)\n",
    "    prop_prior = dd.Gaussian(m=[prop_prior_mean], S=[[prop_prior_var]], seed=seed+2)\n",
    "    s = ds.Identity(1)\n",
    "\n",
    "    return dg.Default(m, prior, s, seed=seed+3)\n",
    "\n",
    "p_true = dd.Gaussian(m=0.8*np.ones(1), S=0.05*np.eye(1), seed = seed)\n",
    "obs_stats = 0.84343267 * np.ones((1,1))\n",
    "\n",
    "\n",
    "sig2s = np.linspace(np.sqrt(0.05), np.sqrt(0.5), 100)**2\n",
    "sig2s = sig2s[::-1][[25, 50, 75, 99]]\n",
    "ms    = np.linspace(0.8, 2., 100)\n",
    "ms    = ms[::-1][[25, 50, 75, 99]]\n",
    "\n",
    "taus = np.linspace(0.001, 0.8, 801)\n",
    "\n",
    "seed = 47\n",
    "\n",
    "fig = plt.figure(figsize=(18,7.5))\n",
    "\n",
    "#ms, sig2s = [ms[-1]], [sig2s[-1]]\n",
    "\n",
    "clrs = ['g', 'c',  'm', 'r']\n",
    "\n",
    "theta_lims = [0, 3]\n",
    "xx = np.linspace(theta_lims[0], theta_lims[1], 500).reshape(-1,1)\n",
    "g = init_g(seed)\n",
    "xlims = [0, g.model.get_means(theta_lims[1]) * 1.1]\n",
    "\n",
    "for i in range(len(sig2s)):\n",
    "\n",
    "    sig2 = sig2s[i]\n",
    "    m = ms[i]\n",
    "    p_prop = dd.Gaussian(m=m*np.ones(1), S = sig2*np.eye(1), seed=seed+1234+i)\n",
    "\n",
    "    g = init_g(seed)\n",
    "    g.proposal = p_prop\n",
    "    trn_data = g.gen(N)\n",
    "\n",
    "    print('Var[th] = ', trn_data[0].var())\n",
    "\n",
    "    ax = plt.subplot(gs[0,0])\n",
    "    ax.plot(  p_prop.eval(xx, log=False), xx, '-', color=clrs[i], linewidth=linewidth)\n",
    "\n",
    "    ax = plt.subplot(gs[0,1])\n",
    "\n",
    "    liws = (g.prior.eval(trn_data[0]) - g.proposal.eval(trn_data[0]))\n",
    "    iws = np.exp(liws - logsumexp(liws))    \n",
    "\n",
    "    ESS = 1./np.sum( (iws/iws.sum())**2 )\n",
    "\n",
    "    dists = np.sqrt( np.sum( (trn_data[1] - obs_stats)**2, axis=1) )\n",
    "    ax.plot( dists[:N_show], liws[:N_show], 'o', color=clrs[i])\n",
    "    plt.xlabel(\"$|| x - x_o ||$\", fontsize=fontsize)\n",
    "    plt.ylabel('log importance weights', fontsize=fontsize)\n",
    "\n",
    "    kESS = np.zeros(taus.size)\n",
    "    kcbl = np.zeros(taus.size)\n",
    "    for j in range(len(taus)): \n",
    "\n",
    "        cbk = My_Helper_Kernel(obs=obs_stats, Z=np.zeros(1), A=(1./taus[j])**2*np.ones(1)).eval(trn_data[1])\n",
    "        kiws = iws * cbk\n",
    "        kESS[j] = 1./np.sum( (kiws/kiws.sum())**2 )\n",
    "        \n",
    "        kcbl[j] = - np.mean(np.log(cbk)) + np.log(np.mean(kiws))\n",
    "\n",
    "    cbkrnl, cbl = kernel_opt(\n",
    "        iws=iws.astype(np.float32), \n",
    "        stats=trn_data[1].reshape(-1,1).astype(np.float32),\n",
    "        obs=obs_stats.reshape(1,1).astype(np.float32), \n",
    "        kernel_loss='x_kl', \n",
    "        epochs=10000, #epochs \n",
    "        minibatch=1000, #minibatch, \n",
    "        stop_on_nan=False,\n",
    "        seed=42, \n",
    "        monitor=None)\n",
    "        \n",
    "    ax = plt.subplot(gs[0,2])\n",
    "    ax.plot(taus, kESS, color=clrs[i], linewidth=3.0)\n",
    "    ax.plot([0.91, 0.93], [ESS, ESS], color=clrs[i], linewidth=3.0)\n",
    "\n",
    "    txt_offsets = [-5, -5, -5, -5]\n",
    "\n",
    "    if ESS > 100:\n",
    "        ax.text(0.95, ESS+txt_offsets[i], str(np.round(ESS*10)/(10)), color=clrs[i], fontsize=fontsize)\n",
    "    else:\n",
    "        ax.text(0.95, ESS+txt_offsets[i], str(np.round(ESS*100)/(100)), color=clrs[i], fontsize=fontsize)\n",
    "\n",
    "\n",
    "\n",
    "    tau_est = 1./cbkrnl.B\n",
    "    \n",
    "    if i == 2:\n",
    "        tau_plot = tau_est\n",
    "    \n",
    "    idx = np.argmin(np.abs(tau_est - taus))\n",
    "\n",
    "    ax.plot(tau_est, kESS[idx]+10, 'v', color=clrs[i], markersize=12, markerfacecolor=clrs[i],\n",
    "             markeredgewidth=1., markeredgecolor='k')\n",
    "\n",
    "    ax = plt.subplot(gs[0,3])    \n",
    "    ax.plot(taus, kcbl, color=clrs[i], linewidth=3.0)\n",
    "    ax.plot(tau_est, kcbl[idx]+0.015, 'v', color=clrs[i], markersize=12, markerfacecolor=clrs[i],\n",
    "             markeredgewidth=1., markeredgecolor='k')\n",
    "    \n",
    "    \n",
    "ax = plt.subplot(gs[0,0])\n",
    "ax.plot( g.prior.eval(xx, log=False), xx, '--', color='b')\n",
    "plt.ylabel(r'$\\theta$', fontsize=fontsize)\n",
    "plt.xlabel('density', fontsize=fontsize)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.yticks([])\n",
    "plt.xticks([])\n",
    "ax.set_ylim(theta_lims)\n",
    "\n",
    "ax = plt.subplot(gs[0,1])\n",
    "plt.yticks([])\n",
    "plt.xticks([0., 0.2, 0.4, 0.6, 0.8], fontsize=fontsize)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.axis([-0.01, 0.81, np.min(liws[:N_show])*1.01, np.max(liws[:N_show])*1.01])\n",
    "\n",
    "xx = np.linspace(0, 0.8, 801).reshape(-1,1)\n",
    "cbk = My_Helper_Kernel(obs=0*obs_stats, Z=np.ones(1), A=(1./tau_plot)**2*np.ones(1)).eval(xx)\n",
    "ax.plot(xx, np.log(cbk), 'k', linewidth=linewidth+0.5)\n",
    "ax.plot(xx, np.log(cbk), 'm', linewidth=linewidth-0.5)\n",
    "\n",
    "ax = plt.subplot(gs[0,2])\n",
    "plt.xticks([0., 0.2, 0.4, 0.6, 0.8, 0.92], \n",
    "           ['0', '0.2', '0.4', '0.6', '0.8', r'$\\infty$'], fontsize=fontsize)\n",
    "plt.yticks(np.array([0., 0.2, 0.4, 0.6, 0.8, 1.0])*N, fontsize=fontsize)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.xlabel('kernel bandwidth ' + r'$\\tau$', fontsize=fontsize)\n",
    "plt.ylabel('effective sample size', fontsize=fontsize)\n",
    "plt.axis([-0.01, 1.06, 0, N+1])\n",
    "\n",
    "ax = plt.subplot(gs[0,3])\n",
    "plt.xticks([0., 0.2, 0.4, 0.6, 0.8], \n",
    "           ['0', '0.2', '0.4', '0.6', '0.8'], fontsize=fontsize)\n",
    "plt.yticks(np.array([-7.4, -7., -6.6, -6.2]), fontsize=fontsize)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.xlabel('kernel bandwidth ' + r'$\\tau$', fontsize=fontsize)\n",
    "plt.ylabel(r'$\\mathcal{L}(\\tau)$', fontsize=fontsize)\n",
    "plt.axis([-0.01, 0.81, -7.5, -6])\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(path + 'importance_weights_vs_distance.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.misc import logsumexp\n",
    "from delfi.kernel.Kernel_learning import kernel_opt\n",
    "\n",
    "\n",
    "path = '/home/marcel/Dropbox (mackelab)/team/Write/Posters/2018_Edinburgh/figures/col3/'\n",
    "N = 1000\n",
    "N_show = 1000\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(9,2.5))\n",
    "gs = gridspec.GridSpec(1, 2, width_ratios=[1,1], height_ratios=[1])\n",
    "\n",
    "def init_g(seed):\n",
    "    \n",
    "\n",
    "    m = ForwardModel(seed=seed)\n",
    "    prior = dd.Gaussian(m=[prior_mean], S=[[prior_var]], seed=seed+1)\n",
    "    prop_prior = dd.Gaussian(m=[prop_prior_mean], S=[[prop_prior_var]], seed=seed+2)\n",
    "    s = ds.Identity(1)\n",
    "\n",
    "    return dg.Default(m, prior, s, seed=seed+3)\n",
    "\n",
    "\n",
    "p_true = dd.Gaussian(m=0.8*np.ones(1), S=0.05*np.eye(1), seed = seed)\n",
    "obs_stats = 0.84343267 * np.ones((1,1))\n",
    "\n",
    "\n",
    "sig2s = np.linspace(np.sqrt(0.05), np.sqrt(0.5), 100)**2\n",
    "sig2s = sig2s[::-1][[25, 50, 75, 99]]\n",
    "ms    = np.linspace(0.8, 2., 100)\n",
    "ms    = ms[::-1][[25, 50, 75, 99]]\n",
    "\n",
    "taus = np.linspace(0.001, 0.8, 801)\n",
    "\n",
    "seed = 47\n",
    "\n",
    "\n",
    "#ms, sig2s = [ms[-1]], [sig2s[-1]]\n",
    "\n",
    "clrs = ['g', 'c',  'm', 'r']\n",
    "\n",
    "theta_lims = [0, 3]\n",
    "xx = np.linspace(xlims[0], xlims[1], 500).reshape(-1,1)\n",
    "g = init_g(seed)\n",
    "xlims = [0, g.model.get_means(theta_lims[1]) * 1.1]\n",
    "\n",
    "for i in range(len(sig2s)):\n",
    "\n",
    "    sig2 = sig2s[i]\n",
    "    m = ms[i]\n",
    "    p_prop = dd.Gaussian(m=m*np.ones(1), S = sig2*np.eye(1), seed=seed+1234+i)\n",
    "\n",
    "    g = init_g(seed)\n",
    "    g.proposal = p_prop\n",
    "    trn_data = g.gen(N)\n",
    "\n",
    "    print('Var[th] = ', trn_data[0].var())\n",
    "\n",
    "    ax = plt.subplot(gs[0,0])\n",
    "\n",
    "    liws = (g.prior.eval(trn_data[0]) - g.proposal.eval(trn_data[0]))\n",
    "    iws = np.exp(liws - logsumexp(liws))    \n",
    "\n",
    "    cbkrnl, cbl = kernel_opt(\n",
    "        iws=iws.astype(np.float32), \n",
    "        stats=trn_data[1].reshape(-1,1).astype(np.float32),\n",
    "        obs=obs_stats.reshape(1,1).astype(np.float32), \n",
    "        kernel_loss='x_kl', \n",
    "        epochs=10000, #epochs \n",
    "        minibatch=1000, #minibatch, \n",
    "        stop_on_nan=False,\n",
    "        seed=42, \n",
    "        monitor=None)\n",
    "\n",
    "    tau_est = 1./cbkrnl.B\n",
    "\n",
    "    prop_prior_marg_samples, marg_iws = compute_marginals(g.proposal, g.prior)\n",
    "    cbk = cbkrnl.eval(prop_prior_marg_samples)\n",
    "    marg_kiws = marg_iws * cbk\n",
    "    \n",
    "    prop_prior_marg_density = KernelDensity(kernel='gaussian', \n",
    "                                           bandwidth=0.05 * (xlims[1] - xlims[0])).fit(prop_prior_marg_samples)\n",
    "    iw_marg_density = KernelDensity(kernel='gaussian', \n",
    "                                    bandwidth=0.05 * (xlims[1] - xlims[0])).fit(prop_prior_marg_samples, \n",
    "                                                                                sample_weight=marg_iws)\n",
    "    ax = plt.subplot(gs[0,0])\n",
    "    ax.plot(xs, np.exp(iw_marg_density.score_samples(xs.reshape(-1,1))),  color=clrs[i], \n",
    "            label='importance weighted', linewidth=linewidth)        \n",
    "    ax = plt.subplot(gs[0,0])\n",
    "    ax.plot(xs, np.exp(prop_prior_marg_density.score_samples(xs.reshape(-1,1))), \n",
    "            c=clrs[i], alpha=0.5, label='proposal prior', linewidth=linewidth/2)\n",
    "    \n",
    "    \n",
    "    kiw_marg_density = KernelDensity(kernel='gaussian', \n",
    "                                    bandwidth=0.05 * (xlims[1] - xlims[0])).fit(prop_prior_marg_samples, \n",
    "                                                                                sample_weight=marg_kiws)\n",
    "    ax = plt.subplot(gs[0,1])\n",
    "    ax.plot(xs, np.exp(kiw_marg_density.score_samples(xs.reshape(-1,1))),  color=clrs[i], \n",
    "            label='importance weighted', linewidth=linewidth)    \n",
    "    ax = plt.subplot(gs[0,1])\n",
    "    ax.plot(xs, np.exp(prop_prior_marg_density.score_samples(xs.reshape(-1,1))), \n",
    "            c=clrs[i], alpha=0.5, label='proposal prior', linewidth=linewidth/2)\n",
    "    \n",
    "    \n",
    "for i in range(2):\n",
    "    ax = plt.subplot(gs[0,i])\n",
    "    prior_marg_samples = compute_marginals(g.prior)\n",
    "    prior_marg_density = KernelDensity(kernel='gaussian', \n",
    "                                       bandwidth=0.05 * (xlims[1] - xlims[0])).fit(prior_marg_samples)\n",
    "    ax.plot(xs, np.exp(prior_marg_density.score_samples(xs.reshape(-1,1))), '--', c='b', label='prior', linewidth=3)\n",
    "    ax.axvline(xobs, lw=2, c='k')\n",
    "    plt.ylabel('density', fontsize=fontsize)\n",
    "    ax.set_xlabel(\"$x$\", fontsize=fontsize)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    #plt.yticks([])\n",
    "    plt.xticks([xobs], [r'$x_{o}$'], fontsize=fontsize)\n",
    "    ax.set_xlim(xlims)\n",
    "    #ax.set_ylim([0, ])\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(path + 'recovered_locality.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
