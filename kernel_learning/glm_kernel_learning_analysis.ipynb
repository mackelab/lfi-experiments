{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## learning kernels for the GLM example. \n",
    "\n",
    "we optimize kernels such that\n",
    "$ K(x_n, x_0) p(\\theta_n) / \\tilde{p}(\\theta_n) \\approx 1$. \n",
    "\n",
    "Spoiler:\n",
    "starts to work.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# approach\n",
    "\n",
    "The above problem doesn't require MDNs at all. \n",
    "Once prior, proposal, kernel and simulator are fixed and we drew an artificial dataset $(x_n, \\theta_n)$, we're good to play. \n",
    "Let's run SNPE as usual, note down the data-sets $(x_n, \\theta_n)$, proposal priors and importance weights it produced over rounds, and afterwards play with the kernel on those fixed targets. \n",
    "\n",
    "- Remark: results look a lot worse if we convert to Students-t distributions. Could be that kernel shape (squared-exponential in $x$) has to match proposal-prior shape (squared in $\\theta$ for students-T with df=3)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1. basic squared loss\n",
    "\n",
    "argmin $ \\sum_n \\left( 1 - \\frac{K(x_n, x_0) p(\\theta_n)}{\\tilde{p}(\\theta_n)} \\right)^2 $, emphasizing the absolute value of $\\approx 1$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import delfi.distribution as dd\n",
    "import delfi.generator as dg\n",
    "import delfi.inference as infer\n",
    "import delfi.utils.io as io\n",
    "import delfi.summarystats as ds\n",
    "import lfimodels.glm.utils as utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from lfimodels.glm.GLM import GLM\n",
    "from lfimodels.glm.GLMStats import GLMStats\n",
    "from delfi.utils.viz import plot_pdf\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def d_kl_gauss(m1, m2, S1, S2):\n",
    "   \n",
    "    S2i = np.linalg.inv(S2)\n",
    "    dm =  m2 - m1\n",
    "   \n",
    "    out  = np.trace(S2i.dot(S1))\n",
    "    out += dm.dot(S2i.dot(dm))\n",
    "    out -= m1.size\n",
    "    out += np.prod(np.linalg.slogdet(S2)) - np.prod(np.linalg.slogdet(S1))\n",
    "    return out / 2.\n",
    "\n",
    "\n",
    "seeds = np.arange(90, 110)\n",
    "duration = 250\n",
    "\n",
    "posteriors_s = []\n",
    "\n",
    "for seed in seeds:\n",
    "    true_params, labels_params = utils.obs_params()\n",
    "    obs = utils.obs_data(true_params, seed=seed, duration = duration)\n",
    "    obs_stats = utils.obs_stats(true_params, seed=seed, duration = duration)\n",
    "\n",
    "    sam = np.load('sam_' + str(duration) + '_' + str(seed) + '.npz')['arr_0']\n",
    "    \n",
    "    res  = np.load('check_kernels_d' + str(duration) + '_' + str(seed) + '.npy')[()]\n",
    "\n",
    "    ms = sam.mean(axis=1)\n",
    "    Ss = np.cov(sam)    \n",
    "    posteriors_s.append(dd.Gaussian(m=ms, S=Ss))    \n",
    "    \n",
    "    # run with Gaussian proposals\n",
    "    \n",
    "    print('\\n seed #' + str(seed) + '\\n')\n",
    "    posteriors = res['posteriors']\n",
    "    posteriors_k = res['posteriors_k']\n",
    "    posteriors_k2 = res['posteriors_k2']\n",
    "    \n",
    "    if posteriors[-1] is None:\n",
    "        posteriors.pop()\n",
    "    \n",
    "    print('vanilla #succesful rounds: ', len(posteriors))\n",
    "    print('x_kl    #succesful rounds: ', len(posteriors_k))\n",
    "    print('max_ESS #succesful rounds: ', len(posteriors_k2))\n",
    "\n",
    "    plot_pdf(posteriors[-1],\n",
    "             pdf2=posteriors_k[-1], \n",
    "             resolution=100,\n",
    "             lims=[-2,2], \n",
    "             samples=sam, \n",
    "             gt=true_params, \n",
    "             figsize=(9,9));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import delfi.distribution as dd\n",
    "import delfi.generator as dg\n",
    "import delfi.inference as infer\n",
    "import delfi.utils.io as io\n",
    "import delfi.summarystats as ds\n",
    "import lfimodels.glm.utils as utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from lfimodels.glm.GLM import GLM\n",
    "from lfimodels.glm.GLMStats import GLMStats\n",
    "from delfi.utils.viz import plot_pdf\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def d_kl_gauss(m1, m2, S1, S2):\n",
    "   \n",
    "    S2i = np.linalg.inv(S2)\n",
    "    dm =  m2 - m1\n",
    "   \n",
    "    out  = np.trace(S2i.dot(S1))\n",
    "    out += dm.dot(S2i.dot(dm))\n",
    "    out -= m1.size\n",
    "    out += np.prod(np.linalg.slogdet(S2)) - np.prod(np.linalg.slogdet(S1))\n",
    "    return out / 2.\n",
    "\n",
    "\n",
    "seeds = np.arange(90, 110)\n",
    "duration = 100\n",
    "\n",
    "posteriors_s = []\n",
    "\n",
    "for seed in seeds:\n",
    "    true_params, labels_params = utils.obs_params()\n",
    "    obs = utils.obs_data(true_params, seed=seed, duration = duration)\n",
    "    obs_stats = utils.obs_stats(true_params, seed=seed, duration = duration)\n",
    "\n",
    "    sam = np.load('sam_' + str(duration) + '_' + str(seed) + '.npz')['arr_0']\n",
    "    \n",
    "    res  = np.load('check_kernels_d' + str(duration) + '_' + str(seed) + '.npy')[()]\n",
    "\n",
    "    ms = sam.mean(axis=1)\n",
    "    Ss = np.cov(sam)    \n",
    "    posteriors_s.append(dd.Gaussian(m=ms, S=Ss))    \n",
    "    \n",
    "    # run with Gaussian proposals\n",
    "    \n",
    "    print('\\n seed #' + str(seed) + '\\n')\n",
    "    posteriors = res['posteriors']\n",
    "    posteriors_k = res['posteriors_k']\n",
    "    posteriors_k2 = res['posteriors_k2']\n",
    "    \n",
    "    if posteriors[-1] is None:\n",
    "        posteriors.pop()\n",
    "    \n",
    "    print('vanilla #succesful rounds: ', len(posteriors))\n",
    "    print('x_kl    #succesful rounds: ', len(posteriors_k))\n",
    "    print('max_ESS #succesful rounds: ', len(posteriors_k2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn \n",
    "\n",
    "dkls = np.zeros((len(seeds), 3))\n",
    "dklsa = np.nan * np.ones((len(seeds), 3, res['n_rounds']))\n",
    "BAM = np.nan * np.ones_like(dklsa)\n",
    "\n",
    "ess = np.zeros((len(seeds), 3, res['n_rounds']))\n",
    "mu_   = np.zeros((len(seeds), 3, res['n_rounds'], obs_stats.size))\n",
    "sig2e = np.zeros((len(seeds), 3, res['n_rounds'], obs_stats.size))\n",
    "sig2_ = np.zeros((len(seeds), 3, res['n_rounds'], obs_stats.size))\n",
    "\n",
    "for i in range(len(seeds)):\n",
    "\n",
    "    seed = seeds[i]\n",
    "    p1 = posteriors_s[i]\n",
    "    \n",
    "    res  = np.load('check_kernels_d' + str(duration) + '_' + str(seed) + '.npy')[()]\n",
    "    posteriors_all = [res['posteriors'], res['posteriors_k'], res['posteriors_k2']]\n",
    "    tds_all = [res['tds'], res['tds_k'], res['tds_k2']]\n",
    "    \n",
    "    for j in range(len(posteriors_all)):\n",
    "        psts =  posteriors_all[j]\n",
    "        for k in range(len(psts)):\n",
    "            if psts[k] is None:\n",
    "                p2 = psts[k-1].xs[0]\n",
    "                BAM[i,j,k-1] = d_kl_gauss(p1.m, p2.m, p1.S, p2.S)\n",
    "                psts.pop()\n",
    "                psts.pop()    \n",
    "            else:\n",
    "                p2 = psts[k].xs[0]\n",
    "                dklsa[i,j,k] = d_kl_gauss(p1.m, p2.m, p1.S, p2.S)\n",
    "                \n",
    "                w = tds_all[j][k][2].reshape(-1,1)\n",
    "                w /= w.sum()\n",
    "                ess[i,j,k] = 1/np.sum(w**2)\n",
    "\n",
    "                stats = tds_all[j][k][1]\n",
    "                sig2e[i, j, k, :] = np.var( stats, axis = 0)\n",
    "                mu_[  i, j, k, :] = np.sum( w * stats,                      axis=0).reshape(1,-1)\n",
    "                sig2_[i, j, k, :] = np.sum( w * (stats-mu_[i, j, k, :])**2, axis=0)                   \n",
    "                \n",
    "        p2 = psts[-1].xs[0]\n",
    "        dkls[i,j] = d_kl_gauss(p1.m, p2.m, p1.S, p2.S)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16,13))\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "idx = np.argsort(dkls[:,0])[::-1]\n",
    "#idx = np.arange(20)\n",
    "dkls_s = dkls[idx,:]\n",
    "plt.bar(np.arange(dkls_s.shape[0]),     dkls_s[:,0], 0.3, color='r')\n",
    "plt.bar(np.arange(dkls_s.shape[0])+0.2, dkls_s[:,1], 0.3, color='b')\n",
    "plt.bar(np.arange(dkls_s.shape[0])+0.4, dkls_s[:,2], 0.3, color='g')\n",
    "plt.xlabel('#rnd seed')\n",
    "plt.ylabel('final KL divergences')\n",
    "plt.legend(['raw', 'x_kl', 'mESS'])\n",
    "\n",
    "plt.subplot(2,4,3)\n",
    "plt.boxplot(dkls, labels=['raw', 'x_kl', 'mESS'])\n",
    "\n",
    "plt.subplot(2,4,4)\n",
    "plt.plot(-1, -1, 'r', linewidth=1.5)\n",
    "plt.plot(-1, -1, 'b', linewidth=1.5)\n",
    "plt.plot(-1, -1, 'g', linewidth=1.5)\n",
    "plt.plot(np.arange(1,dklsa.shape[2]+1), dklsa[:,0,:].T, 'r', linewidth=1.5)\n",
    "plt.plot(np.arange(1,dklsa.shape[2]+1), dklsa[:,1,:].T, 'b', linewidth=1.5)\n",
    "plt.plot(np.arange(1,dklsa.shape[2]+1), dklsa[:,2,:].T, 'g', linewidth=1.5)\n",
    "plt.plot(np.arange(1,dklsa.shape[2]+1), BAM[:,0,:].T, 'ro', ms=6)\n",
    "plt.plot(np.arange(1,dklsa.shape[2]+1), BAM[:,1,:].T, 'bo', ms=6)\n",
    "plt.plot(np.arange(1,dklsa.shape[2]+1), BAM[:,2,:].T, 'go', ms=6)\n",
    "plt.ylabel('KL divergence')\n",
    "plt.xlabel('#round')\n",
    "plt.legend(['raw', 'x_kl', 'mESS'])\n",
    "plt.axis([0.99, dklsa.shape[2], 0, 1.1*np.nanmax(dklsa)])\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "clrs = ['r', 'b', 'g']\n",
    "for j_ in np.arange(3)[::-1]:\n",
    "    m, s = np.mean(ess[:,j_,1:], axis=0), np.std(ess[:,j_,1:], axis=0)\n",
    "    #plt.plot(np.arange(2,ess.shape[2]+1), m+s, '--', color=clrs[j_], linewidth=1.5)\n",
    "    #plt.plot(np.arange(2,ess.shape[2]+1), m-s, '--', color=clrs[j_], linewidth=1.5)\n",
    "    plt.fill_between(np.arange(2,ess.shape[2]+1),\n",
    "                     m-s,\n",
    "                     m+s,\n",
    "                     color=clrs[j_],\n",
    "                     alpha=0.5\n",
    "                    )\n",
    "    plt.plot(np.arange(2,ess.shape[2]+1), m, clrs[j_], linewidth=2.5)    \n",
    "plt.xlabel('#round')\n",
    "plt.ylabel('ESS (+/- std over 20 rnd seeds)')\n",
    "\n",
    "\n",
    "rs = [0, 1, 4, 9]\n",
    "sp = [11, 12, 15, 16]\n",
    "for r_ in range(4):\n",
    "    \n",
    "    r = rs[r_]\n",
    "    plt.subplot(4,4,sp[r_])\n",
    "    \n",
    "    for j_ in np.arange(3):\n",
    "        m, s = sig2_[:,j_,r,:].mean(axis=(0,)), sig2_[:,j_,r,:].std(axis=(0,))\n",
    "        plt.plot(np.arange(len(m))+1, m, color=clrs[j_], linewidth=1.5)   \n",
    "        #plt.fill_between(np.arange(len(m)),\n",
    "        #                 m-s,\n",
    "        #                 m+s,\n",
    "        #                 color=clrs[j_],\n",
    "        #                 alpha=0.5\n",
    "        #                )    \n",
    "        #plt.plot(m-s, '--', color=clrs[j_], linewidth=1.5)   \n",
    "        #plt.plot(m+1, '--', color=clrs[j_], linewidth=1.5)   \n",
    "\n",
    "    if r_ in [2,3] :\n",
    "        plt.xlabel('# summary statistic')\n",
    "    if r_ in [0,2]:\n",
    "        plt.ylabel('empirical variance')\n",
    "    plt.title('SNPE round #' + str(r+1))\n",
    "\n",
    "    if r_==0:\n",
    "        plt.legend(['raw iws', 'iws + x_kl', 'iws + max_ess', 'unweighted'], loc=2)\n",
    "        \n",
    "plt.savefig('summary_GLM_' + str(len(seeds)) + 'seeds_dur' + str(duration) + '.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for seed in seeds:\n",
    "    r = 0\n",
    "    res  = np.load('check_kernels_d' + str(duration) + '_' + str(seed) + '.npy')[()]\n",
    "    stats = res['tds'][r][1]\n",
    "\n",
    "    plt.plot(stats.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
