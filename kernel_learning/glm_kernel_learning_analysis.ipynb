{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## learning kernels for the GLM example. \n",
    "\n",
    "we optimize kernels such that\n",
    "$ K(x_n, x_0) p(\\theta_n) / \\tilde{p}(\\theta_n) \\approx 1$. \n",
    "\n",
    "Spoiler:\n",
    "starts to work.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# approach\n",
    "\n",
    "The above problem doesn't require MDNs at all. \n",
    "Once prior, proposal, kernel and simulator are fixed and we drew an artificial dataset $(x_n, \\theta_n)$, we're good to play. \n",
    "Let's run SNPE as usual, note down the data-sets $(x_n, \\theta_n)$, proposal priors and importance weights it produced over rounds, and afterwards play with the kernel on those fixed targets. \n",
    "\n",
    "- Remark: results look a lot worse if we convert to Students-t distributions. Could be that kernel shape (squared-exponential in $x$) has to match proposal-prior shape (squared in $\\theta$ for students-T with df=3)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1. basic squared loss\n",
    "\n",
    "argmin $ \\sum_n \\left( 1 - \\frac{K(x_n, x_0) p(\\theta_n)}{\\tilde{p}(\\theta_n)} \\right)^2 $, emphasizing the absolute value of $\\approx 1$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import delfi.distribution as dd\n",
    "import delfi.generator as dg\n",
    "import delfi.inference as infer\n",
    "import delfi.utils.io as io\n",
    "import delfi.summarystats as ds\n",
    "import lfimodels.glm.utils as utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from lfimodels.glm.GLM import GLM\n",
    "from lfimodels.glm.GLMStats import GLMStats\n",
    "from delfi.utils.viz import plot_pdf\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def d_kl_gauss(m1, m2, S1, S2):\n",
    "   \n",
    "    S2i = np.linalg.inv(S2)\n",
    "    dm =  m2 - m1\n",
    "   \n",
    "    out  = np.trace(S2i.dot(S1))\n",
    "    out += dm.dot(S2i.dot(dm))\n",
    "    out -= m1.size\n",
    "    out += np.prod(np.linalg.slogdet(S2)) - np.prod(np.linalg.slogdet(S1))\n",
    "    return out / 2.\n",
    "\n",
    "\n",
    "seeds = np.arange(90, 110)\n",
    "duration = 300\n",
    "batch_specifier = '_cp'\n",
    "fit_specifier = '_5dim' #'_5dim'\n",
    "path = '' #'a_05/' #'glm_runs_badprior/'\n",
    "\n",
    "posteriors_s = []\n",
    "\n",
    "for seed in seeds:\n",
    "    \n",
    "    res  = np.load(path+'check_higherOrder_kernels' + batch_specifier + fit_specifier + '_d' + str(duration) + '_' + str(seed) + '.npy')[()]\n",
    "\n",
    "    true_params = res['true_params']\n",
    "    obs_stats   = res['obs_stats']\n",
    "    \n",
    "    sam = np.load(path+'sam_' + str(duration) + '_' + str(seed) + batch_specifier + '.npz')['arr_0']\n",
    "    ms = sam.mean(axis=1)\n",
    "    Ss = np.cov(sam)    \n",
    "    posteriors_s.append(dd.Gaussian(m=ms, S=Ss))    \n",
    "    \n",
    "    # run with Gaussian proposals\n",
    "    \n",
    "    print('\\n seed #' + str(seed) + '\\n')\n",
    "    posteriors = res['posteriors']\n",
    "    posteriors_k = res['posteriors_ki']\n",
    "    posteriors_k2 = res['posteriors_kh']\n",
    "    \n",
    "    if posteriors[-1] is None:\n",
    "        posteriors.pop()\n",
    "    \n",
    "    print('vanilla #succesful rounds: ', len(posteriors))\n",
    "    print('x_kl    #succesful rounds: ', len(posteriors_k))\n",
    "    print('max_ESS #succesful rounds: ', len(posteriors_k2))\n",
    "    \n",
    "    try:\n",
    "        fig,_ = plot_pdf(posteriors[-1],\n",
    "                 pdf2=posteriors_k[-1], \n",
    "                 resolution=100,\n",
    "                 lims=[-2,2], \n",
    "                 samples=sam, \n",
    "                 gt=true_params, \n",
    "                 figsize=(9,9));\n",
    "        fig.savefig('finalPosteriors_rawVsKernel' + '_ki' + '_dur' + str(duration) + batch_specifier + fit_specifier + str(seed) +'.pdf')\n",
    "        fig,_ = plot_pdf(posteriors[-1],\n",
    "                 pdf2=posteriors_k2[-1], \n",
    "                 resolution=100,\n",
    "                 lims=[-2,2], \n",
    "                 samples=sam, \n",
    "                 gt=true_params, \n",
    "                 figsize=(9,9));\n",
    "        fig.savefig('finalPosteriors_rawVsKernel' + '_kh' + '_dur' + str(duration) + batch_specifier + fit_specifier + str(seed) +'.pdf')\n",
    "        \n",
    "    except:\n",
    "        print('printing broke !')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn \n",
    "\n",
    "labels=['raw', 'x_kl_input', 'x_kl_hidden']\n",
    "mks = np.max((res['logs_ki'][-1]['cbkrnl'].A.size,\n",
    "              res['logs_kh'][-1]['cbkrnl'].A.size))\n",
    "\n",
    "dkls = np.zeros((len(seeds), 3))\n",
    "dklsa = np.nan * np.ones((len(seeds), 3, res['n_rounds']))\n",
    "BAM   = np.nan * np.ones_like(dklsa)\n",
    "\n",
    "ess = np.nan*np.ones((len(seeds), 3, res['n_rounds']))\n",
    "mu_   = np.nan*np.ones((len(seeds), 3, res['n_rounds'], obs_stats.size))\n",
    "sig2e = np.nan*np.ones((len(seeds), 3, res['n_rounds'], obs_stats.size))\n",
    "sig2_ = np.nan*np.ones((len(seeds), 3, res['n_rounds'], obs_stats.size))\n",
    "\n",
    "MSEs =  np.nan*np.ones((len(seeds), 3, res['n_rounds'], res['true_params'].size, 2))\n",
    "invwidths = np.nan*np.ones((len(seeds), 3, res['n_rounds'], mks))\n",
    "clrs = ['r', 'b', 'g']\n",
    "\n",
    "for i in range(len(seeds)):\n",
    "\n",
    "    seed = seeds[i]\n",
    "    p1 = posteriors_s[i]\n",
    "\n",
    "    res  = np.load(path+'check_higherOrder_kernels' + batch_specifier + fit_specifier + '_d' + str(duration) + '_' + str(seed) + '.npy')[()]\n",
    "    posteriors_all = [res['posteriors'], res['posteriors_ki'], res['posteriors_kh']]\n",
    "    tds_all = [res['tds'], res['tds_ki'], res['tds_kh']]\n",
    "    logs_all = [res['logs'], res['logs_ki'], res['logs_kh'] ]\n",
    "        \n",
    "    for j in range(len(posteriors_all)):\n",
    "        psts =  posteriors_all[j]\n",
    "        for k in range(len(psts)):\n",
    "            if psts[k] is None:\n",
    "                \n",
    "                p2 = psts[k-1].xs[0]\n",
    "                \n",
    "                BAM[i,j,k-1] = d_kl_gauss(p1.m, p2.m, p1.S, p2.S)\n",
    "                dklsa[i,j,k-1] = d_kl_gauss(p1.m, p2.m, p1.S, p2.S)\n",
    "\n",
    "                if len(psts) > 2:\n",
    "                    psts.pop()\n",
    "                if len(psts) > 1:\n",
    "                    psts.pop()    \n",
    "                \n",
    "        for k in range(len(psts)):\n",
    "            #else:\n",
    "            p2 = psts[k].xs[0]\n",
    "            dklsa[i,j,k] = d_kl_gauss(p1.m, p2.m, p1.S, p2.S)\n",
    "\n",
    "            w = tds_all[j][k][2].reshape(-1,1)\n",
    "            w /= w.sum()\n",
    "            ess[i,j,k] = 1/np.sum(w**2)\n",
    "\n",
    "            stats = tds_all[j][k][1]\n",
    "            sig2e[i, j, k, :] = np.var( stats, axis = 0)\n",
    "            mu_[  i, j, k, :] = np.sum( w * stats,                      axis=0).reshape(1,-1)\n",
    "            sig2_[i, j, k, :] = np.sum( w * (stats-mu_[i, j, k, :])**2, axis=0)                   \n",
    "\n",
    "            MSEs[i,j,k,:,0] = (         psts[k].xs[0].m  -         posteriors_s[i].m  )**2\n",
    "            MSEs[i,j,k,:,1] = ( np.diag(psts[k].xs[0].S) - np.diag(posteriors_s[i].S) )**2\n",
    "\n",
    "        lgs =  logs_all[j]\n",
    "        for k in range(len(psts)):\n",
    "            if not lgs[k]['cbkrnl'] is None:                \n",
    "                invwidths[i,j,k,:lgs[k]['cbkrnl'].A.size] = lgs[k]['cbkrnl'].A         \n",
    "                pass\n",
    "            \n",
    "        p2 = psts[-1].xs[0]\n",
    "        #p2 = psts[np.min((len(psts)-1, res['round_cl']-2))].xs[0]\n",
    "        dkls[i,j] = d_kl_gauss(p1.m, p2.m, p1.S, p2.S)\n",
    "\n",
    "RMSEs = np.sqrt(MSEs.sum(axis=3))        \n",
    "mRMSEs = np.nanmean(RMSEs, axis=0) # avg over seeds\n",
    "\n",
    "\n",
    "plt.figure(figsize=(24,21))\n",
    "plt.subplot(3,4,1)\n",
    "\n",
    "pu = np.zeros((3, res['n_rounds']))\n",
    "for j in range(1,3):\n",
    "    for k in range(res['n_rounds']):\n",
    "        tmp = invwidths[:,j,k,:].reshape(-1)\n",
    "        tmp = tmp[np.invert(np.isnan(tmp))]\n",
    "        ks = k * np.ones_like(tmp)\n",
    "        pu[j,k] = np.nanmean(tmp > 10**(-4))\n",
    "    plt.plot(pu[j,:], 'o-', color=clrs[j])\n",
    "plt.xlabel('#round')\n",
    "plt.ylabel('fraction i : A_ii > 0.0001')\n",
    "plt.title('usage of kernel (# non-flat kernel dims)')\n",
    "plt.legend(labels[1:], loc=5)\n",
    "\n",
    "plt.subplot(6,4,2)\n",
    "tmp = invwidths[:,1,:,:]\n",
    "tmp = tmp[np.invert(np.isnan(tmp))]\n",
    "plt.hist(np.maximum( np.log(tmp), 1e-20 ), bins=20, color=clrs[1]);\n",
    "plt.yticks([])\n",
    "plt.ylabel(labels[1])\n",
    "plt.title('distributions of learned kernel params')\n",
    "\n",
    "plt.subplot(6,4,6)\n",
    "tmp = invwidths[:,2,:,:]\n",
    "tmp = tmp[np.invert(np.isnan(tmp))]\n",
    "plt.hist(np.maximum( np.log(tmp), 1e-20 ), bins=20, color=clrs[2]);\n",
    "plt.yticks([])\n",
    "plt.ylabel(labels[2])\n",
    "plt.xlabel( 'log(A_ii)' )\n",
    "\n",
    "\n",
    "plt.subplot(3,4,3)\n",
    "for j in range(len(posteriors_all)):\n",
    "    plt.semilogy(range(1, mRMSEs.shape[1]+1), RMSEs[:,j,:,0].T, '--', alpha=0.35, color=clrs[j])\n",
    "    plt.semilogy(range(1, mRMSEs.shape[1]+1),mRMSEs[j,:,0], color=clrs[j], linewidth=2.5)\n",
    "plt.title('error in posterior means')\n",
    "plt.ylabel('Eucl. distance (avg. over seeds)')\n",
    "plt.legend(labels, loc=1)\n",
    "plt.xlabel('#round')\n",
    "\n",
    "plt.subplot(3,4,4)\n",
    "for j in range(len(posteriors_all)):\n",
    "    plt.semilogy(range(1, mRMSEs.shape[1]+1),mRMSEs[j,:,1], color=clrs[j], linewidth=2.5)\n",
    "    plt.semilogy(range(1, mRMSEs.shape[1]+1), RMSEs[:,j,:,1].T, '--', alpha=0.35, color=clrs[j])\n",
    "plt.title('error in posterior variances (diag(S))')\n",
    "plt.xlabel('#round')\n",
    "\n",
    "plt.subplot(3,2,3)\n",
    "idx = np.argsort(dkls[:,0])[::-1]\n",
    "#idx = np.arange(len(seeds))\n",
    "dkls_s = dkls[idx,:]\n",
    "plt.bar(np.arange(dkls_s.shape[0]),     dkls_s[:,0], 0.3, color='r')\n",
    "plt.bar(np.arange(dkls_s.shape[0])+0.2, dkls_s[:,1], 0.3, color='b')\n",
    "plt.bar(np.arange(dkls_s.shape[0])+0.4, dkls_s[:,2], 0.3, color='g')\n",
    "plt.xlabel('#rnd seed')\n",
    "plt.ylabel('final KL divergences')\n",
    "plt.legend(labels)\n",
    "plt.title('distance of posteriors to ground-truth')\n",
    "\n",
    "plt.subplot(3,4,7)\n",
    "if dkls.shape[0] > 1:\n",
    "    plt.boxplot(dkls, labels=labels)\n",
    "plt.title('distribution of final D_KL')\n",
    "\n",
    "plt.subplot(3,4,8)\n",
    "plt.plot(-1, -1, 'r', linewidth=1.5)\n",
    "plt.plot(-1, -1, 'b', linewidth=1.5)\n",
    "plt.plot(-1, -1, 'g', linewidth=1.5)\n",
    "for j_ in np.arange(3)[::-1]:\n",
    "\n",
    "    plt.plot(np.arange(1,dklsa.shape[2]+1), dklsa[:,j_,:].T, '--', color=clrs[j_], alpha=0.35)\n",
    "    plt.plot(np.arange(1,dklsa.shape[2]+1), BAM[:,j_,:].T, 'o', color=clrs[j_], ms=6, alpha=0.35)\n",
    "    m, s = np.nanmean(dklsa[:,j_,:], axis=0), np.nanstd(dklsa[:,j_,:], axis=0)\n",
    "    plt.plot(np.arange(1,dklsa.shape[2]+1), m, clrs[j_], linewidth=2.5)    \n",
    "\n",
    "plt.ylabel('KL divergence')\n",
    "plt.xlabel('#round')\n",
    "plt.legend(labels)\n",
    "plt.axis([0.99, dklsa.shape[2], 0, 1.1*np.nanmax(dklsa)])\n",
    "plt.title('posterior distance over rounds')\n",
    "\n",
    "plt.subplot(3,2,5)\n",
    "for j_ in np.arange(3)[::-1]:\n",
    "    m, s = np.nanmean(ess[:,j_,1:], axis=0), np.nanstd(ess[:,j_,1:], axis=0)\n",
    "    plt.plot(np.arange(2,ess.shape[2]+1), m, clrs[j_], linewidth=2.5)    \n",
    "    plt.plot(np.arange(2,ess.shape[2]+1), ess[:,j_,1:].T, '--', alpha=0.35, color=clrs[j_])\n",
    "plt.xlabel('#round')\n",
    "plt.ylabel('ESS (avg: thick line)')\n",
    "plt.title('IS weight variance: effective sample sizes')\n",
    "\n",
    "if res['n_rounds'] > 9:\n",
    "    rs = [0, 1, 4, 9]\n",
    "else: \n",
    "    rs = [0, 1, 2, 3]\n",
    "sp = [19, 20, 23, 24]\n",
    "for r_ in range(4):\n",
    "    \n",
    "    r = rs[r_]\n",
    "    plt.subplot(6,4,sp[r_])\n",
    "    \n",
    "    for j_ in np.arange(3):\n",
    "        m, s = np.nanmean(sig2_[:,j_,r,:],axis=(0,)), np.nanmean(sig2_[:,j_,r,:], axis=(0,))\n",
    "        plt.plot(np.arange(len(m))+1, m, color=clrs[j_], linewidth=1.5)   \n",
    "        \n",
    "    for j_ in np.arange(3):\n",
    "        plt.plot(np.arange(len(m))+1, sig2e[:,j_,r,:].mean(axis=0,), \n",
    "                '--', color=clrs[j_], linewidth=1.2)\n",
    "\n",
    "    if r_ in [2,3] :\n",
    "        plt.xlabel('# summary statistic')\n",
    "    if r_ in [0,2]:\n",
    "        plt.ylabel('empirical variance')\n",
    "    plt.title('SNPE round #' + str(r+1))\n",
    "\n",
    "    if r_==0:\n",
    "        plt.legend(['raw iws', 'iws + x_kl', 'iws + mESS'], loc=1)\n",
    "        \n",
    "plt.savefig('summary_GLM' + batch_specifier + fit_specifier +'_'+ str(len(seeds)) + 'seeds_dur' + str(duration) + '.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# figures on weighted summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import delfi.distribution as dd\n",
    "import delfi.generator as dg\n",
    "import delfi.inference as infer\n",
    "import delfi.utils.io as io\n",
    "import delfi.summarystats as ds\n",
    "import lfimodels.glm.utils as utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from lfimodels.glm.GLM import GLM\n",
    "from lfimodels.glm.GLMStats import GLMStats\n",
    "from delfi.utils.viz import plot_pdf\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def d_kl_gauss(m1, m2, S1, S2):\n",
    "   \n",
    "    S2i = np.linalg.inv(S2)\n",
    "    dm =  m2 - m1\n",
    "   \n",
    "    out  = np.trace(S2i.dot(S1))\n",
    "    out += dm.dot(S2i.dot(dm))\n",
    "    out -= m1.size\n",
    "    out += np.prod(np.linalg.slogdet(S2)) - np.prod(np.linalg.slogdet(S1))\n",
    "    return out / 2.\n",
    "\n",
    "\n",
    "seeds = np.arange(90, 110)\n",
    "duration = 300\n",
    "batch_specifier = '_cp'\n",
    "fit_specifier = '_5dim' #'_5dim'\n",
    "path = '' #'a_05/' #'glm_runs_badprior/'\n",
    "\n",
    "posteriors_s = []\n",
    "\n",
    "for seed in seeds:\n",
    "    \n",
    "    res  = np.load(path+'check_higherOrder_kernels' + batch_specifier + fit_specifier + '_d' + str(duration) + '_' + str(seed) + '.npy')[()]\n",
    "\n",
    "    true_params = res['true_params']\n",
    "    obs_stats   = res['obs_stats']\n",
    "    \n",
    "    sam = np.load(path+'sam_' + str(duration) + '_' + str(seed) + batch_specifier + '.npz')['arr_0']\n",
    "    ms = sam.mean(axis=1)\n",
    "    Ss = np.cov(sam)    \n",
    "    posteriors_s.append(dd.Gaussian(m=ms, S=Ss))    \n",
    "    \n",
    "    # run with Gaussian proposals\n",
    "    \n",
    "    print('\\n seed #' + str(seed) + '\\n')\n",
    "    posteriors = res['posteriors']\n",
    "    posteriors_k = res['posteriors_ki']\n",
    "    posteriors_k2 = res['posteriors_kh']\n",
    "    \n",
    "    if posteriors[-1] is None:\n",
    "        posteriors.pop()\n",
    "    \n",
    "    print('vanilla #succesful rounds: ', len(posteriors))\n",
    "    print('x_kl    #succesful rounds: ', len(posteriors_k))\n",
    "    print('max_ESS #succesful rounds: ', len(posteriors_k2))\n",
    "    \n",
    "\n",
    "    r = res['n_rounds']-1\n",
    "    tds, tds_k = res['tds'], res['tds_ki']\n",
    "    stats, w = tds[r][1], tds[r][2]\n",
    "    w /= w.sum()\n",
    "    px = dd.Gaussian(m=w.dot(stats),\n",
    "                     S=np.cov(stats.T, aweights=w))\n",
    "    stats, w = tds_k[r][1], tds_k[r][2]\n",
    "    w /= w.sum()\n",
    "    px_k = dd.Gaussian(m=w.dot(stats),\n",
    "                     S=np.cov(stats.T, aweights=w))\n",
    "    stats = tds_k[r][1]\n",
    "    fig,_ = plot_pdf(px, pdf2=px_k, samples=stats.T, lims = [-2, 2], resolution=100,\n",
    "             figsize=(16,16));        \n",
    "    fig.savefig('finalWeightedStats_rawVsKernel' + '_ki' + '_dur' + str(duration) + batch_specifier + fit_specifier + str(seed) +'.pdf')\n",
    "\n",
    "    tds, tds_k = res['tds'], res['tds_ki']\n",
    "    stats, w = tds[r][1], tds[r][2]\n",
    "    w /= w.sum()\n",
    "    px = dd.Gaussian(m=w.dot(stats),\n",
    "                     S=np.cov(stats.T, aweights=w))\n",
    "    stats, w = tds_k[r][1], tds_k[r][2]\n",
    "    w /= w.sum()\n",
    "    px_k = dd.Gaussian(m=w.dot(stats),\n",
    "                     S=np.cov(stats.T, aweights=w))\n",
    "    stats = tds_k[r][1]\n",
    "    fig,_ = plot_pdf(px, pdf2=px_k, samples=stats.T, lims = [-2, 2], resolution=100,\n",
    "             figsize=(16,16));            \n",
    "    fig.savefig('finalWeightedStats_rawVsKernel' + '_kh' + '_dur' + str(duration) + batch_specifier + fit_specifier + str(seed) +'.pdf')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# that one bad one..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "seed = 99\n",
    "res  = np.load(path+'check_higherOrder_kernels' + batch_specifier + fit_specifier + '_d' + str(duration) + '_' + str(seed) + '.npy')[()]\n",
    "\n",
    "true_params = res['true_params']\n",
    "obs_stats   = res['obs_stats']\n",
    "\n",
    "sam = np.load(path+'sam_' + str(duration) + '_' + str(seed) + batch_specifier + '.npz')['arr_0']\n",
    "ms = sam.mean(axis=1)\n",
    "Ss = np.cov(sam)    \n",
    "posteriors_s.append(dd.Gaussian(m=ms, S=Ss))    \n",
    "\n",
    "# run with Gaussian proposals\n",
    "\n",
    "print('\\n seed #' + str(seed) + '\\n')\n",
    "posteriors = res['posteriors']\n",
    "posteriors_k = res['posteriors_ki']\n",
    "posteriors_k2 = res['posteriors_kh']\n",
    "\n",
    "if posteriors[-1] is None:\n",
    "    posteriors.pop()\n",
    "\n",
    "print('vanilla #succesful rounds: ', len(posteriors))\n",
    "print('x_kl    #succesful rounds: ', len(posteriors_k))\n",
    "print('max_ESS #succesful rounds: ', len(posteriors_k2))\n",
    "\n",
    "for r in range(5):\n",
    "    plot_pdf(posteriors[r],\n",
    "             pdf2=posteriors_k[r], \n",
    "             resolution=100,\n",
    "             lims=[-2,2], \n",
    "             samples=sam, \n",
    "             gt=true_params, \n",
    "             figsize=(9,9));\n",
    "for r in range(5):\n",
    "    plot_pdf(posteriors[r],\n",
    "             pdf2=posteriors_k2[r], \n",
    "             resolution=100,\n",
    "             lims=[-2,2], \n",
    "             samples=sam, \n",
    "             gt=true_params, \n",
    "             figsize=(9,9));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# previous sweeps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import delfi.distribution as dd\n",
    "import delfi.generator as dg\n",
    "import delfi.inference as infer\n",
    "import delfi.utils.io as io\n",
    "import delfi.summarystats as ds\n",
    "import lfimodels.glm.utils as utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from lfimodels.glm.GLM import GLM\n",
    "from lfimodels.glm.GLMStats import GLMStats\n",
    "from delfi.utils.viz import plot_pdf\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def d_kl_gauss(m1, m2, S1, S2):\n",
    "   \n",
    "    S2i = np.linalg.inv(S2)\n",
    "    dm =  m2 - m1\n",
    "   \n",
    "    out  = np.trace(S2i.dot(S1))\n",
    "    out += dm.dot(S2i.dot(dm))\n",
    "    out -= m1.size\n",
    "    out += np.prod(np.linalg.slogdet(S2)) - np.prod(np.linalg.slogdet(S1))\n",
    "    return out / 2.\n",
    "\n",
    "\n",
    "seeds = np.arange(90, 110)\n",
    "duration = 300\n",
    "batch_specifier = '_cp'\n",
    "fit_specifier = '_pilot_convT_small_05'\n",
    "path = '' #'a_05/' #'glm_runs_badprior/'\n",
    "\n",
    "posteriors_s = []\n",
    "\n",
    "for seed in seeds:\n",
    "    \n",
    "    true_params, labels_params = utils.obs_params()\n",
    "    obs = utils.obs_data(true_params, seed=seed, duration = duration)\n",
    "    obs_stats = utils.obs_stats(true_params, seed=seed, duration = duration)\n",
    "\n",
    "    res  = np.load(path+'check_kernels' + batch_specifier + fit_specifier + '_d' + str(duration) + '_' + str(seed) + '.npy')[()]\n",
    "\n",
    "    #assert np.all( true_params == res['true_params'] )\n",
    "    #assert np.all( obs_stats == res['obs_stats'] )\n",
    "    \n",
    "    sam = np.load(path+'sam_' + str(duration) + '_' + str(seed) + batch_specifier + '.npz')['arr_0']\n",
    "    ms = sam.mean(axis=1)\n",
    "    Ss = np.cov(sam)    \n",
    "    posteriors_s.append(dd.Gaussian(m=ms, S=Ss))    \n",
    "    \n",
    "    # run with Gaussian proposals\n",
    "    \n",
    "    print('\\n seed #' + str(seed) + '\\n')\n",
    "    posteriors = res['posteriors']\n",
    "    posteriors_k = res['posteriors_k']\n",
    "    posteriors_k2 = res['posteriors_k2']\n",
    "    \n",
    "    if posteriors[-1] is None:\n",
    "        posteriors.pop()\n",
    "    \n",
    "    print('vanilla #succesful rounds: ', len(posteriors))\n",
    "    print('x_kl    #succesful rounds: ', len(posteriors_k))\n",
    "    print('max_ESS #succesful rounds: ', len(posteriors_k2))\n",
    "    \n",
    "    try:\n",
    "        bla\n",
    "        plot_pdf(posteriors[-1],\n",
    "                 pdf2=posteriors_k[-1], \n",
    "                 resolution=100,\n",
    "                 lims=[-2,2], \n",
    "                 samples=sam, \n",
    "                 gt=true_params, \n",
    "                 figsize=(9,9));\n",
    "    except:\n",
    "        print('printing broke !')\n",
    "\n",
    "import seaborn \n",
    "\n",
    "dkls = np.zeros((len(seeds), 3))\n",
    "dklsa = np.nan * np.ones((len(seeds), 3, res['n_rounds']))\n",
    "BAM   = np.nan * np.ones_like(dklsa)\n",
    "\n",
    "ess = np.nan*np.ones((len(seeds), 3, res['n_rounds']))\n",
    "mu_   = np.nan*np.ones((len(seeds), 3, res['n_rounds'], obs_stats.size))\n",
    "sig2e = np.nan*np.ones((len(seeds), 3, res['n_rounds'], obs_stats.size))\n",
    "sig2_ = np.nan*np.ones((len(seeds), 3, res['n_rounds'], obs_stats.size))\n",
    "\n",
    "MSEs =  np.nan*np.ones((len(seeds), 3, res['n_rounds'], res['true_params'].size, 2))\n",
    "invwidths = np.nan*np.ones((len(seeds), 3, res['n_rounds'], obs_stats.size))\n",
    "clrs = ['r', 'b', 'g']\n",
    "\n",
    "for i in range(len(seeds)):\n",
    "\n",
    "    seed = seeds[i]\n",
    "    p1 = posteriors_s[i]\n",
    "\n",
    "    res  = np.load(path+'check_kernels' + batch_specifier + fit_specifier + '_d' + str(duration) + '_' + str(seed) + '.npy')[()]\n",
    "    posteriors_all = [res['posteriors'], res['posteriors_k'], res['posteriors_k2']]\n",
    "    tds_all = [res['tds'], res['tds_k'], res['tds_k2']]\n",
    "    logs_all = [res['logs'], res['logs_k'], res['logs_k2'] ]\n",
    "        \n",
    "    for j in range(len(posteriors_all)):\n",
    "        psts =  posteriors_all[j]\n",
    "        for k in range(len(psts)):\n",
    "            if psts[k] is None:\n",
    "                \n",
    "                p2 = psts[k-1].xs[0]\n",
    "                \n",
    "                BAM[i,j,k-1] = d_kl_gauss(p1.m, p2.m, p1.S, p2.S)\n",
    "                dklsa[i,j,k-1] = d_kl_gauss(p1.m, p2.m, p1.S, p2.S)\n",
    "\n",
    "                if len(psts) > 2:\n",
    "                    psts.pop()\n",
    "                if len(psts) > 1:\n",
    "                    psts.pop()    \n",
    "                \n",
    "        for k in range(len(psts)):\n",
    "            #else:\n",
    "            p2 = psts[k].xs[0]\n",
    "            dklsa[i,j,k] = d_kl_gauss(p1.m, p2.m, p1.S, p2.S)\n",
    "\n",
    "            w = tds_all[j][k][2].reshape(-1,1)\n",
    "            w /= w.sum()\n",
    "            ess[i,j,k] = 1/np.sum(w**2)\n",
    "\n",
    "            stats = tds_all[j][k][1]\n",
    "            sig2e[i, j, k, :] = np.var( stats, axis = 0)\n",
    "            mu_[  i, j, k, :] = np.sum( w * stats,                      axis=0).reshape(1,-1)\n",
    "            sig2_[i, j, k, :] = np.sum( w * (stats-mu_[i, j, k, :])**2, axis=0)                   \n",
    "\n",
    "            MSEs[i,j,k,:,0] = (         psts[k].xs[0].m  -         posteriors_s[i].m  )**2\n",
    "            MSEs[i,j,k,:,1] = ( np.diag(psts[k].xs[0].S) - np.diag(posteriors_s[i].S) )**2\n",
    "\n",
    "        lgs =  logs_all[j]\n",
    "        for k in range(len(psts)):\n",
    "            if not lgs[k]['cbkrnl'] is None:                \n",
    "                invwidths[i,j,k,:] = lgs[k]['cbkrnl'].A         \n",
    "            \n",
    "        p2 = psts[-1].xs[0]\n",
    "        #p2 = psts[np.min((len(psts)-1, res['round_cl']-2))].xs[0]\n",
    "        dkls[i,j] = d_kl_gauss(p1.m, p2.m, p1.S, p2.S)\n",
    "\n",
    "RMSEs = np.nanmean(np.sqrt(MSEs.sum(axis=3)), axis=0) # avg over seeds\n",
    "#sig2_ = sig2_ / sig2e[:,:,0,:].reshape(20,3,1,10)\n",
    "#sig2e = sig2e / sig2e[:,:,0,:].reshape(20,3,1,10)\n",
    "\n",
    "plt.figure(figsize=(24,21))\n",
    "\n",
    "\"\"\"\n",
    "s_bw = np.argmin(dkls[:,1] - dkls[i,0]), np.argmax(dkls[:,1] - dkls[i,0]) # best and worst\n",
    "for i in range(len(s_bw)):\n",
    "    res  = np.load('check_kernels_cp_d' + str(duration) + '_' + str(s_bw[i]) + '.npy')[()]\n",
    "    plt.subplot(3,4,i+1)\n",
    "    \n",
    "    posterior, posterior_k = res['posteriors'][-1], res['posteriors_k'][-1]\n",
    "    sam = np.load('sam_' + str(duration) + '_' + str(seed) + 'cp.npz')['arr_0']\n",
    "\n",
    "    plot_pdf(posterior,pdf2=posterior_k, \n",
    "             resolution=100, \n",
    "             samples=sam, gt=true_params);\n",
    "\"\"\"\n",
    "\n",
    "plt.subplot(3,4,1)\n",
    "\n",
    "pu = np.zeros((3, res['n_rounds']))\n",
    "for j in range(1,3):\n",
    "    for k in range(res['n_rounds']):\n",
    "        tmp = invwidths[:,j,k,:].reshape(-1)\n",
    "        tmp = tmp[np.invert(np.isnan(tmp))]\n",
    "        ks = k * np.ones_like(tmp)\n",
    "        pu[j,k] = np.nanmean(tmp > 10**(-4))\n",
    "    plt.plot(pu[j,:], 'o-', color=clrs[j])\n",
    "plt.xlabel('#round')\n",
    "plt.ylabel('fraction i : A_ii > 0.0001')\n",
    "plt.title('usage of kernel (# non-flat kernel dims)')\n",
    "plt.legend(['x_kl', 'mEss'], loc=5)\n",
    "\n",
    "plt.subplot(6,4,2)\n",
    "tmp = invwidths[:,1,:,:]\n",
    "tmp = tmp[np.invert(np.isnan(tmp))]\n",
    "plt.hist(np.log(tmp), bins=20, color=clrs[1]);\n",
    "plt.yticks([])\n",
    "plt.ylabel('x_kl')\n",
    "plt.title('distributions of learned kernel params')\n",
    "\n",
    "plt.subplot(6,4,6)\n",
    "tmp = invwidths[:,2,:,:]\n",
    "tmp = tmp[np.invert(np.isnan(tmp))]\n",
    "plt.hist(np.log(tmp), bins=20, color=clrs[2]);\n",
    "plt.yticks([])\n",
    "plt.ylabel('mESS')\n",
    "plt.xlabel( 'log(A_ii)' )\n",
    "\n",
    "\n",
    "plt.subplot(3,4,3)\n",
    "for j in range(len(posteriors_all)):\n",
    "    plt.semilogy(range(1, RMSEs.shape[1]+1),RMSEs[j,:,0], color=clrs[j])\n",
    "plt.title('error in posterior means')\n",
    "plt.ylabel('Eucl. distance (avg. over seeds)')\n",
    "plt.xlabel('#round')\n",
    "\n",
    "plt.subplot(3,4,4)\n",
    "for j in range(len(posteriors_all)):\n",
    "    plt.semilogy(range(1, RMSEs.shape[1]+1),RMSEs[j,:,1], color=clrs[j])\n",
    "plt.title('error in posterior variances (diag(S))')\n",
    "plt.xlabel('#round')\n",
    "\n",
    "plt.subplot(3,2,3)\n",
    "idx = np.argsort(dkls[:,0])[::-1]\n",
    "dkls_s = dkls[idx,:]\n",
    "plt.bar(np.arange(dkls_s.shape[0]),     dkls_s[:,0], 0.3, color='r')\n",
    "plt.bar(np.arange(dkls_s.shape[0])+0.2, dkls_s[:,1], 0.3, color='b')\n",
    "plt.bar(np.arange(dkls_s.shape[0])+0.4, dkls_s[:,2], 0.3, color='g')\n",
    "plt.xlabel('#rnd seed')\n",
    "plt.ylabel('final KL divergences')\n",
    "plt.legend(['raw', 'x_kl', 'mESS'])\n",
    "plt.title('distance of posteriors to ground-truth')\n",
    "\n",
    "plt.subplot(3,4,7)\n",
    "if dkls.shape[0] > 1:\n",
    "    plt.boxplot(dkls, labels=['raw', 'x_kl', 'mESS'])\n",
    "plt.title('distribution of final D_KL')\n",
    "\n",
    "plt.subplot(3,4,8)\n",
    "plt.plot(-1, -1, 'r', linewidth=1.5)\n",
    "plt.plot(-1, -1, 'b', linewidth=1.5)\n",
    "plt.plot(-1, -1, 'g', linewidth=1.5)\n",
    "for j_ in np.arange(3)[::-1]:\n",
    "\n",
    "    plt.plot(np.arange(1,dklsa.shape[2]+1), dklsa[:,j_,:].T, '--', color=clrs[j_], alpha=0.35)\n",
    "    plt.plot(np.arange(1,dklsa.shape[2]+1), BAM[:,j_,:].T, 'o', color=clrs[j_], ms=6, alpha=0.35)\n",
    "    m, s = np.nanmean(dklsa[:,j_,:], axis=0), np.nanstd(dklsa[:,j_,:], axis=0)\n",
    "    plt.plot(np.arange(1,dklsa.shape[2]+1), m, clrs[j_], linewidth=2.5)    \n",
    "\n",
    "plt.ylabel('KL divergence')\n",
    "plt.xlabel('#round')\n",
    "plt.legend(['raw', 'x_kl', 'mESS'])\n",
    "plt.axis([0.99, dklsa.shape[2], 0, 1.1*np.nanmax(dklsa)])\n",
    "plt.title('posterior distance over rounds')\n",
    "\n",
    "plt.subplot(3,2,5)\n",
    "for j_ in np.arange(3)[::-1]:\n",
    "    m, s = np.nanmean(ess[:,j_,1:], axis=0), np.nanstd(ess[:,j_,1:], axis=0)\n",
    "    #plt.fill_between(np.arange(2,ess.shape[2]+1),\n",
    "    #                 m-s,\n",
    "    #                 m+s,\n",
    "    #                 color=clrs[j_],\n",
    "    #                 alpha=0.5\n",
    "    #                )\n",
    "    plt.plot(np.arange(2,ess.shape[2]+1), m, clrs[j_], linewidth=2.5)    \n",
    "    plt.plot(np.arange(2,ess.shape[2]+1), ess[:,j_,1:].T, '--', alpha=0.35, color=clrs[j_])\n",
    "plt.xlabel('#round')\n",
    "plt.ylabel('ESS (avg: thick line)')\n",
    "plt.title('IS weight variance: effective sample sizes')\n",
    "\n",
    "if res['n_rounds'] > 9:\n",
    "    rs = [0, 1, 4, 9]\n",
    "else: \n",
    "    rs = [0, 1, 2, 3]\n",
    "sp = [19, 20, 23, 24]\n",
    "for r_ in range(4):\n",
    "    \n",
    "    r = rs[r_]\n",
    "    plt.subplot(6,4,sp[r_])\n",
    "    \n",
    "    for j_ in np.arange(3):\n",
    "        m, s = np.nanmean(sig2_[:,j_,r,:],axis=(0,)), np.nanmean(sig2_[:,j_,r,:], axis=(0,))\n",
    "        plt.plot(np.arange(len(m))+1, m, color=clrs[j_], linewidth=1.5)   \n",
    "        \n",
    "    for j_ in np.arange(3):\n",
    "        plt.plot(np.arange(len(m))+1, sig2e[:,j_,r,:].mean(axis=0,), \n",
    "                '--', color=clrs[j_], linewidth=1.2)\n",
    "\n",
    "    if r_ in [2,3] :\n",
    "        plt.xlabel('# summary statistic')\n",
    "    if r_ in [0,2]:\n",
    "        plt.ylabel('empirical variance')\n",
    "    plt.title('SNPE round #' + str(r+1))\n",
    "\n",
    "    if r_==0:\n",
    "        plt.legend(['raw iws', 'iws + x_kl', 'iws + mESS'], loc=1)\n",
    "        \n",
    "plt.savefig('summary_GLM' + batch_specifier + fit_specifier +'_'+ str(len(seeds)) + 'seeds_dur' + str(duration) + '.pdf')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
