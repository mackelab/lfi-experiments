{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## learning kernels for the GLM example. \n",
    "\n",
    "we optimize kernels such that\n",
    "$ K(x_n, x_0) p(\\theta_n) / \\tilde{p}(\\theta_n) \\approx 1$. \n",
    "\n",
    "Spoiler:\n",
    "starts to work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import delfi.distribution as dd\n",
    "import delfi.generator as dg\n",
    "import delfi.inference as infer\n",
    "import delfi.utils.io as io\n",
    "import delfi.summarystats as ds\n",
    "import lfimodels.glm.utils as utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from lfimodels.glm.GLM import GLM\n",
    "from lfimodels.glm.GLMStats import GLMStats\n",
    "from delfi.utils.viz import plot_pdf\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "seeds = np.arange(90, 110)\n",
    "\n",
    "batch_specifier = '_cp'\n",
    "fit_specifier = '_5dim'\n",
    "if batch_specifier == '_bp':\n",
    "    smoothing_prior = utils.smoothing_prior_highVar\n",
    "elif batch_specifier == '_cp':\n",
    "    smoothing_prior = utils.smoothing_prior   \n",
    "\n",
    "duration = 300\n",
    "\n",
    "len_filter, a = 4, 2.\n",
    "true_params, labels_params = utils.obs_params(len_filter, a)\n",
    "\n",
    "def init_g(seed):\n",
    "    \n",
    "    s = GLMStats(n_summary=len_filter+1)\n",
    "    p = smoothing_prior(n_params=len_filter+1, seed=seed)\n",
    "    m = GLM(len_filter=len_filter, duration=duration, seed=seed)\n",
    "    g = dg.Default(summary=s, model=m, prior=p)    \n",
    "    \n",
    "    return g\n",
    "    \n",
    "n_train=3000\n",
    "n_rounds=5\n",
    "minibatch=100 \n",
    "epochs=200   \n",
    "round_cl=3\n",
    "\n",
    "minibatch_cbk=n_train\n",
    "epochs_cbk=10000\n",
    "\n",
    "n_hiddens = [10,10]\n",
    "convert_to_T = 3\n",
    "pilot_samples = 1000\n",
    "svi=True\n",
    "reg_lambda=0.01\n",
    "prior_norm=False\n",
    "cbk_feature_layer = 4\n",
    "\n",
    "for seed in seeds:\n",
    "    \n",
    "    obs = utils.obs_data(true_params, seed=seed, duration=duration)\n",
    "    obs_stats = utils.obs_stats(true_params, seed=seed, duration=duration)\n",
    "\n",
    "    \n",
    "    sam = utils.pg_mcmc(true_params, obs, duration=duration, \n",
    "                        prior_dist=smoothing_prior(n_params=len_filter+1, seed=seed))\n",
    "    np.savez('sam_' + str(duration) + '_' + str(seed) + batch_specifier + '.npz', sam)\n",
    "    \n",
    "    pe = dd.Gaussian(m=sam.mean(axis=1), S=np.cov(sam))\n",
    "\n",
    "\n",
    "    res = infer.SNPE(generator=init_g(seed), \n",
    "                     obs=obs_stats, \n",
    "                     n_hiddens=n_hiddens, \n",
    "                     seed=seed, \n",
    "                     convert_to_T=convert_to_T, \n",
    "                     pilot_samples=pilot_samples,\n",
    "                     svi=svi,\n",
    "                     reg_lambda=reg_lambda,\n",
    "                     prior_norm=prior_norm)\n",
    "    logs, tds, posteriors = res.run(n_train=n_train, \n",
    "                                    n_rounds=n_rounds, \n",
    "                                    minibatch=minibatch, \n",
    "                                    epochs=epochs, \n",
    "                                    minibatch_cbk=minibatch_cbk,\n",
    "                                    epochs_cbk=epochs_cbk,                                        \n",
    "                                    round_cl=round_cl, \n",
    "                                    kernel_loss=None)\n",
    "\n",
    "    res_ki = infer.SNPE(generator=init_g(seed), \n",
    "                     obs=obs_stats, \n",
    "                     n_hiddens=n_hiddens, \n",
    "                     seed=seed, \n",
    "                     convert_to_T=convert_to_T, \n",
    "                     pilot_samples=pilot_samples,\n",
    "                     svi=svi,\n",
    "                     reg_lambda=reg_lambda,\n",
    "                     prior_norm=prior_norm)\n",
    "    logs_ki, tds_ki, posteriors_ki = res_ki.run(n_train=n_train, \n",
    "                                    n_rounds=n_rounds, \n",
    "                                    minibatch=minibatch, \n",
    "                                    epochs=epochs, \n",
    "                                    minibatch_cbk=minibatch_cbk,\n",
    "                                    epochs_cbk=epochs_cbk,                                        \n",
    "                                    round_cl=round_cl, \n",
    "                                    cbk_feature_layer=0,\n",
    "                                    kernel_loss='x_kl')\n",
    "\n",
    "    res_kh = infer.SNPE(generator=init_g(seed), \n",
    "                     obs=obs_stats, \n",
    "                     n_hiddens=n_hiddens, \n",
    "                     seed=seed, \n",
    "                     convert_to_T=convert_to_T, \n",
    "                     pilot_samples=pilot_samples,\n",
    "                     svi=svi,\n",
    "                     reg_lambda=reg_lambda,\n",
    "                     prior_norm=prior_norm)\n",
    "    logs_kh, tds_kh, posteriors_kh = res_kh.run(n_train=n_train, \n",
    "                                    n_rounds=n_rounds, \n",
    "                                    minibatch=minibatch, \n",
    "                                    epochs=epochs, \n",
    "                                    minibatch_cbk=minibatch_cbk,\n",
    "                                    epochs_cbk=epochs_cbk,                                        \n",
    "                                    round_cl=round_cl, \n",
    "                                    cbk_feature_layer=cbk_feature_layer,\n",
    "                                    kernel_loss='x_kl')\n",
    "    \n",
    "    np.save('check_higherOrder_kernels' + batch_specifier + fit_specifier + '_d' + str(duration) + '_' + str(seed),\n",
    "            {'seed': seed,\n",
    "             'duration' : duration, \n",
    "             'n_train' : n_train,\n",
    "             'n_rounds' : n_rounds,\n",
    "             'minibatch' : minibatch,\n",
    "             'epochs' : minibatch,\n",
    "\n",
    "             'epochs_cbk' : epochs_cbk,\n",
    "             'minibatch_cbk' : minibatch_cbk,\n",
    "             \n",
    "             'n_hiddens' : n_hiddens, \n",
    "             'convert_to_T' : convert_to_T, \n",
    "             'pilot_samples' : pilot_samples,\n",
    "             'svi' : svi,\n",
    "             'reg_lambda': reg_lambda,\n",
    "             'prior_norm': prior_norm,             \n",
    "             'round_cl' : round_cl,     \n",
    "             \n",
    "             'obs_stats' : obs_stats,\n",
    "             'true_params' : true_params,\n",
    "             \n",
    "             'g' : init_g(seed), \n",
    "             'pe' : pe, \n",
    "\n",
    "             'cbk_feature_layer' : cbk_feature_layer,\n",
    "             'logs' : logs, \n",
    "             'logs_ki' : logs_ki, \n",
    "             'logs_kh' : logs_kh, \n",
    "             'tds' : tds,\n",
    "             'tds_ki' : tds_ki,\n",
    "             'tds_kh' : tds_kh,\n",
    "             'posteriors' : posteriors,\n",
    "             'posteriors_ki' : posteriors_ki,\n",
    "             'posteriors_kh' : posteriors_kh\n",
    "             })    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import delfi.distribution as dd\n",
    "import delfi.generator as dg\n",
    "import delfi.inference as infer\n",
    "import delfi.utils.io as io\n",
    "import delfi.summarystats as ds\n",
    "import lfimodels.glm.utils as utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from lfimodels.glm.GLM import GLM\n",
    "from lfimodels.glm.GLMStats import GLMStats\n",
    "from delfi.utils.viz import plot_pdf\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "seeds = np.arange(90, 110)\n",
    "duration = 500\n",
    "\n",
    "\n",
    "batch_specifier = '_bp'\n",
    "fit_specifier = '_pilot_test_05'\n",
    "\n",
    "\n",
    "for seed in seeds:\n",
    "    true_params, labels_params = utils.obs_params(a=a_)\n",
    "    obs = utils.obs_data(true_params, seed=seed, duration = duration)\n",
    "    obs_stats = utils.obs_stats(true_params, seed=seed, duration = duration)\n",
    "\n",
    "    rerun=False\n",
    "    \n",
    "    try:\n",
    "        assert rerun == False, 'rerun requested'\n",
    "        sam = np.load('sam_' + str(duration) + '_' + str(seed) + batch_specifier + '.npz')['arr_0']\n",
    "    except:\n",
    "        sam = utils.pg_mcmc(true_params, obs, duration = duration)\n",
    "        np.savez('sam_' + str(duration) + '_' + str(seed) + batch_specifier + '.npz', sam)\n",
    "\n",
    "    n_train = 5000\n",
    "    n_rounds = 4\n",
    "    minibatch = 100\n",
    "    epochs = 500\n",
    "    round_cl = 4\n",
    "\n",
    "    epochs_cbk = 5000\n",
    "    minibatch_cbk = n_train\n",
    "    \n",
    "    n_hiddens = [50] \n",
    "    convert_to_T = None\n",
    "    pilot_samples = 1000\n",
    "    svi = True\n",
    "    reg_lambda = 0.01\n",
    "    prior_norm = False\n",
    "    \n",
    "    if batch_specifier == '_bp':\n",
    "        smoothing_prior = utils.smoothing_prior_highVar\n",
    "    elif batch_specifier == '_cp':\n",
    "        smoothing_prior = utils.smoothing_prior    \n",
    "    \n",
    "    m = GLM(seed=seed, duration = duration)\n",
    "    p = smoothing_prior(n_params=m.n_params, seed=seed)\n",
    "    s = GLMStats(n_summary=m.n_params)\n",
    "    g = dg.Default(model=m, prior=p, summary=s)\n",
    "\n",
    "    res = infer.SNPE(g, \n",
    "                     obs=obs_stats, \n",
    "                     n_hiddens=n_hiddens, \n",
    "                     seed=seed, \n",
    "                     convert_to_T=convert_to_T, \n",
    "                     pilot_samples=pilot_samples,\n",
    "                     svi=svi,\n",
    "                     reg_lambda=reg_lambda,\n",
    "                     prior_norm=prior_norm)\n",
    "\n",
    "    logs, tds, posteriors = res.run(n_train=n_train, \n",
    "                                    n_rounds=n_rounds, \n",
    "                                    minibatch=minibatch, \n",
    "                                    epochs=epochs, \n",
    "                                    round_cl=round_cl, \n",
    "                                    epochs_cbk=epochs_cbk,\n",
    "                                    minibatch_cbk=minibatch_cbk,\n",
    "                                    kernel_loss=None)\n",
    "\n",
    "    m = GLM(seed=seed, duration = duration)\n",
    "    p = smoothing_prior(n_params=m.n_params, seed=seed)\n",
    "    s = GLMStats(n_summary=m.n_params)\n",
    "    g = dg.Default(model=m, prior=p, summary=s)\n",
    "    res_k = infer.SNPE(g, \n",
    "                     obs=obs_stats, \n",
    "                     n_hiddens=n_hiddens, \n",
    "                     seed=seed, \n",
    "                     convert_to_T=convert_to_T, \n",
    "                     pilot_samples=pilot_samples,\n",
    "                     svi=svi,\n",
    "                     reg_lambda=reg_lambda,\n",
    "                     prior_norm=prior_norm)\n",
    "\n",
    "    logs_k, tds_k, posteriors_k = res_k.run(n_train=n_train, \n",
    "                                    n_rounds=n_rounds, \n",
    "                                    minibatch=minibatch, \n",
    "                                    epochs=epochs, \n",
    "                                    round_cl=round_cl, \n",
    "                                    epochs_cbk=epochs_cbk,\n",
    "                                    minibatch_cbk=minibatch_cbk,\n",
    "                                    kernel_loss='x_kl')\n",
    "\n",
    "    m = GLM(seed=seed, duration = duration)\n",
    "    p = smoothing_prior(n_params=m.n_params, seed=seed)\n",
    "    s = GLMStats(n_summary=m.n_params)\n",
    "    g = dg.Default(model=m, prior=p, summary=s)\n",
    "    res_k2 = infer.SNPE(g, \n",
    "                     obs=obs_stats, \n",
    "                     n_hiddens=n_hiddens, \n",
    "                     seed=seed, \n",
    "                     convert_to_T=convert_to_T, \n",
    "                     pilot_samples=pilot_samples,\n",
    "                     svi=svi,\n",
    "                     reg_lambda=reg_lambda,\n",
    "                     prior_norm=prior_norm)\n",
    "\n",
    "    logs_k2, tds_k2, posteriors_k2 = res_k2.run(n_train=n_train, \n",
    "                                    n_rounds=n_rounds, \n",
    "                                    minibatch=minibatch, \n",
    "                                    epochs=epochs, \n",
    "                                    round_cl=round_cl, \n",
    "                                    epochs_cbk=epochs_cbk,\n",
    "                                    minibatch_cbk=minibatch_cbk,\n",
    "                                    kernel_loss='ess')\n",
    "    \n",
    "    np.save('check_kernels' + batch_specifier + fit_specifier + '_d' + str(duration) + '_' + str(seed),\n",
    "            {'seed': seed,\n",
    "             'duration' : duration, \n",
    "             'n_train' : n_train,\n",
    "             'n_rounds' : n_rounds,\n",
    "             'minibatch' : minibatch,\n",
    "             'epochs' : minibatch,\n",
    "\n",
    "             'epochs_cbk' : epochs_cbk,\n",
    "             'minibatch_cbk' : minibatch_cbk,\n",
    "             \n",
    "             'n_hiddens' : n_hiddens, \n",
    "             'convert_to_T' : convert_to_T, \n",
    "             'pilot_samples' : pilot_samples,\n",
    "             'svi' : svi,\n",
    "             'reg_lambda': reg_lambda,\n",
    "             'prior_norm': prior_norm,             \n",
    "             'round_cl' : round_cl,     \n",
    "             \n",
    "             'obs_stats' : obs_stats,\n",
    "             'true_params' : true_params,\n",
    "\n",
    "             'logs' : logs, \n",
    "             'logs_k' : logs_k, \n",
    "             'logs_k2' : logs_k2, \n",
    "             'tds' : tds,\n",
    "             'tds_k' : tds_k,\n",
    "             'tds_k2' : tds_k2,\n",
    "             'posteriors' : posteriors,\n",
    "             'posteriors_k' : posteriors_k,\n",
    "             'posteriors_k2' : posteriors_k2\n",
    "             })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import delfi.distribution as dd\n",
    "import delfi.generator as dg\n",
    "import delfi.inference as infer\n",
    "import delfi.utils.io as io\n",
    "import delfi.summarystats as ds\n",
    "import lfimodels.glm.utils as utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from lfimodels.glm.GLM import GLM\n",
    "from lfimodels.glm.GLMStats import GLMStats\n",
    "from delfi.utils.viz import plot_pdf\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "seeds = np.arange(90, 110)\n",
    "duration = 300\n",
    "\n",
    "\n",
    "batch_specifier = '_bp'\n",
    "a_ = 0.5\n",
    "fit_specifier = '_pilot_convT_small_05'\n",
    "\n",
    "\n",
    "for seed in seeds:\n",
    "    true_params, labels_params = utils.obs_params(a=a_)\n",
    "    obs = utils.obs_data(true_params, seed=seed, duration = duration)\n",
    "    obs_stats = utils.obs_stats(true_params, seed=seed, duration = duration)\n",
    "\n",
    "    rerun = False  # if False, will try loading file from disk\n",
    "\n",
    "    try:\n",
    "        assert rerun == False, 'rerun requested'\n",
    "        sam = np.load('sam_' + str(duration) + '_' + str(seed) + batch_specifier + '.npz')['arr_0']\n",
    "    except:\n",
    "        sam = utils.pg_mcmc(true_params, obs, duration = duration)\n",
    "        np.savez('sam_' + str(duration) + '_' + str(seed) + batch_specifier + '.npz', sam)\n",
    "\n",
    "    n_train = 3000\n",
    "    n_rounds = 10\n",
    "    minibatch = 100\n",
    "    epochs = 500\n",
    "    round_cl = 7\n",
    "    \n",
    "    epochs_cbk = 5000\n",
    "    minibatch_cbk = n_train\n",
    "    \n",
    "    n_hiddens = [5] \n",
    "    convert_to_T = 3\n",
    "    pilot_samples = 1000\n",
    "    svi = True\n",
    "    reg_lambda = 0.01\n",
    "    prior_norm = False\n",
    "    \n",
    "    if batch_specifier == '_bp':\n",
    "        smoothing_prior = utils.smoothing_prior_highVar\n",
    "    elif batch_specifier == '_cp':\n",
    "        smoothing_prior = utils.smoothing_prior    \n",
    "    \n",
    "    m = GLM(seed=seed, duration = duration)\n",
    "    p = smoothing_prior(n_params=m.n_params, seed=seed)\n",
    "    s = GLMStats(n_summary=m.n_params)\n",
    "    g = dg.Default(model=m, prior=p, summary=s)\n",
    "\n",
    "    res = infer.SNPE(g, \n",
    "                     obs=obs_stats, \n",
    "                     n_hiddens=n_hiddens, \n",
    "                     seed=seed, \n",
    "                     convert_to_T=convert_to_T, \n",
    "                     pilot_samples=pilot_samples,\n",
    "                     svi=svi,\n",
    "                     reg_lambda=reg_lambda,\n",
    "                     prior_norm=prior_norm)\n",
    "\n",
    "    logs, tds, posteriors = res.run(n_train=n_train, \n",
    "                                    n_rounds=n_rounds, \n",
    "                                    minibatch=minibatch, \n",
    "                                    epochs=epochs, \n",
    "                                    round_cl=round_cl, \n",
    "                                    epochs_cbk=epochs_cbk,\n",
    "                                    minibatch_cbk=minibatch_cbk,\n",
    "                                    kernel_loss=None)\n",
    "\n",
    "    m = GLM(seed=seed, duration = duration)\n",
    "    p = smoothing_prior(n_params=m.n_params, seed=seed)\n",
    "    s = GLMStats(n_summary=m.n_params)\n",
    "    g = dg.Default(model=m, prior=p, summary=s)\n",
    "    res_k = infer.SNPE(g, \n",
    "                     obs=obs_stats, \n",
    "                     n_hiddens=n_hiddens, \n",
    "                     seed=seed, \n",
    "                     convert_to_T=convert_to_T, \n",
    "                     pilot_samples=pilot_samples,\n",
    "                     svi=svi,\n",
    "                     reg_lambda=reg_lambda,\n",
    "                     prior_norm=prior_norm)\n",
    "\n",
    "    logs_k, tds_k, posteriors_k = res_k.run(n_train=n_train, \n",
    "                                    n_rounds=n_rounds, \n",
    "                                    minibatch=minibatch, \n",
    "                                    epochs=epochs, \n",
    "                                    round_cl=round_cl, \n",
    "                                    epochs_cbk=epochs_cbk,\n",
    "                                    minibatch_cbk=minibatch_cbk,\n",
    "                                    kernel_loss='x_kl')\n",
    "\n",
    "    m = GLM(seed=seed, duration = duration)\n",
    "    p = smoothing_prior(n_params=m.n_params, seed=seed)\n",
    "    s = GLMStats(n_summary=m.n_params)\n",
    "    g = dg.Default(model=m, prior=p, summary=s)\n",
    "    res_k2 = infer.SNPE(g, \n",
    "                     obs=obs_stats, \n",
    "                     n_hiddens=n_hiddens, \n",
    "                     seed=seed, \n",
    "                     convert_to_T=convert_to_T, \n",
    "                     pilot_samples=pilot_samples,\n",
    "                     svi=svi,\n",
    "                     reg_lambda=reg_lambda,\n",
    "                     prior_norm=prior_norm)\n",
    "\n",
    "    logs_k2, tds_k2, posteriors_k2 = res_k2.run(n_train=n_train, \n",
    "                                    n_rounds=n_rounds, \n",
    "                                    minibatch=minibatch, \n",
    "                                    epochs=epochs, \n",
    "                                    round_cl=round_cl, \n",
    "                                    epochs_cbk=epochs_cbk,\n",
    "                                    minibatch_cbk=minibatch_cbk,\n",
    "                                    kernel_loss='ess')\n",
    "    \n",
    "    np.save('check_kernels' + batch_specifier + fit_specifier + '_d' + str(duration) + '_' + str(seed),\n",
    "            {'seed': seed,\n",
    "             'duration' : duration, \n",
    "             'n_train' : n_train,\n",
    "             'n_rounds' : n_rounds,\n",
    "             'minibatch' : minibatch,\n",
    "             'epochs' : minibatch,\n",
    "\n",
    "             'epochs_cbk' : epochs_cbk,\n",
    "             'minibatch_cbk' : minibatch_cbk,\n",
    "             \n",
    "             'n_hiddens' : n_hiddens, \n",
    "             'convert_to_T' : convert_to_T, \n",
    "             'pilot_samples' : pilot_samples,\n",
    "             'svi' : svi,\n",
    "             'reg_lambda': reg_lambda,\n",
    "             'prior_norm': prior_norm,             \n",
    "             'round_cl' : round_cl,     \n",
    "             \n",
    "             'obs_stats' : obs_stats,\n",
    "             'true_params' : true_params,\n",
    "\n",
    "             'logs' : logs, \n",
    "             'logs_k' : logs_k, \n",
    "             'logs_k2' : logs_k2, \n",
    "             'tds' : tds,\n",
    "             'tds_k' : tds_k,\n",
    "             'tds_k2' : tds_k2,\n",
    "             'posteriors' : posteriors,\n",
    "             'posteriors_k' : posteriors_k,\n",
    "             'posteriors_k2' : posteriors_k2\n",
    "             })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import delfi.distribution as dd\n",
    "import delfi.generator as dg\n",
    "import delfi.inference as infer\n",
    "import delfi.utils.io as io\n",
    "import delfi.summarystats as ds\n",
    "import lfimodels.glm.utils as utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from lfimodels.glm.GLM import GLM\n",
    "from lfimodels.glm.GLMStats import GLMStats\n",
    "from delfi.utils.viz import plot_pdf\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "seeds = np.arange(90, 110)\n",
    "duration = 300\n",
    "\n",
    "\n",
    "batch_specifier = '_bp'\n",
    "a_ = 0.5\n",
    "fit_specifier = '_pilot_convT_small_05'\n",
    "\n",
    "if batch_specifier == '_bp':\n",
    "    smoothing_prior = utils.smoothing_prior_highVar\n",
    "elif batch_specifier == '_cp':\n",
    "    smoothing_prior = utils.smoothing_prior    \n",
    "    \n",
    "for seed in seeds:\n",
    "    true_params, labels_params = utils.obs_params(a=a_)\n",
    "    obs = utils.obs_data(true_params, seed=seed, duration = duration)\n",
    "    obs_stats = utils.obs_stats(true_params, seed=seed, duration = duration)\n",
    "\n",
    "    rerun = True  # if False, will try loading file from disk\n",
    "\n",
    "    try:\n",
    "        assert rerun == False, 'rerun requested'\n",
    "        sam = np.load('sam_' + str(duration) + '_' + str(seed) + batch_specifier + '.npz')['arr_0']\n",
    "    except:\n",
    "        sam = utils.pg_mcmc(true_params, obs, duration = duration, prior=smoothing_prior)\n",
    "        np.savez('sam_' + str(duration) + '_' + str(seed) + batch_specifier + '.npz', sam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run with Gaussian proposals\n",
    "for r in range(len(tds_k)):\n",
    "    plot_pdf(posteriors[r],\n",
    "             pdf2=posteriors_k[r], \n",
    "             lims=[-2,2], \n",
    "             samples=sam, \n",
    "             gt=true_params, \n",
    "             figsize=(9,9));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run with Gaussian proposals\n",
    "for r in range(len(tds_k)):\n",
    "    plot_pdf(posteriors[r],\n",
    "             pdf2=posteriors_k2[r], \n",
    "             lims=[-2,2], \n",
    "             samples=sam, \n",
    "             gt=true_params, \n",
    "             figsize=(9,9));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
