{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## learning kernels for the GLM example. \n",
    "\n",
    "we optimize kernels such that\n",
    "$ K(x_n, x_0) p(\\theta_n) / \\tilde{p}(\\theta_n) \\approx 1$. \n",
    "\n",
    "Spoiler:\n",
    "starts to work.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# approach\n",
    "\n",
    "The above problem doesn't require MDNs at all. \n",
    "Once prior, proposal, kernel and simulator are fixed and we drew an artificial dataset $(x_n, \\theta_n)$, we're good to play. \n",
    "Let's run SNPE as usual, note down the data-sets $(x_n, \\theta_n)$, proposal priors and importance weights it produced over rounds, and afterwards play with the kernel on those fixed targets. \n",
    "\n",
    "- Remark: results look a lot worse if we convert to Students-t distributions. Could be that kernel shape (squared-exponential in $x$) has to match proposal-prior shape (squared in $\\theta$ for students-T with df=3)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to do:\n",
    "- nonlinear kernels: $k(x, x_0) \\propto \\exp - \\frac{1}{2} || F(x) - F(x_0) ||^2$ \n",
    "- full (correlated) covariance matrices\n",
    "- in fact, run full covariance matrices as $F(x) = Ax$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try out a bunch of simple squared losses. \n",
    "\n",
    "### 1. basic squared loss\n",
    "\n",
    "argmin $ \\sum_n \\left( 1 - \\frac{K(x_n, x_0) p(\\theta_n)}{\\tilde{p}(\\theta_n)} \\right)^2 $\n",
    "\n",
    "### 2. locality-preserving loss\n",
    "\n",
    "argmin $ D_{KL}(\\tilde{p}(x) || p_K(x) ) \\approx $ argmin $\\log \\frac{1}{N} \\sum_n \\frac{p(\\theta_n)}{\\tilde{p}(\\theta_n)} K(x_n, x_0) - \\frac{1}{N} \\sum_n \\log K(x_n, x_0) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import delfi.distribution as dd\n",
    "import delfi.generator as dg\n",
    "import delfi.inference as infer\n",
    "import delfi.utils.io as io\n",
    "import delfi.summarystats as ds\n",
    "import lfimodels.glm.utils as utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from lfimodels.glm.GLM import GLM\n",
    "from lfimodels.glm.GLMStats import GLMStats\n",
    "from delfi.utils.viz import plot_pdf\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "seed = 98\n",
    "duration = 300\n",
    "\n",
    "true_params, labels_params = utils.obs_params()\n",
    "obs = utils.obs_data(true_params, seed=seed, duration=duration)\n",
    "obs_stats = utils.obs_stats(true_params, seed=seed, duration=duration)\n",
    "\n",
    "rerun = False  # if False, will try loading file from disk\n",
    "\n",
    "try:\n",
    "    assert rerun == False, 'rerun requested'\n",
    "    sam = np.load('sam.npz')['arr_0']\n",
    "except:\n",
    "    sam = utils.pg_mcmc(true_params, obs, duration=duration)\n",
    "    np.savez('sam.npz', sam)\n",
    "\n",
    "n_train=3000 \n",
    "n_rounds=10\n",
    "minibatch=100 \n",
    "epochs=500   \n",
    "round_cl=999\n",
    "\n",
    "minibatch_cbk=n_train\n",
    "epochs_cbk=5000\n",
    "\n",
    "n_hiddens = [5]\n",
    "convert_to_T = None\n",
    "pilot_samples = 1000\n",
    "svi=True\n",
    "reg_lambda=0.01\n",
    "prior_norm=False\n",
    "    \n",
    "m = GLM(duration=duration, seed=seed)\n",
    "p = utils.smoothing_prior(n_params=m.n_params, seed=seed)\n",
    "s = GLMStats(n_summary=m.n_params)\n",
    "g = dg.Default(model=m, prior=p, summary=s)\n",
    "res = infer.SNPE(g, \n",
    "                 obs=obs_stats, \n",
    "                 n_hiddens=n_hiddens, \n",
    "                 seed=seed, \n",
    "                 convert_to_T=convert_to_T, \n",
    "                 pilot_samples=pilot_samples,\n",
    "                 svi=svi,\n",
    "                 reg_lambda=reg_lambda,\n",
    "                 prior_norm=prior_norm)\n",
    "\n",
    "logs, tds, posteriors = res.run(n_train=n_train, \n",
    "                                n_rounds=n_rounds, \n",
    "                                minibatch=minibatch, \n",
    "                                epochs=epochs, \n",
    "                                minibatch_cbk=minibatch_cbk,\n",
    "                                epochs_cbk=epochs_cbk,                                        \n",
    "                                round_cl=round_cl, \n",
    "                                kernel_loss=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# version with learned kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = GLM(duration=duration, seed=seed)\n",
    "p = utils.smoothing_prior(n_params=m.n_params, seed=seed)\n",
    "s = GLMStats(n_summary=m.n_params)\n",
    "g = dg.Default(model=m, prior=p, summary=s)\n",
    "res_k = infer.SNPE(g, \n",
    "                 obs=obs_stats, \n",
    "                 n_hiddens=n_hiddens, \n",
    "                 seed=seed, \n",
    "                 convert_to_T=convert_to_T, \n",
    "                 pilot_samples=pilot_samples,\n",
    "                 svi=svi,\n",
    "                 reg_lambda=reg_lambda,\n",
    "                 prior_norm=prior_norm)\n",
    "\n",
    "logs_k, tds_k, posteriors_k = res_k.run(n_train=n_train, \n",
    "                                n_rounds=n_rounds, \n",
    "                                minibatch=minibatch, \n",
    "                                epochs=epochs, \n",
    "                                minibatch_cbk=minibatch_cbk,\n",
    "                                epochs_cbk=epochs_cbk,                                        \n",
    "                                round_cl=round_cl, \n",
    "                                kernel_loss='x_kl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iws = tds[1][2]\n",
    "iws /= iws.sum()\n",
    "\n",
    "kiws = tds_k[1][2]\n",
    "kiws /= kiws.sum()\n",
    "1/np.sum(iws**2), 1/np.sum(kiws**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from delfi.kernel.Kernel_learning import kernel_opt\n",
    "import lasagne.layers as ll\n",
    "import lasagne.updates as lu\n",
    "import theano \n",
    "\n",
    "\n",
    "kernel_loss = 'x_kl'\n",
    "trn_data = tds_k[1]\n",
    "n_train_round = n_train\n",
    "iws = res_k.generator.prior.eval(trn_data[0], log=False) / posteriors_k[0].eval(trn_data[0], log=False)\n",
    "\n",
    "ks = list(res_k.network.layer.keys())\n",
    "layer_index = 0\n",
    "hl = res_k.network.layer[ks[layer_index]]\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "clrs = ['k', 'r']\n",
    "\n",
    "iws_  = iws/iws.sum()\n",
    "print('ESS pre: ', 1./sum(iws_**2))\n",
    "for z in range(2):\n",
    "    \n",
    "    #zscore = False if z==0 else True\n",
    "    #epochs__ = 2000\n",
    "    #minibatch__ = n_train\n",
    "    \n",
    "    zscore=True\n",
    "    if z==1:\n",
    "        epochs__ = 2000\n",
    "        minibatch__ = n_train\n",
    "    elif z==0:\n",
    "        epochs__ = 2000\n",
    "        minibatch__=minibatch \n",
    "\n",
    "    \n",
    "    print('condition :' + str(z))\n",
    "    print('minibatch =' + str(minibatch__))\n",
    "    print('epochs =' + str(epochs__))\n",
    "    stats = trn_data[1].reshape(n_train_round,-1).copy()\n",
    "    obs_z = obs_stats.copy()\n",
    "    if zscore: \n",
    "        obs_z = ( obs_z - res_k.stats_mean) / res_k.stats_std\n",
    "        #stats = ( stats - stats.mean(axis=0)) / stats.std(axis=0)\n",
    "    stat_features = theano.function(\n",
    "        inputs=[res_k.network.stats],\n",
    "        outputs=ll.get_output(hl))\n",
    "    fstats = stat_features(stats)\n",
    "    fobs_z = stat_features(obs_z)\n",
    "\n",
    "    \n",
    "    for r in range(10):\n",
    "        cbkrnl, cbl = kernel_opt(\n",
    "            iws=iws.astype(np.float32), \n",
    "            stats=fstats,\n",
    "            obs=fobs_z, \n",
    "            kernel_loss=kernel_loss, \n",
    "            epochs=epochs__, \n",
    "            minibatch=minibatch__, \n",
    "            stop_on_nan=False,\n",
    "            seed=res.gen_newseed(), \n",
    "            step=lu.adam,\n",
    "            monitor=res.monitor_dict_from_names(None))\n",
    "\n",
    "        kiws = iws * cbkrnl.eval(fstats)\n",
    "\n",
    "        kiws_ = kiws/kiws.sum()\n",
    "        print('ESS post:', 1./sum(kiws_**2))\n",
    "\n",
    "        plt.subplot(1,3,1)\n",
    "        plt.plot(cbl, color=clrs[z])\n",
    "        plt.title('final loss' + str(cbl[-1]))\n",
    "        #plt.subplot(1,3,2)\n",
    "        #plt.plot(cbkrnl.A / cbkrnl.A.sum(), color=clrs[z])\n",
    "        plt.subplot(1,3,2)\n",
    "        if zscore:\n",
    "            plt.plot(cbkrnl.A / trn_data[1].reshape(n_train_round,-1).copy().var(axis=0), color=clrs[z])\n",
    "        else:\n",
    "            plt.plot(cbkrnl.A , color=clrs[z])\n",
    "        plt.subplot(1,3,3)\n",
    "        if z==0:\n",
    "            x_ = cbkrnl.eval(fstats)\n",
    "        elif z==1:\n",
    "            y_ = cbkrnl.eval(fstats)\n",
    "            plt.plot(x_, y_, '.')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = GLM(duration=duration, seed=seed)\n",
    "p = utils.smoothing_prior(n_params=m.n_params, seed=seed)\n",
    "s = GLMStats(n_summary=m.n_params)\n",
    "g = dg.Default(model=m, prior=p, summary=s)\n",
    "res_k2 = infer.SNPE(g, \n",
    "                 obs=obs_stats, \n",
    "                 n_hiddens=n_hiddens, \n",
    "                 seed=seed, \n",
    "                 convert_to_T=convert_to_T, \n",
    "                 pilot_samples=pilot_samples,\n",
    "                 svi=svi,\n",
    "                 reg_lambda=reg_lambda,\n",
    "                 prior_norm=prior_norm)\n",
    "\n",
    "logs_k2, tds_k2, posteriors_k2 = res_k2.run(n_train=n_train, \n",
    "                                n_rounds=n_rounds, \n",
    "                                minibatch=minibatch, \n",
    "                                epochs=epochs, \n",
    "                                minibatch_cbk=minibatch_cbk,\n",
    "                                epochs_cbk=epochs_cbk,                                        \n",
    "                                round_cl=round_cl, \n",
    "                                kernel_loss='ess')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iws = tds[1][2]\n",
    "iws /= iws.sum()\n",
    "\n",
    "kiws = tds_k2[1][2]\n",
    "kiws /= kiws.sum()\n",
    "1/np.sum(iws**2), 1/np.sum(kiws**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from delfi.kernel.Kernel_learning import kernel_opt\n",
    "import lasagne.layers as ll\n",
    "import lasagne.updates as lu\n",
    "import theano \n",
    "\n",
    "\n",
    "kernel_loss = 'ess'\n",
    "trn_data = tds_k[1]\n",
    "n_train_round = n_train\n",
    "iws = res_k.generator.prior.eval(trn_data[0], log=False) / posteriors_k[0].eval(trn_data[0], log=False)\n",
    "\n",
    "ks = list(res_k.network.layer.keys())\n",
    "layer_index = 0\n",
    "hl = res_k.network.layer[ks[layer_index]]\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "clrs = ['k', 'r']\n",
    "\n",
    "iws_  = iws/iws.sum()\n",
    "print('ESS pre: ', 1./sum(iws_**2))\n",
    "for z in range(2):\n",
    "    \n",
    "    #zscore = False if z==0 else True\n",
    "    #epochs__ = 2000\n",
    "    #minibatch__ = n_train\n",
    "    \n",
    "    zscore=True\n",
    "    if z==1:\n",
    "        epochs__ = 2000\n",
    "        minibatch__ = n_train\n",
    "    elif z==0:\n",
    "        epochs__ = 2000\n",
    "        minibatch__=minibatch \n",
    "\n",
    "    \n",
    "    print('zscoring =' + str(z))\n",
    "    print('minibatch =' + str(minibatch__))\n",
    "    print('epochs =' + str(epochs__))\n",
    "    stats = trn_data[1].reshape(n_train_round,-1).copy()\n",
    "    obs_z = obs_stats.copy()\n",
    "    if zscore: \n",
    "        obs_z = ( obs_z - res_k.stats_mean) / res_k.stats_std\n",
    "        #stats = ( stats - stats.mean(axis=0)) / stats.std(axis=0)\n",
    "    stat_features = theano.function(\n",
    "        inputs=[res_k.network.stats],\n",
    "        outputs=ll.get_output(hl))\n",
    "    fstats = stat_features(stats)\n",
    "    fobs_z = stat_features(obs_z)\n",
    "\n",
    "    \n",
    "    for r in range(10):\n",
    "        cbkrnl, cbl = kernel_opt(\n",
    "            iws=iws.astype(np.float32), \n",
    "            stats=fstats,\n",
    "            obs=fobs_z, \n",
    "            kernel_loss=kernel_loss, \n",
    "            epochs=epochs__, \n",
    "            minibatch=minibatch__, \n",
    "            stop_on_nan=False,\n",
    "            seed=res.gen_newseed(), \n",
    "            step=lu.adam,\n",
    "            monitor=res.monitor_dict_from_names(None))\n",
    "\n",
    "        kiws = iws * cbkrnl.eval(fstats)\n",
    "\n",
    "        kiws_ = kiws/kiws.sum()\n",
    "        print('ESS post:', 1./sum(kiws_**2))\n",
    "\n",
    "        plt.subplot(1,3,1)\n",
    "        plt.plot(cbl, color=clrs[z])\n",
    "        plt.title('final loss' + str(cbl[-1]))\n",
    "        #plt.subplot(1,3,2)\n",
    "        #plt.plot(cbkrnl.A / cbkrnl.A.sum(), color=clrs[z])\n",
    "        plt.subplot(1,3,2)\n",
    "        if zscore:\n",
    "            plt.plot(cbkrnl.A / trn_data[1].reshape(n_train_round,-1).copy().var(axis=0), color=clrs[z])\n",
    "        else:\n",
    "            plt.plot(cbkrnl.A , color=clrs[z])\n",
    "        plt.subplot(1,3,3)\n",
    "        if z==0:\n",
    "            x_ = cbkrnl.eval(fstats)\n",
    "        elif z==1:\n",
    "            y_ = cbkrnl.eval(fstats)\n",
    "            plt.plot(x_, y_, '.')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(fstats.mean(axis=0), 'k')\n",
    "plt.plot(fobs_z.flatten(), 'ro-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for r in range(n_rounds):\n",
    "    plt.plot(logs[r]['loss'])\n",
    "    plt.plot(logs_k[r]['loss'])\n",
    "    plt.plot(logs_k2[r]['loss'])\n",
    "    plt.legend(['raw', 'x_kl', 'max_ess'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn\n",
    "\n",
    "\n",
    "sets = [tds, tds_k, tds_k2]\n",
    "\n",
    "ess   = np.zeros((len(tds), 3))\n",
    "mu_   = np.zeros((len(tds), 3, obs_stats.size)) \n",
    "sig2_ = np.zeros((len(tds), 3, obs_stats.size))\n",
    "sig2e = np.zeros((len(tds), 3, obs_stats.size))\n",
    "\n",
    "for r in range(len(tds)):\n",
    "    for i in range(3):\n",
    "        w = sets[i][r][2].reshape(-1,1)\n",
    "        w /= w.sum()\n",
    "        ess[r, i] = 1./np.sum(w**2)\n",
    "\n",
    "        stats = sets[i][r][1]\n",
    "        sig2e[r, i, :] = np.var( stats, axis = 0)\n",
    "        mu_[r, i, :]   = np.sum( w * stats,                   axis=0).reshape(1,-1)\n",
    "        sig2_[r, i, :] = np.sum( w * (stats-mu_[r, i, :])**2, axis=0)    \n",
    "            \n",
    "plt.plot(np.arange(1, len(tds)), ess[1:,:])\n",
    "plt.legend(['raw iws', 'iws + x_kl', 'iws + max_ess', 'unweighted'])\n",
    "plt.xlabel('round')\n",
    "plt.ylabel('effective sample size')\n",
    "plt.show()    \n",
    "\n",
    "\"\"\"\n",
    "plt.figure(figsize=(12,16))\n",
    "for i in range(10):\n",
    "    plt.subplot(5,2,i+1)\n",
    "    plt.plot(np.arange(0,len(tds)), sig2e[:, :, i], '--')\n",
    "    plt.plot(np.arange(0,len(tds)), sig2_[:,:,i], linewidth=1.5)    \n",
    "    plt.legend(['raw', 'x_kl', 'max_ess'])\n",
    "plt.show()    \n",
    "\"\"\"\n",
    "plt.figure(figsize=(12,16))\n",
    "for r in range(1,len(tds)):\n",
    "    plt.subplot(2,2,r)\n",
    "    plt.plot(sig2_[r,:,:].T, linewidth=1.5)    \n",
    "    plt.plot(sig2e[r,1,:].T, 'k--')\n",
    "    plt.xlabel('# summary statistic')\n",
    "    plt.ylabel('empirical variance')\n",
    "    plt.title('SNPE round #' + str(r+1))\n",
    "    plt.legend(['raw iws', 'iws + x_kl', 'iws + max_ess', 'unweighted'])\n",
    "plt.show()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run with Gaussian proposals\n",
    "for r in range(len(tds_k)):\n",
    "    plot_pdf(posteriors[r],\n",
    "             pdf2=posteriors_k[r], \n",
    "             lims=[-2,2], \n",
    "             samples=sam, \n",
    "             gt=true_params, \n",
    "             resolution=100,\n",
    "             figsize=(9,9));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run with Gaussian proposals\n",
    "for r in range(len(tds_k)):\n",
    "    plot_pdf(posteriors[r],\n",
    "             pdf2=posteriors_k2[r], \n",
    "             lims=[-2,2], \n",
    "             samples=sam, \n",
    "             gt=true_params, \n",
    "             resolution=100,\n",
    "             figsize=(9,9));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# run with Gaussian proposals\n",
    "for r in range(len(tds_k)):\n",
    "    plot_pdf(posteriors[r],\n",
    "             pdf2=posteriors_k[r], \n",
    "             lims=[-2,2], \n",
    "             samples=sam, \n",
    "             gt=true_params, \n",
    "             resolution=100,\n",
    "             figsize=(9,9));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# run with Gaussian proposals\n",
    "for r in range(len(tds_k)):\n",
    "    plot_pdf(posteriors[r],\n",
    "             pdf2=posteriors_k2[r], \n",
    "             lims=[-2,2], \n",
    "             samples=sam, \n",
    "             gt=true_params, \n",
    "             resolution=100,\n",
    "             figsize=(9,9));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# run with Gaussian proposals\n",
    "for r in range(len(tds_k)):\n",
    "    plot_pdf(posteriors[r],\n",
    "             pdf2=posteriors_k[r], \n",
    "             lims=[-2,2], \n",
    "             samples=sam, \n",
    "             gt=true_params, \n",
    "             resolution=100,\n",
    "             figsize=(9,9));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# run with Gaussian proposals\n",
    "for r in range(len(tds_k)):\n",
    "    plot_pdf(posteriors[r],\n",
    "             pdf2=posteriors_k2[r], \n",
    "             lims=[-2,2], \n",
    "             samples=sam, \n",
    "             gt=true_params, \n",
    "             resolution=100,\n",
    "             figsize=(9,9));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# run with Gaussian proposals\n",
    "for r in range(len(tds_k)):\n",
    "    plot_pdf(posteriors[r],\n",
    "             pdf2=posteriors_k[r], \n",
    "             lims=[-2,2], \n",
    "             samples=sam, \n",
    "             gt=true_params, \n",
    "             resolution=100,\n",
    "             figsize=(9,9));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# run with Gaussian proposals\n",
    "for r in range(len(tds_k)):\n",
    "    plot_pdf(posteriors[r],\n",
    "             pdf2=posteriors_k2[r], \n",
    "             lims=[-2,2], \n",
    "             samples=sam, \n",
    "             gt=true_params, \n",
    "             resolution=100,\n",
    "             figsize=(9,9));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# run with Gaussian proposals\n",
    "for r in range(len(tds_k)):\n",
    "    plot_pdf(posteriors[r],\n",
    "             pdf2=posteriors_k[r], \n",
    "             lims=[-2,2], \n",
    "             samples=sam, \n",
    "             gt=true_params, \n",
    "             resolution=100,\n",
    "             figsize=(9,9));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# run with Gaussian proposals\n",
    "for r in range(len(tds_k)):\n",
    "    plot_pdf(posteriors[r],\n",
    "             pdf2=posteriors_k2[r], \n",
    "             lims=[-2,2], \n",
    "             samples=sam, \n",
    "             gt=true_params, \n",
    "             resolution=100,             \n",
    "             figsize=(9,9));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import theano\n",
    "import lasagne.layers as ll\n",
    "\n",
    "network = res.network\n",
    "inputs  = tds[0][1]\n",
    "obs_z   = (obs_stats - res.stats_mean) / res.stats_std\n",
    "\n",
    "ks = list(network.layer.keys())\n",
    "hiddens = np.where([i[:6]=='hidden' for i in ks])[0]\n",
    "layer_index = hiddens[0]\n",
    "hl = network.layer[ks[layer_index]]\n",
    "print(hl.name)\n",
    "\n",
    "f_eval = theano.function(\n",
    "    inputs=[network.stats],\n",
    "    outputs=ll.get_output(hl))\n",
    "\n",
    "plt.plot(f_eval(inputs)[:, :].T, 'k.')\n",
    "plt.plot(f_eval(obs_z).reshape(-1), 'ro')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "layer_index = hiddens[-1]\n",
    "hl = network.layer[ks[layer_index]]\n",
    "print(hl.name)\n",
    "\n",
    "f_eval = theano.function(\n",
    "    inputs=[network.stats],\n",
    "    outputs=ll.get_output(hl))\n",
    "\n",
    "plt.plot(f_eval(inputs)[:, :].T, 'k.')\n",
    "plt.plot(f_eval(obs_z).reshape(-1), 'ro')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(network.layer['mixture_means'])\n",
    "f_eval = theano.function(\n",
    "    inputs=[network.stats],\n",
    "    outputs=network.dms)\n",
    "plt.plot(f_eval(inputs)[0].T, 'k.')\n",
    "plt.plot(f_eval( obs_z)[0].T, 'ro')\n",
    "plt.plot(true_params, 'bx', ms=5)\n",
    "plt.show()\n",
    "\n",
    "print(f_eval( obs_z)[0])\n",
    "print(posteriors[-1].xs[0].m)\n",
    "print(true_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import theano\n",
    "import lasagne.layers as ll\n",
    "\n",
    "network = res.network\n",
    "inputs  = tds[-1][1]\n",
    "obs_z   = (obs_stats - res.stats_mean) / res.stats_std\n",
    "\n",
    "ks = list(network.layer.keys())\n",
    "hiddens = np.where([i[:6]=='hidden' for i in ks])[0]\n",
    "layer_index = hiddens[0]\n",
    "hl = network.layer[ks[layer_index]]\n",
    "print(hl.name)\n",
    "\n",
    "f_eval = theano.function(\n",
    "    inputs=[network.stats],\n",
    "    outputs=ll.get_output(hl))\n",
    "\n",
    "plt.plot(f_eval(inputs)[:, :].T, 'k.')\n",
    "plt.plot(f_eval(obs_z).reshape(-1), 'ro')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "layer_index = hiddens[-1]\n",
    "hl = network.layer[ks[layer_index]]\n",
    "print(hl.name)\n",
    "\n",
    "f_eval = theano.function(\n",
    "    inputs=[network.stats],\n",
    "    outputs=ll.get_output(hl))\n",
    "\n",
    "plt.plot(f_eval(inputs)[:, :].T, 'k.')\n",
    "plt.plot(f_eval(obs_z).reshape(-1), 'ro')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(network.layer['mixture_means'])\n",
    "f_eval = theano.function(\n",
    "    inputs=[network.stats],\n",
    "    outputs=network.dms)\n",
    "plt.plot(f_eval(inputs)[0].T, 'k.')\n",
    "plt.plot(f_eval( obs_z)[0].T, 'ro')\n",
    "plt.plot(true_params, 'bx', ms=5)\n",
    "plt.show()\n",
    "\n",
    "print(f_eval( obs_z)[0])\n",
    "print(posteriors[-1].xs[0].m)\n",
    "print(true_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distm = np.zeros((n_rounds, 3))\n",
    "dists = np.zeros((n_rounds, 3))\n",
    "\n",
    "for r in range(n_rounds):\n",
    "\n",
    "    distm[r,:] = (np.sqrt( np.sum( (posteriors[r].xs[0].m    - sam.mean(axis=1))**2 ) ),\n",
    "           np.sqrt( np.sum( (posteriors_k[r].xs[0].m  - sam.mean(axis=1))**2 ) ),\n",
    "           np.sqrt( np.sum( (posteriors_k2[r].xs[0].m - sam.mean(axis=1))**2 ) ))\n",
    "           \n",
    "    dists[r,:] = (np.sqrt( np.sum( (np.diag(posteriors[r].xs[0].S) - sam.var(axis=1))**2 ) ),\n",
    "           np.sqrt( np.sum( (np.diag(posteriors_k[r].xs[0].S) - sam.var(axis=1))**2 ) ), \n",
    "           np.sqrt( np.sum( (np.diag(posteriors_k2[r].xs[0].S) - sam.var(axis=1))**2 ) ))        \n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(distm[1:,0].T, 'r')\n",
    "plt.plot(distm[1:,1].T, 'b')\n",
    "plt.plot(distm[1:,2].T, 'g')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(dists[1:,0].T, 'r')\n",
    "plt.plot(dists[1:,1].T, 'b')\n",
    "plt.plot(dists[1:,2].T, 'g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_k[3]['cbkrnl'].A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_k2[2]['cbkrnl'].A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distm = np.zeros((n_rounds, 3))\n",
    "dists = np.zeros((n_rounds, 3))\n",
    "\n",
    "for r in range(n_rounds):\n",
    "\n",
    "    distm[r,:] = (np.sqrt( np.sum( (posteriors[r].xs[0].m    - sam.mean(axis=1))**2 ) ),\n",
    "           np.sqrt( np.sum( (posteriors_k[r].xs[0].m  - sam.mean(axis=1))**2 ) ),\n",
    "           np.sqrt( np.sum( (posteriors_k2[r].xs[0].m - sam.mean(axis=1))**2 ) ))\n",
    "           \n",
    "    dists[r,:] = (np.sqrt( np.sum( (np.diag(posteriors[r].xs[0].S) - sam.var(axis=1))**2 ) ),\n",
    "           np.sqrt( np.sum( (np.diag(posteriors_k[r].xs[0].S) - sam.var(axis=1))**2 ) ), \n",
    "           np.sqrt( np.sum( (np.diag(posteriors_k2[r].xs[0].S) - sam.var(axis=1))**2 ) ))        \n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(distm[1:,0].T, 'r')\n",
    "plt.plot(distm[1:,1].T, 'b')\n",
    "plt.plot(distm[1:,2].T, 'g')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(dists[1:,0].T, 'r')\n",
    "plt.plot(dists[1:,1].T, 'b')\n",
    "plt.plot(dists[1:,2].T, 'g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distm = np.zeros((n_rounds, 3))\n",
    "dists = np.zeros((n_rounds, 3))\n",
    "\n",
    "for r in range(n_rounds):\n",
    "\n",
    "    distm[r,:] = (np.sqrt( np.sum( (posteriors[r].xs[0].m    - sam.mean(axis=1))**2 ) ),\n",
    "           np.sqrt( np.sum( (posteriors_k[r].xs[0].m  - sam.mean(axis=1))**2 ) ),\n",
    "           np.sqrt( np.sum( (posteriors_k2[r].xs[0].m - sam.mean(axis=1))**2 ) ))\n",
    "           \n",
    "    dists[r,:] = (np.sqrt( np.sum( (np.diag(posteriors[r].xs[0].S) - sam.var(axis=1))**2 ) ),\n",
    "           np.sqrt( np.sum( (np.diag(posteriors_k[r].xs[0].S) - sam.var(axis=1))**2 ) ), \n",
    "           np.sqrt( np.sum( (np.diag(posteriors_k2[r].xs[0].S) - sam.var(axis=1))**2 ) ))        \n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(distm[1:,0].T, 'r')\n",
    "plt.plot(distm[1:,1].T, 'b')\n",
    "plt.plot(distm[1:,2].T, 'g')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(dists[1:,0].T, 'r')\n",
    "plt.plot(dists[1:,1].T, 'b')\n",
    "plt.plot(dists[1:,2].T, 'g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distm = np.zeros((n_rounds, 3))\n",
    "dists = np.zeros((n_rounds, 3))\n",
    "\n",
    "for r in range(n_rounds):\n",
    "\n",
    "    distm[r,:] = (np.sqrt( np.sum( (posteriors[r].xs[0].m    - sam.mean(axis=1))**2 ) ),\n",
    "           np.sqrt( np.sum( (posteriors_k[r].xs[0].m  - sam.mean(axis=1))**2 ) ),\n",
    "           np.sqrt( np.sum( (posteriors_k2[r].xs[0].m - sam.mean(axis=1))**2 ) ))\n",
    "           \n",
    "    dists[r,:] = (np.sqrt( np.sum( (np.diag(posteriors[r].xs[0].S) - sam.var(axis=1))**2 ) ),\n",
    "           np.sqrt( np.sum( (np.diag(posteriors_k[r].xs[0].S) - sam.var(axis=1))**2 ) ), \n",
    "           np.sqrt( np.sum( (np.diag(posteriors_k2[r].xs[0].S) - sam.var(axis=1))**2 ) ))        \n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(distm[1:,0].T, 'r')\n",
    "plt.plot(distm[1:,1].T, 'b')\n",
    "plt.plot(distm[1:,2].T, 'g')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(dists[1:,0].T, 'r')\n",
    "plt.plot(dists[1:,1].T, 'b')\n",
    "plt.plot(dists[1:,2].T, 'g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distm = np.zeros((n_rounds, 3))\n",
    "dists = np.zeros((n_rounds, 3))\n",
    "\n",
    "for r in range(n_rounds):\n",
    "\n",
    "    distm[r,:] = (np.sqrt( np.sum( (posteriors[r].xs[0].m    - sam.mean(axis=1))**2 ) ),\n",
    "           np.sqrt( np.sum( (posteriors_k[r].xs[0].m  - sam.mean(axis=1))**2 ) ),\n",
    "           np.sqrt( np.sum( (posteriors_k2[r].xs[0].m - sam.mean(axis=1))**2 ) ))\n",
    "           \n",
    "    dists[r,:] = (np.sqrt( np.sum( (np.diag(posteriors[r].xs[0].S) - sam.var(axis=1))**2 ) ),\n",
    "           np.sqrt( np.sum( (np.diag(posteriors_k[r].xs[0].S) - sam.var(axis=1))**2 ) ), \n",
    "           np.sqrt( np.sum( (np.diag(posteriors_k2[r].xs[0].S) - sam.var(axis=1))**2 ) ))        \n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(distm[1:,0].T, 'r')\n",
    "plt.plot(distm[1:,1].T, 'b')\n",
    "plt.plot(distm[1:,2].T, 'g')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(dists[1:,0].T, 'r')\n",
    "plt.plot(dists[1:,1].T, 'b')\n",
    "plt.plot(dists[1:,2].T, 'g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distm = np.zeros((n_rounds, 3))\n",
    "dists = np.zeros((n_rounds, 3))\n",
    "\n",
    "for r in range(n_rounds):\n",
    "\n",
    "    distm[r,:] = (np.sqrt( np.sum( (posteriors[r].xs[0].m    - sam.mean(axis=1))**2 ) ),\n",
    "           np.sqrt( np.sum( (posteriors_k[r].xs[0].m  - sam.mean(axis=1))**2 ) ),\n",
    "           np.sqrt( np.sum( (posteriors_k2[r].xs[0].m - sam.mean(axis=1))**2 ) ))\n",
    "           \n",
    "    dists[r,:] = (np.sqrt( np.sum( (np.diag(posteriors[r].xs[0].S) - sam.var(axis=1))**2 ) ),\n",
    "           np.sqrt( np.sum( (np.diag(posteriors_k[r].xs[0].S) - sam.var(axis=1))**2 ) ), \n",
    "           np.sqrt( np.sum( (np.diag(posteriors_k2[r].xs[0].S) - sam.var(axis=1))**2 ) ))        \n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(distm[1:,0].T, 'r')\n",
    "plt.plot(distm[1:,1].T, 'b')\n",
    "plt.plot(distm[1:,2].T, 'g')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(dists[1:,0].T, 'r')\n",
    "plt.plot(dists[1:,1].T, 'b')\n",
    "plt.plot(dists[1:,2].T, 'g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in range(1,n_rounds):\n",
    "    plt.plot(logs_k2[r]['cbkrnl'].A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in range(1,n_rounds):\n",
    "    plt.plot(logs_k[r]['cbkrnl'].A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
