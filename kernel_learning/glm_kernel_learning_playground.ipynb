{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## learning kernels for the GLM example. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import delfi.distribution as dd\n",
    "import delfi.generator as dg\n",
    "import delfi.inference as infer\n",
    "import delfi.utils.io as io\n",
    "import delfi.summarystats as ds\n",
    "import lfimodels.glm.utils as utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from lfimodels.glm.GLM import GLM\n",
    "from lfimodels.glm.GLMStats import GLMStats\n",
    "from delfi.utils.viz import plot_pdf\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "data_seed = 99\n",
    "seed = 42\n",
    "duration = 300\n",
    "\n",
    "len_filter, a = 9, 1.\n",
    "true_params, labels_params = utils.obs_params(len_filter, a)\n",
    "\n",
    "obs = utils.obs_data(true_params, seed=data_seed, duration=duration)\n",
    "obs_stats = utils.obs_stats(true_params, seed=data_seed, duration=duration)\n",
    "\n",
    "rerun = False  # if False, will try loading file from disk\n",
    "\n",
    "def init_g():\n",
    "    \n",
    "    s = GLMStats(n_summary=len_filter+1)\n",
    "\n",
    "    p = utils.smoothing_prior(n_params=len_filter+1, seed=seed)\n",
    "    m = GLM(len_filter=len_filter, duration=duration, seed=data_seed)\n",
    "    g = dg.Default(summary=s, model=m, prior=p)    \n",
    "    \n",
    "    #g = dg.MPGenerator(models=[GLM(len_filter=len_filter, duration=duration, seed=seed+i) for i in range(n_workers)], \n",
    "    #                   prior=p, summary=s)\n",
    "    \n",
    "    return g\n",
    "\n",
    "try:\n",
    "    assert rerun == False, 'rerun requested'\n",
    "    sam = np.load('sam.npz')['arr_0']\n",
    "except:\n",
    "    sam = utils.pg_mcmc(true_params, obs, duration=duration, \n",
    "                        prior_dist=utils.smoothing_prior(n_params=len_filter+1, seed=data_seed))\n",
    "    np.savez('sam.npz', sam)\n",
    "pe = dd.Gaussian(m=sam.mean(axis=1), S=np.cov(sam))\n",
    "    \n",
    "n_train=10000\n",
    "n_rounds=5\n",
    "minibatch=100 \n",
    "epochs=200   \n",
    "round_cl=3\n",
    "\n",
    "minibatch_cbk=100\n",
    "epochs_cbk=500\n",
    "\n",
    "n_hiddens = [50,50]\n",
    "convert_to_T = 3\n",
    "pilot_samples = 1000\n",
    "svi=True\n",
    "reg_lambda=0.01\n",
    "prior_norm=False\n",
    "n_workers = 10    \n",
    "\n",
    "res = infer.SNPE(generator=init_g(), \n",
    "                 obs=obs_stats, \n",
    "                 n_hiddens=n_hiddens, \n",
    "                 seed=seed, \n",
    "                 convert_to_T=convert_to_T, \n",
    "                 pilot_samples=pilot_samples,\n",
    "                 svi=svi,\n",
    "                 reg_lambda=reg_lambda,\n",
    "                 prior_norm=prior_norm)\n",
    "\n",
    "logs, tds, posteriors = res.run(n_train=n_train, \n",
    "                                n_rounds=n_rounds, \n",
    "                                minibatch=minibatch, \n",
    "                                epochs=epochs, \n",
    "                                minibatch_cbk=minibatch_cbk,\n",
    "                                epochs_cbk=epochs_cbk,                                        \n",
    "                                round_cl=round_cl, \n",
    "                                kernel_loss=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# version with learned kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## x_kl loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "res_k = infer.SNPE(generator=init_g(), \n",
    "                 obs=obs_stats, \n",
    "                 n_hiddens=n_hiddens, \n",
    "                 seed=seed, \n",
    "                 convert_to_T=convert_to_T, \n",
    "                 pilot_samples=pilot_samples,\n",
    "                 svi=svi,\n",
    "                 reg_lambda=reg_lambda,\n",
    "                 prior_norm=prior_norm)\n",
    "\n",
    "logs_k, tds_k, posteriors_k = res_k.run(n_train=n_train, \n",
    "                                n_rounds=n_rounds, \n",
    "                                minibatch=minibatch, \n",
    "                                epochs=epochs, \n",
    "                                minibatch_cbk=minibatch_cbk,\n",
    "                                epochs_cbk=epochs_cbk,                                        \n",
    "                                round_cl=round_cl, \n",
    "                                cbk_feature_layer=4,\n",
    "                                kernel_loss='x_kl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "obs_statz = (obs_stats - res.stats_mean) / res.stats_std \n",
    "\n",
    "def d_kl_gauss(m1, m2, S1, S2):\n",
    "   \n",
    "    S2i = np.linalg.inv(S2)\n",
    "    dm =  m2 - m1\n",
    "   \n",
    "    out  = np.trace(S2i.dot(S1))\n",
    "    out += dm.dot(S2i.dot(dm))\n",
    "    out -= m1.size\n",
    "    out += np.prod(np.linalg.slogdet(S2)) - np.prod(np.linalg.slogdet(S1))\n",
    "    return out / 2.\n",
    "\n",
    "# run with Gaussian proposals\n",
    "for r in range(len(tds_k)):\n",
    "    plot_pdf(posteriors[r],\n",
    "             pdf2=posteriors_k[r], \n",
    "             lims=[-2,2], \n",
    "             samples=sam, \n",
    "             gt=true_params, \n",
    "             resolution=100,\n",
    "             figsize=(16,16));\n",
    "\n",
    "\n",
    "    stats, w = tds[r][1], tds[r][2]\n",
    "    w /= w.sum()\n",
    "    px = dd.Gaussian(m=w.dot(stats),\n",
    "                     S=np.cov(stats.T, aweights=w))\n",
    "    stats, w = tds_k[r][1], tds_k[r][2]\n",
    "    w /= w.sum()\n",
    "    px_k = dd.Gaussian(m=w.dot(stats),\n",
    "                     S=np.cov(stats.T, aweights=w))\n",
    "    stats = tds_k[r][1]\n",
    "    plot_pdf(px, pdf2=px_k, samples=stats.T, lims = [-2, 2], resolution=100,\n",
    "             gt=obs_statz.reshape(-1,1), figsize=(16,16));    \n",
    "    \n",
    "    \n",
    "    pdf1, pdf2  = posteriors[r].xs[0], posteriors_k[r].xs[0]\n",
    "    m1, m2, S1, S2 = pdf1.m, pdf2.m, pdf1.S, pdf2.S\n",
    "    dr = d_kl_gauss(pe.m, m1, pe.S, S1)\n",
    "    dk = d_kl_gauss(pe.m, m2, pe.S, S2)\n",
    "    print('D_KL: ', (dr, dk))\n",
    "    \n",
    "    iws = tds[r][2]\n",
    "    iws /= iws.sum()\n",
    "\n",
    "    kiws = tds_k[r][2]\n",
    "    kiws /= kiws.sum()\n",
    "    print('ESS: ', 1/np.sum(iws**2), 1/np.sum(kiws**2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "res_k = infer.SNPE(generator=init_g(), \n",
    "                 obs=obs_stats, \n",
    "                 n_hiddens=n_hiddens, \n",
    "                 seed=seed, \n",
    "                 convert_to_T=convert_to_T, \n",
    "                 pilot_samples=pilot_samples,\n",
    "                 svi=svi,\n",
    "                 reg_lambda=reg_lambda,\n",
    "                 prior_norm=prior_norm)\n",
    "\n",
    "logs_k, tds_k, posteriors_k = res_k.run(n_train=n_train, \n",
    "                                n_rounds=n_rounds, \n",
    "                                minibatch=minibatch, \n",
    "                                epochs=epochs, \n",
    "                                minibatch_cbk=minibatch_cbk,\n",
    "                                epochs_cbk=epochs_cbk,                                        \n",
    "                                round_cl=round_cl, \n",
    "                                cbk_feature_layer=0,\n",
    "                                kernel_loss='x_kl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "obs_statz = (obs_stats - res.stats_mean) / res.stats_std \n",
    "\n",
    "def d_kl_gauss(m1, m2, S1, S2):\n",
    "   \n",
    "    S2i = np.linalg.inv(S2)\n",
    "    dm =  m2 - m1\n",
    "   \n",
    "    out  = np.trace(S2i.dot(S1))\n",
    "    out += dm.dot(S2i.dot(dm))\n",
    "    out -= m1.size\n",
    "    out += np.prod(np.linalg.slogdet(S2)) - np.prod(np.linalg.slogdet(S1))\n",
    "    return out / 2.\n",
    "\n",
    "# run with Gaussian proposals\n",
    "for r in range(len(tds_k)):\n",
    "    plot_pdf(posteriors[r],\n",
    "             pdf2=posteriors_k[r], \n",
    "             lims=[-2,2], \n",
    "             samples=sam, \n",
    "             gt=true_params, \n",
    "             resolution=100,\n",
    "             figsize=(16,16));\n",
    "\n",
    "\n",
    "    stats, w = tds[r][1], tds[r][2]\n",
    "    w /= w.sum()\n",
    "    px = dd.Gaussian(m=w.dot(stats),\n",
    "                     S=np.cov(stats.T, aweights=w))\n",
    "    stats, w = tds_k[r][1], tds_k[r][2]\n",
    "    w /= w.sum()\n",
    "    px_k = dd.Gaussian(m=w.dot(stats),\n",
    "                     S=np.cov(stats.T, aweights=w))\n",
    "    stats = tds_k[r][1]\n",
    "    plot_pdf(px, pdf2=px_k, samples=stats.T, lims = [-2, 2], resolution=100,\n",
    "             gt=obs_statz.reshape(-1,1), figsize=(16,16));    \n",
    "    \n",
    "    \n",
    "    pdf1, pdf2  = posteriors[r].xs[0], posteriors_k[r].xs[0]\n",
    "    m1, m2, S1, S2 = pdf1.m, pdf2.m, pdf1.S, pdf2.S\n",
    "    dr = d_kl_gauss(pe.m, m1, pe.S, S1)\n",
    "    dk = d_kl_gauss(pe.m, m2, pe.S, S2)\n",
    "    print('D_KL: ', (dr, dk))\n",
    "    \n",
    "    iws = tds[r][2]\n",
    "    iws /= iws.sum()\n",
    "\n",
    "    kiws = tds_k[r][2]\n",
    "    kiws /= kiws.sum()\n",
    "    print('ESS: ', 1/np.sum(iws**2), 1/np.sum(kiws**2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "for r in range(n_rounds):\n",
    "    plt.subplot(n_rounds,3,3*r+1)\n",
    "    plt.plot(logs[r]['loss'])\n",
    "    plt.subplot(n_rounds,3,3*r+2)\n",
    "    plt.plot(logs_k[r]['loss'])    \n",
    "    plt.subplot(n_rounds,3,3*r+3)\n",
    "    if r > 0:\n",
    "        plt.plot(logs_k[r]['cbk_loss'])    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from delfi.kernel.Kernel_learning import kernel_opt\n",
    "import lasagne.layers as ll\n",
    "import lasagne.updates as lu\n",
    "import theano \n",
    "\n",
    "\n",
    "kernel_loss = 'x_kl'\n",
    "trn_data = tds_k[1]\n",
    "n_train_round = n_train\n",
    "iws = res_k.generator.prior.eval(trn_data[0], log=False) / posteriors_k[0].eval(trn_data[0], log=False)\n",
    "\n",
    "ks = list(res_k.network.layer.keys())\n",
    "layer_index = 0\n",
    "hl = res_k.network.layer[ks[layer_index]]\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "clrs = ['k', 'r']\n",
    "\n",
    "iws_  = iws/iws.sum()\n",
    "print('ESS pre: ', 1./sum(iws_**2))\n",
    "for z in range(2):\n",
    "    \n",
    "    #zscore = False if z==0 else True\n",
    "    #epochs__ = 2000\n",
    "    #minibatch__ = n_train\n",
    "    \n",
    "    zscore=True\n",
    "    if z==1:\n",
    "        epochs__ = 2000\n",
    "        minibatch__ = n_train\n",
    "    elif z==0:\n",
    "        epochs__ = 2000\n",
    "        minibatch__=minibatch \n",
    "\n",
    "    \n",
    "    print('condition :' + str(z))\n",
    "    print('minibatch =' + str(minibatch__))\n",
    "    print('epochs =' + str(epochs__))\n",
    "    stats = trn_data[1].reshape(n_train_round,-1).copy()\n",
    "    obs_z = obs_stats.copy()\n",
    "    if zscore: \n",
    "        obs_z = ( obs_z - res_k.stats_mean) / res_k.stats_std\n",
    "        #stats = ( stats - stats.mean(axis=0)) / stats.std(axis=0)\n",
    "    stat_features = theano.function(\n",
    "        inputs=[res_k.network.stats],\n",
    "        outputs=ll.get_output(hl))\n",
    "    fstats = stat_features(stats)\n",
    "    fobs_z = stat_features(obs_z)\n",
    "\n",
    "    \n",
    "    for r in range(10):\n",
    "        cbkrnl, cbl = kernel_opt(\n",
    "            iws=iws.astype(np.float32), \n",
    "            stats=fstats,\n",
    "            obs=fobs_z, \n",
    "            kernel_loss=kernel_loss, \n",
    "            epochs=epochs__, \n",
    "            minibatch=minibatch__, \n",
    "            stop_on_nan=False,\n",
    "            seed=res.gen_newseed(), \n",
    "            step=lu.adam,\n",
    "            monitor=res.monitor_dict_from_names(None))\n",
    "\n",
    "        kiws = iws * cbkrnl.eval(fstats)\n",
    "\n",
    "        kiws_ = kiws/kiws.sum()\n",
    "        print('ESS post:', 1./sum(kiws_**2))\n",
    "\n",
    "        plt.subplot(1,3,1)\n",
    "        plt.plot(cbl, color=clrs[z])\n",
    "        plt.title('final loss' + str(cbl[-1]))\n",
    "        #plt.subplot(1,3,2)\n",
    "        #plt.plot(cbkrnl.A / cbkrnl.A.sum(), color=clrs[z])\n",
    "        plt.subplot(1,3,2)\n",
    "        if zscore:\n",
    "            plt.plot(cbkrnl.A / trn_data[1].reshape(n_train_round,-1).copy().var(axis=0), color=clrs[z])\n",
    "        else:\n",
    "            plt.plot(cbkrnl.A , color=clrs[z])\n",
    "        plt.subplot(1,3,3)\n",
    "        if z==0:\n",
    "            x_ = cbkrnl.eval(fstats)\n",
    "        elif z==1:\n",
    "            y_ = cbkrnl.eval(fstats)\n",
    "            plt.plot(x_, y_, '.')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mESS loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = GLM(duration=duration, seed=seed)\n",
    "p = utils.smoothing_prior(n_params=m.n_params, seed=seed)\n",
    "s = GLMStats(n_summary=m.n_params)\n",
    "g = dg.Default(model=m, prior=p, summary=s)\n",
    "res_k2 = infer.SNPE(generator=init_g(), \n",
    "                 obs=obs_stats, \n",
    "                 n_hiddens=n_hiddens, \n",
    "                 seed=seed, \n",
    "                 convert_to_T=convert_to_T, \n",
    "                 pilot_samples=pilot_samples,\n",
    "                 svi=svi,\n",
    "                 reg_lambda=reg_lambda,\n",
    "                 prior_norm=prior_norm)\n",
    "\n",
    "logs_k2, tds_k2, posteriors_k2 = res_k2.run(n_train=n_train, \n",
    "                                n_rounds=n_rounds, \n",
    "                                minibatch=minibatch, \n",
    "                                epochs=epochs, \n",
    "                                minibatch_cbk=minibatch_cbk,\n",
    "                                epochs_cbk=epochs_cbk,                                        \n",
    "                                round_cl=round_cl, \n",
    "                                kernel_loss='ess')\n",
    "\n",
    "iws = tds[1][2]\n",
    "iws /= iws.sum()\n",
    "\n",
    "kiws = tds_k2[1][2]\n",
    "kiws /= kiws.sum()\n",
    "1/np.sum(iws**2), 1/np.sum(kiws**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from delfi.kernel.Kernel_learning import kernel_opt\n",
    "import lasagne.layers as ll\n",
    "import lasagne.updates as lu\n",
    "import theano \n",
    "\n",
    "\n",
    "kernel_loss = 'ess'\n",
    "trn_data = tds_k[1]\n",
    "n_train_round = n_train\n",
    "iws = res_k.generator.prior.eval(trn_data[0], log=False) / posteriors_k[0].eval(trn_data[0], log=False)\n",
    "\n",
    "ks = list(res_k.network.layer.keys())\n",
    "layer_index = 0\n",
    "hl = res_k.network.layer[ks[layer_index]]\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "clrs = ['k', 'r']\n",
    "\n",
    "iws_  = iws/iws.sum()\n",
    "print('ESS pre: ', 1./sum(iws_**2))\n",
    "for z in range(2):\n",
    "    \n",
    "    #zscore = False if z==0 else True\n",
    "    #epochs__ = 2000\n",
    "    #minibatch__ = n_train\n",
    "    \n",
    "    zscore=True\n",
    "    if z==1:\n",
    "        epochs__ = 2000\n",
    "        minibatch__ = n_train\n",
    "    elif z==0:\n",
    "        epochs__ = 2000\n",
    "        minibatch__=minibatch \n",
    "\n",
    "    \n",
    "    print('zscoring =' + str(z))\n",
    "    print('minibatch =' + str(minibatch__))\n",
    "    print('epochs =' + str(epochs__))\n",
    "    stats = trn_data[1].reshape(n_train_round,-1).copy()\n",
    "    obs_z = obs_stats.copy()\n",
    "    if zscore: \n",
    "        obs_z = ( obs_z - res_k.stats_mean) / res_k.stats_std\n",
    "        #stats = ( stats - stats.mean(axis=0)) / stats.std(axis=0)\n",
    "    stat_features = theano.function(\n",
    "        inputs=[res_k.network.stats],\n",
    "        outputs=ll.get_output(hl))\n",
    "    fstats = stat_features(stats)\n",
    "    fobs_z = stat_features(obs_z)\n",
    "\n",
    "    \n",
    "    for r in range(10):\n",
    "        cbkrnl, cbl = kernel_opt(\n",
    "            iws=iws.astype(np.float32), \n",
    "            stats=fstats,\n",
    "            obs=fobs_z, \n",
    "            kernel_loss=kernel_loss, \n",
    "            epochs=epochs__, \n",
    "            minibatch=minibatch__, \n",
    "            stop_on_nan=False,\n",
    "            seed=res.gen_newseed(), \n",
    "            step=lu.adam,\n",
    "            monitor=res.monitor_dict_from_names(None))\n",
    "\n",
    "        kiws = iws * cbkrnl.eval(fstats)\n",
    "\n",
    "        kiws_ = kiws/kiws.sum()\n",
    "        print('ESS post:', 1./sum(kiws_**2))\n",
    "\n",
    "        plt.subplot(1,3,1)\n",
    "        plt.plot(cbl, color=clrs[z])\n",
    "        plt.title('final loss' + str(cbl[-1]))\n",
    "        #plt.subplot(1,3,2)\n",
    "        #plt.plot(cbkrnl.A / cbkrnl.A.sum(), color=clrs[z])\n",
    "        plt.subplot(1,3,2)\n",
    "        if zscore:\n",
    "            plt.plot(cbkrnl.A / trn_data[1].reshape(n_train_round,-1).copy().var(axis=0), color=clrs[z])\n",
    "        else:\n",
    "            plt.plot(cbkrnl.A , color=clrs[z])\n",
    "        plt.subplot(1,3,3)\n",
    "        if z==0:\n",
    "            x_ = cbkrnl.eval(fstats)\n",
    "        elif z==1:\n",
    "            y_ = cbkrnl.eval(fstats)\n",
    "            plt.plot(x_, y_, '.')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(fstats.mean(axis=0), 'k')\n",
    "plt.plot(fobs_z.flatten(), 'ro-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for r in range(n_rounds):\n",
    "    plt.plot(logs[r]['loss'])\n",
    "    plt.plot(logs_k[r]['loss'])\n",
    "    plt.plot(logs_k2[r]['loss'])\n",
    "    plt.legend(['raw', 'x_kl', 'max_ess'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn\n",
    "\n",
    "\n",
    "sets = [tds, tds_k, tds_k2]\n",
    "\n",
    "ess   = np.zeros((len(tds), 3))\n",
    "mu_   = np.zeros((len(tds), 3, obs_stats.size)) \n",
    "sig2_ = np.zeros((len(tds), 3, obs_stats.size))\n",
    "sig2e = np.zeros((len(tds), 3, obs_stats.size))\n",
    "\n",
    "for r in range(len(tds)):\n",
    "    for i in range(3):\n",
    "        w = sets[i][r][2].reshape(-1,1)\n",
    "        w /= w.sum()\n",
    "        ess[r, i] = 1./np.sum(w**2)\n",
    "\n",
    "        stats = sets[i][r][1]\n",
    "        sig2e[r, i, :] = np.var( stats, axis = 0)\n",
    "        mu_[r, i, :]   = np.sum( w * stats,                   axis=0).reshape(1,-1)\n",
    "        sig2_[r, i, :] = np.sum( w * (stats-mu_[r, i, :])**2, axis=0)    \n",
    "            \n",
    "plt.plot(np.arange(1, len(tds)), ess[1:,:])\n",
    "plt.legend(['raw iws', 'iws + x_kl', 'iws + max_ess', 'unweighted'])\n",
    "plt.xlabel('round')\n",
    "plt.ylabel('effective sample size')\n",
    "plt.show()    \n",
    "\n",
    "\"\"\"\n",
    "plt.figure(figsize=(12,16))\n",
    "for i in range(10):\n",
    "    plt.subplot(5,2,i+1)\n",
    "    plt.plot(np.arange(0,len(tds)), sig2e[:, :, i], '--')\n",
    "    plt.plot(np.arange(0,len(tds)), sig2_[:,:,i], linewidth=1.5)    \n",
    "    plt.legend(['raw', 'x_kl', 'max_ess'])\n",
    "plt.show()    \n",
    "\"\"\"\n",
    "plt.figure(figsize=(12,16))\n",
    "for r in range(1,len(tds)):\n",
    "    plt.subplot(2,2,r)\n",
    "    plt.plot(sig2_[r,:,:].T, linewidth=1.5)    \n",
    "    plt.plot(sig2e[r,1,:].T, 'k--')\n",
    "    plt.xlabel('# summary statistic')\n",
    "    plt.ylabel('empirical variance')\n",
    "    plt.title('SNPE round #' + str(r+1))\n",
    "    plt.legend(['raw iws', 'iws + x_kl', 'iws + max_ess', 'unweighted'])\n",
    "plt.show()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run with Gaussian proposals\n",
    "for r in range(len(tds_k)):\n",
    "    plot_pdf(posteriors[r],\n",
    "             pdf2=posteriors_k[r], \n",
    "             lims=[-2,2], \n",
    "             samples=sam, \n",
    "             gt=true_params, \n",
    "             resolution=100,\n",
    "             figsize=(9,9));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run with Gaussian proposals\n",
    "for r in range(len(tds_k)):\n",
    "    plot_pdf(posteriors[r],\n",
    "             pdf2=posteriors_k2[r], \n",
    "             lims=[-2,2], \n",
    "             samples=sam, \n",
    "             gt=true_params, \n",
    "             resolution=100,\n",
    "             figsize=(9,9));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# run with Gaussian proposals\n",
    "for r in range(len(tds_k)):\n",
    "    plot_pdf(posteriors[r],\n",
    "             pdf2=posteriors_k[r], \n",
    "             lims=[-2,2], \n",
    "             samples=sam, \n",
    "             gt=true_params, \n",
    "             resolution=100,\n",
    "             figsize=(9,9));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# run with Gaussian proposals\n",
    "for r in range(len(tds_k)):\n",
    "    plot_pdf(posteriors[r],\n",
    "             pdf2=posteriors_k2[r], \n",
    "             lims=[-2,2], \n",
    "             samples=sam, \n",
    "             gt=true_params, \n",
    "             resolution=100,\n",
    "             figsize=(9,9));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# run with Gaussian proposals\n",
    "for r in range(len(tds_k)):\n",
    "    plot_pdf(posteriors[r],\n",
    "             pdf2=posteriors_k[r], \n",
    "             lims=[-2,2], \n",
    "             samples=sam, \n",
    "             gt=true_params, \n",
    "             resolution=100,\n",
    "             figsize=(9,9));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# run with Gaussian proposals\n",
    "for r in range(len(tds_k)):\n",
    "    plot_pdf(posteriors[r],\n",
    "             pdf2=posteriors_k2[r], \n",
    "             lims=[-2,2], \n",
    "             samples=sam, \n",
    "             gt=true_params, \n",
    "             resolution=100,\n",
    "             figsize=(9,9));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import lasagne.layers as ll\n",
    "\n",
    "network = res.network\n",
    "inputs  = tds[0][1]\n",
    "obs_z   = (obs_stats - res.stats_mean) / res.stats_std\n",
    "\n",
    "ks = list(network.layer.keys())\n",
    "hiddens = np.where([i[:6]=='hidden' for i in ks])[0]\n",
    "layer_index = hiddens[0]\n",
    "hl = network.layer[ks[layer_index]]\n",
    "print(hl.name)\n",
    "\n",
    "f_eval = theano.function(\n",
    "    inputs=[network.stats],\n",
    "    outputs=ll.get_output(hl))\n",
    "\n",
    "plt.plot(f_eval(inputs)[:, :].T, 'k.')\n",
    "plt.plot(f_eval(obs_z).reshape(-1), 'ro')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "layer_index = hiddens[-1]\n",
    "hl = network.layer[ks[layer_index]]\n",
    "print(hl.name)\n",
    "\n",
    "f_eval = theano.function(\n",
    "    inputs=[network.stats],\n",
    "    outputs=ll.get_output(hl))\n",
    "\n",
    "plt.plot(f_eval(inputs)[:, :].T, 'k.')\n",
    "plt.plot(f_eval(obs_z).reshape(-1), 'ro')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(network.layer['mixture_means'])\n",
    "f_eval = theano.function(\n",
    "    inputs=[network.stats],\n",
    "    outputs=network.dms)\n",
    "plt.plot(f_eval(inputs)[0].T, 'k.')\n",
    "plt.plot(f_eval( obs_z)[0].T, 'ro')\n",
    "plt.plot(true_params, 'bx', ms=5)\n",
    "plt.show()\n",
    "\n",
    "print(f_eval( obs_z)[0])\n",
    "print(posteriors[-1].xs[0].m)\n",
    "print(true_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import lasagne.layers as ll\n",
    "\n",
    "network = res.network\n",
    "inputs  = tds[-1][1]\n",
    "obs_z   = (obs_stats - res.stats_mean) / res.stats_std\n",
    "\n",
    "ks = list(network.layer.keys())\n",
    "hiddens = np.where([i[:6]=='hidden' for i in ks])[0]\n",
    "layer_index = hiddens[0]\n",
    "hl = network.layer[ks[layer_index]]\n",
    "print(hl.name)\n",
    "\n",
    "f_eval = theano.function(\n",
    "    inputs=[network.stats],\n",
    "    outputs=ll.get_output(hl))\n",
    "\n",
    "plt.plot(f_eval(inputs)[:, :].T, 'k.')\n",
    "plt.plot(f_eval(obs_z).reshape(-1), 'ro')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "layer_index = hiddens[-1]\n",
    "hl = network.layer[ks[layer_index]]\n",
    "print(hl.name)\n",
    "\n",
    "f_eval = theano.function(\n",
    "    inputs=[network.stats],\n",
    "    outputs=ll.get_output(hl))\n",
    "\n",
    "plt.plot(f_eval(inputs)[:, :].T, 'k.')\n",
    "plt.plot(f_eval(obs_z).reshape(-1), 'ro')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(network.layer['mixture_means'])\n",
    "f_eval = theano.function(\n",
    "    inputs=[network.stats],\n",
    "    outputs=network.dms)\n",
    "plt.plot(f_eval(inputs)[0].T, 'k.')\n",
    "plt.plot(f_eval( obs_z)[0].T, 'ro')\n",
    "plt.plot(true_params, 'bx', ms=5)\n",
    "plt.show()\n",
    "\n",
    "print(f_eval( obs_z)[0])\n",
    "print(posteriors[-1].xs[0].m)\n",
    "print(true_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distm = np.zeros((n_rounds, 3))\n",
    "dists = np.zeros((n_rounds, 3))\n",
    "\n",
    "for r in range(n_rounds):\n",
    "\n",
    "    distm[r,:] = (np.sqrt( np.sum( (posteriors[r].xs[0].m    - sam.mean(axis=1))**2 ) ),\n",
    "           np.sqrt( np.sum( (posteriors_k[r].xs[0].m  - sam.mean(axis=1))**2 ) ),\n",
    "           np.sqrt( np.sum( (posteriors_k2[r].xs[0].m - sam.mean(axis=1))**2 ) ))\n",
    "           \n",
    "    dists[r,:] = (np.sqrt( np.sum( (np.diag(posteriors[r].xs[0].S) - sam.var(axis=1))**2 ) ),\n",
    "           np.sqrt( np.sum( (np.diag(posteriors_k[r].xs[0].S) - sam.var(axis=1))**2 ) ), \n",
    "           np.sqrt( np.sum( (np.diag(posteriors_k2[r].xs[0].S) - sam.var(axis=1))**2 ) ))        \n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(distm[1:,0].T, 'r')\n",
    "plt.plot(distm[1:,1].T, 'b')\n",
    "plt.plot(distm[1:,2].T, 'g')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(dists[1:,0].T, 'r')\n",
    "plt.plot(dists[1:,1].T, 'b')\n",
    "plt.plot(dists[1:,2].T, 'g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distm = np.zeros((n_rounds, 3))\n",
    "dists = np.zeros((n_rounds, 3))\n",
    "\n",
    "for r in range(n_rounds):\n",
    "\n",
    "    distm[r,:] = (np.sqrt( np.sum( (posteriors[r].xs[0].m    - sam.mean(axis=1))**2 ) ),\n",
    "           np.sqrt( np.sum( (posteriors_k[r].xs[0].m  - sam.mean(axis=1))**2 ) ),\n",
    "           np.sqrt( np.sum( (posteriors_k2[r].xs[0].m - sam.mean(axis=1))**2 ) ))\n",
    "           \n",
    "    dists[r,:] = (np.sqrt( np.sum( (np.diag(posteriors[r].xs[0].S) - sam.var(axis=1))**2 ) ),\n",
    "           np.sqrt( np.sum( (np.diag(posteriors_k[r].xs[0].S) - sam.var(axis=1))**2 ) ), \n",
    "           np.sqrt( np.sum( (np.diag(posteriors_k2[r].xs[0].S) - sam.var(axis=1))**2 ) ))        \n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(distm[1:,0].T, 'r')\n",
    "plt.plot(distm[1:,1].T, 'b')\n",
    "plt.plot(distm[1:,2].T, 'g')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(dists[1:,0].T, 'r')\n",
    "plt.plot(dists[1:,1].T, 'b')\n",
    "plt.plot(dists[1:,2].T, 'g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distm = np.zeros((n_rounds, 3))\n",
    "dists = np.zeros((n_rounds, 3))\n",
    "\n",
    "for r in range(n_rounds):\n",
    "\n",
    "    distm[r,:] = (np.sqrt( np.sum( (posteriors[r].xs[0].m    - sam.mean(axis=1))**2 ) ),\n",
    "           np.sqrt( np.sum( (posteriors_k[r].xs[0].m  - sam.mean(axis=1))**2 ) ),\n",
    "           np.sqrt( np.sum( (posteriors_k2[r].xs[0].m - sam.mean(axis=1))**2 ) ))\n",
    "           \n",
    "    dists[r,:] = (np.sqrt( np.sum( (np.diag(posteriors[r].xs[0].S) - sam.var(axis=1))**2 ) ),\n",
    "           np.sqrt( np.sum( (np.diag(posteriors_k[r].xs[0].S) - sam.var(axis=1))**2 ) ), \n",
    "           np.sqrt( np.sum( (np.diag(posteriors_k2[r].xs[0].S) - sam.var(axis=1))**2 ) ))        \n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(distm[1:,0].T, 'r')\n",
    "plt.plot(distm[1:,1].T, 'b')\n",
    "plt.plot(distm[1:,2].T, 'g')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(dists[1:,0].T, 'r')\n",
    "plt.plot(dists[1:,1].T, 'b')\n",
    "plt.plot(dists[1:,2].T, 'g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distm = np.zeros((n_rounds, 3))\n",
    "dists = np.zeros((n_rounds, 3))\n",
    "\n",
    "for r in range(n_rounds):\n",
    "\n",
    "    distm[r,:] = (np.sqrt( np.sum( (posteriors[r].xs[0].m    - sam.mean(axis=1))**2 ) ),\n",
    "           np.sqrt( np.sum( (posteriors_k[r].xs[0].m  - sam.mean(axis=1))**2 ) ),\n",
    "           np.sqrt( np.sum( (posteriors_k2[r].xs[0].m - sam.mean(axis=1))**2 ) ))\n",
    "           \n",
    "    dists[r,:] = (np.sqrt( np.sum( (np.diag(posteriors[r].xs[0].S) - sam.var(axis=1))**2 ) ),\n",
    "           np.sqrt( np.sum( (np.diag(posteriors_k[r].xs[0].S) - sam.var(axis=1))**2 ) ), \n",
    "           np.sqrt( np.sum( (np.diag(posteriors_k2[r].xs[0].S) - sam.var(axis=1))**2 ) ))        \n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(distm[1:,0].T, 'r')\n",
    "plt.plot(distm[1:,1].T, 'b')\n",
    "plt.plot(distm[1:,2].T, 'g')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(dists[1:,0].T, 'r')\n",
    "plt.plot(dists[1:,1].T, 'b')\n",
    "plt.plot(dists[1:,2].T, 'g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distm = np.zeros((n_rounds, 3))\n",
    "dists = np.zeros((n_rounds, 3))\n",
    "\n",
    "for r in range(n_rounds):\n",
    "\n",
    "    distm[r,:] = (np.sqrt( np.sum( (posteriors[r].xs[0].m    - sam.mean(axis=1))**2 ) ),\n",
    "           np.sqrt( np.sum( (posteriors_k[r].xs[0].m  - sam.mean(axis=1))**2 ) ),\n",
    "           np.sqrt( np.sum( (posteriors_k2[r].xs[0].m - sam.mean(axis=1))**2 ) ))\n",
    "           \n",
    "    dists[r,:] = (np.sqrt( np.sum( (np.diag(posteriors[r].xs[0].S) - sam.var(axis=1))**2 ) ),\n",
    "           np.sqrt( np.sum( (np.diag(posteriors_k[r].xs[0].S) - sam.var(axis=1))**2 ) ), \n",
    "           np.sqrt( np.sum( (np.diag(posteriors_k2[r].xs[0].S) - sam.var(axis=1))**2 ) ))        \n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(distm[1:,0].T, 'r')\n",
    "plt.plot(distm[1:,1].T, 'b')\n",
    "plt.plot(distm[1:,2].T, 'g')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(dists[1:,0].T, 'r')\n",
    "plt.plot(dists[1:,1].T, 'b')\n",
    "plt.plot(dists[1:,2].T, 'g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distm = np.zeros((n_rounds, 3))\n",
    "dists = np.zeros((n_rounds, 3))\n",
    "\n",
    "for r in range(n_rounds):\n",
    "\n",
    "    distm[r,:] = (np.sqrt( np.sum( (posteriors[r].xs[0].m    - sam.mean(axis=1))**2 ) ),\n",
    "           np.sqrt( np.sum( (posteriors_k[r].xs[0].m  - sam.mean(axis=1))**2 ) ),\n",
    "           np.sqrt( np.sum( (posteriors_k2[r].xs[0].m - sam.mean(axis=1))**2 ) ))\n",
    "           \n",
    "    dists[r,:] = (np.sqrt( np.sum( (np.diag(posteriors[r].xs[0].S) - sam.var(axis=1))**2 ) ),\n",
    "           np.sqrt( np.sum( (np.diag(posteriors_k[r].xs[0].S) - sam.var(axis=1))**2 ) ), \n",
    "           np.sqrt( np.sum( (np.diag(posteriors_k2[r].xs[0].S) - sam.var(axis=1))**2 ) ))        \n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(distm[1:,0].T, 'r')\n",
    "plt.plot(distm[1:,1].T, 'b')\n",
    "plt.plot(distm[1:,2].T, 'g')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(dists[1:,0].T, 'r')\n",
    "plt.plot(dists[1:,1].T, 'b')\n",
    "plt.plot(dists[1:,2].T, 'g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for r in range(1,n_rounds):\n",
    "    plt.plot(logs_k2[r]['cbkrnl'].A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for r in range(1,n_rounds):\n",
    "    plt.plot(logs_k[r]['cbkrnl'].A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
