{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quickstart\n",
    "======"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a small example on how to do Bayesian model selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step by step explanation\n",
    "----------------------------\n",
    "\n",
    "### Defining a model\n",
    "\n",
    "\n",
    "To do model selection, we first need some models. A model, in the simplest case,\n",
    "is just a callable which takes a single `dict` as input and returns a single `dict` as output. The keys of the input dictionary are the parameters of the model, the output\n",
    "keys denote the summary statistics.\n",
    "Here, the `dict` is passed as `parameters` and has the entry `x`, which denotes the mean of a Gaussian.\n",
    "It returns the observed summary statistics `y`, which is just the sampled value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import tempfile\n",
    "import numpy as np\n",
    "\n",
    "import scipy.stats as st\n",
    "\n",
    "from pyabc import (ABCSMC, RV, Distribution,\n",
    "                   PercentileDistanceFunction)\n",
    "\n",
    "# Define a gaussian model\n",
    "sigma = 1.\n",
    "\n",
    "\n",
    "def model(parameters):\n",
    "    # sample from a gaussian\n",
    "    y = st.norm(parameters.x, sigma).rvs()\n",
    "    # return the sample as dictionary\n",
    "    return {\"y\": y}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For model selection we usually have more than one model.\n",
    "These are assembled in a list. We\n",
    "require a Bayesian prior over the models.\n",
    "The default is to have a uniform prior over the model classes.\n",
    "This concludes the model definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define two models, but they are identical so far\n",
    "models = [model, model, model]\n",
    "\n",
    "\n",
    "# However, our models' priors are not the same.\n",
    "# Their mean differs.\n",
    "mu_x_1, mu_x_2, mu_x_3 = 0, 1, -1\n",
    "parameter_priors = [\n",
    "    Distribution(x=RV(\"norm\", mu_x_1, sigma)),\n",
    "    Distribution(x=RV(\"norm\", mu_x_2, sigma)), \n",
    "    Distribution(x=RV(\"norm\", mu_x_3, sigma))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring the ABCSMC run\n",
    "\n",
    "Having the models defined, we can plug together the `ABCSMC` class.\n",
    "We need a distance function,\n",
    "to measure the distance of obtained samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plug all the ABC options together\n",
    "abc = ABCSMC(\n",
    "    models, parameter_priors,\n",
    "    PercentileDistanceFunction(measures_to_use=[\"y\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the observed data\n",
    "\n",
    "Actually measured data can now be passed to the ABCSMC.\n",
    "This is set via the `new` method, indicating that we start\n",
    "a new run as opposed to resuming a stored run (see the \"resume stored run\" example).\n",
    "Moreover, we have to set the output database where the ABC-SMC run\n",
    "is logged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate test data for comparison to DE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.49671415])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set same seed as in the NDE notebook\n",
    "rng = np.random.RandomState(seed=42)\n",
    "sx_t = rng.normal(loc=0, scale=1, size=1)\n",
    "sx_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a loop over all test data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:History:Start <ABCSMC(id=108, start_time=2018-12-14 17:23:15.213389, end_time=None)>\n",
      "INFO:Epsilon:initial epsilon is 0.4373312603003668\n",
      "INFO:ABC:t:0 eps:0.4373312603003668\n",
      "INFO:ABC:t:1 eps:0.1956997542977105\n",
      "INFO:ABC:t:2 eps:0.09489582533615787\n",
      "INFO:ABC:t:3 eps:0.0541448837359886\n",
      "INFO:ABC:t:4 eps:0.028632904101118524\n",
      "INFO:ABC:t:5 eps:0.018295346365303035\n",
      "INFO:ABC:t:6 eps:0.009101333120114215\n",
      "INFO:ABC:t:7 eps:0.005109189915900939\n",
      "INFO:ABC:t:8 eps:0.0030281484175126295\n",
      "INFO:ABC:t:9 eps:0.001688973306761143\n",
      "INFO:History:Done <ABCSMC(id=108, start_time=2018-12-14 17:23:15.213389, end_time=2018-12-14 17:23:35.265310)>\n"
     ]
    }
   ],
   "source": [
    "n_simulations = np.zeros_like(sx_t)\n",
    "phat = np.zeros((3, sx_t.size))\n",
    "\n",
    "for idx, y_observed in enumerate(sx_t): \n",
    "    # y_observed is the important piece here: our actual observation.\n",
    "    # and we define where to store the results\n",
    "    db_path = (\"sqlite:///\" +\n",
    "               os.path.join(tempfile.gettempdir(), \"test.db\"))\n",
    "    abc_id = abc.new(db_path, {\"y\": y_observed})\n",
    "\n",
    "    # We run the ABC until either criterion is met\n",
    "    history = abc.run(minimum_epsilon=0.0001, max_nr_populations=10)\n",
    "    \n",
    "    n_simulations[idx] = history.total_nr_simulations\n",
    "    \n",
    "    phat[:, idx] = history.get_model_probabilities().values[-1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate true posterior "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import sys \n",
    "sys.path.append('../../')\n",
    "from model_comparison.models import BaseModel\n",
    "\n",
    "\n",
    "# background model prior \n",
    "prior_m0 = scipy.stats.norm(0, 1)\n",
    "# signal model prior \n",
    "prior_m1 = scipy.stats.norm(1, 1)\n",
    "# third model \n",
    "prior_m2 = scipy.stats.norm(-1, 1)\n",
    "\n",
    "class GaussianModel(BaseModel):\n",
    "    def __init__(self, std, dim_param=1, sample_size=10, n_workers=1, seed=None):\n",
    "        super().__init__(dim_param=dim_param, sample_size=sample_size, n_workers=n_workers, seed=seed)\n",
    "        self.std = std\n",
    "        self.posterior = None\n",
    "\n",
    "    def gen_single(self, params):\n",
    "        # in multiprocessing the parameter vector additionally contains a seed\n",
    "        if self.run_parallel:\n",
    "            mu, seed = params\n",
    "            self.rng.seed(int(seed))\n",
    "        else:\n",
    "            mu = params\n",
    "        return self.rng.normal(loc=mu, scale=self.std, size=self.sample_size)\n",
    "\n",
    "# models \n",
    "sample_size = 1\n",
    "m0 = GaussianModel(std=1, sample_size=sample_size)\n",
    "m1 = GaussianModel(std=1, sample_size=sample_size)\n",
    "m2 = GaussianModel(std=1, sample_size=sample_size)\n",
    "\n",
    "marli0 = np.array([scipy.stats.norm.pdf(x=xo, loc=prior_m0.mean(), \n",
    "                                        scale=np.sqrt(m0.std**2 + prior_m0.std()**2)) for xo in sx_t])\n",
    "marli1 = np.array([scipy.stats.norm.pdf(x=xo, loc=prior_m1.mean(), \n",
    "                                        scale=np.sqrt(m1.std**2 + prior_m1.std()**2)) for xo in sx_t])\n",
    "marli2 = np.array([scipy.stats.norm.pdf(x=xo, loc=prior_m2.mean(), \n",
    "                                        scale=np.sqrt(m2.std**2 + prior_m2.std()**2)) for xo in sx_t])\n",
    "\n",
    "p_m0_xtest = marli0 / (marli1 + marli0 + marli2)\n",
    "p_m1_xtest = marli1 / (marli1 + marli0 + marli2)\n",
    "p_m2_xtest = marli2 / (marli1 + marli0 + marli2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptrue = np.vstack((p_m0_xtest, p_m1_xtest, p_m2_xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04090708698630825"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(phat - ptrue).mean()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
