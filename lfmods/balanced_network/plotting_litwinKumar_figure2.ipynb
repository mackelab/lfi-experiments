{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce figure 2 of Litwin-Kumar Doiran 2012\n",
    "\n",
    "Use data from the simulated balanced network to reproduce the figure 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../code/likelihoodfree-models/')\n",
    "from lfmods.balanced_network_utils import *\n",
    "%matplotlib inline\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify data folder \n",
    "folder = '/Users/Jan/Dropbox/Master/mackelab/code/balanced_clustered_network/data/'\n",
    "\n",
    "# give filename for uniform and clustered data \n",
    "fn_uni = '15009991276ree10_dur20_brain1.p'\n",
    "fn_clus = '150099931884ree25_dur20_brain1.p'\n",
    "\n",
    "# filename params \n",
    "time_str = time.time()\n",
    "dur = '2s'\n",
    "figure_filename = '{}_figure2_dur{}'.format(time_str, dur).replace('.', '')\n",
    "\n",
    "# load data \n",
    "d_uni = load_data(fn_uni, folder)\n",
    "d_clus = load_data(fn_clus, folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume a single long trial, use only E neurons\n",
    "# extract parameters \n",
    "\n",
    "# set time window for ff  in sec \n",
    "window_length_ff = 0.1  \n",
    "# and for rho \n",
    "window_length_rho = 0.05 \n",
    "\n",
    "# time windows for ff ocer time windows \n",
    "time_windows = np.linspace(0.025, 0.2, 8)\n",
    "\n",
    "# get the params \n",
    "params = d_uni['params']\n",
    "n_rounds = params['n_rounds']\n",
    "n_trials = params['n_trials']\n",
    "simulation_time = np.asarray(params['simulation_time'])  # remove unit\n",
    "NE = params['NE']\n",
    "NI = params['NI']\n",
    "n_clusters = 50\n",
    "\n",
    "# get the total number of neurons pairs that are in a cluster \n",
    "Nc = NE / n_clusters\n",
    "n_pairs_in_cluster = n_clusters * Nc**2\n",
    "n_random_pairs = int(np.sqrt(n_pairs_in_cluster))\n",
    "\n",
    "time_offset = 1.  # in sec\n",
    "delta_t = simulation_time - time_offset  # in sec\n",
    "recordings_length = delta_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_dict=dict(uniform={}, clustered={})\n",
    "keys = ['uniform', 'clustered']\n",
    "\n",
    "for idx, data in enumerate([d_uni, d_clus]): \n",
    "\n",
    "    spiketimedict = data['trial0']['spikes_E']\n",
    "\n",
    "    # rates \n",
    "    spikecounts = get_spikecounts_fixed_time_window(spiketimedict, time_offset, delta_t)\n",
    "    stat_dict[keys[idx]]['rates'] = spikecounts / delta_t\n",
    "    \n",
    "    # fano factors \n",
    "    spikecounts_over_windows_ff = get_spike_counts_over_time_windows(spiketimedict, time_offset, delta_t, \n",
    "                                                                      window_length=window_length_ff)\n",
    "    stat_dict[keys[idx]]['ff'] = calculate_fano_factor(spikecounts_over_windows_ff)\n",
    "  \n",
    "    # rho all \n",
    "    spikecounts_over_windows_rho = get_spike_counts_over_time_windows(spiketimedict, time_offset, delta_t, \n",
    "                                                              window_length=window_length_rho)\n",
    "    stat_dict[keys[idx]]['rho'] = calculate_correlation_matrix(spikecounts_over_windows_rho)\n",
    "    \n",
    "    # rho pairs is dependent on the clustering \n",
    "    if idx == 0: \n",
    "        shuffled_counts = spikecounts_over_windows_rho.copy()\n",
    "        np.random.shuffle(shuffled_counts)\n",
    "        rho_pairs = calculate_correlation_matrix(shuffled_counts[np.newaxis, :n_random_pairs, :])\n",
    "    else:\n",
    "        rho_pairs = calculate_clusterpair_correlations(spikecounts_over_windows_rho, n_clusters, Nc)\n",
    "    stat_dict[keys[idx]]['rho_pairs'] = rho_pairs\n",
    "    \n",
    "    # ff over time windows \n",
    "    ff_over_windows = np.zeros_like(time_windows)\n",
    "    for w_idx, time_window in enumerate(time_windows): \n",
    "        tmp_spikecounts = get_spike_counts_over_time_windows(spiketimedict, time_offset, delta_t, \n",
    "                                                                  window_length=time_window)\n",
    "        ff_over_windows[w_idx] = calculate_fano_factor(tmp_spikecounts).mean()\n",
    "        \n",
    "    stat_dict[keys[idx]]['ff_over_windows'] = ff_over_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "colors = ['C0', 'C1']\n",
    "for idx, key in enumerate(keys): \n",
    "    \n",
    "    rates = stat_dict[key]['rates']\n",
    "    ff = stat_dict[key]['ff']\n",
    "    rho = stat_dict[key]['rho']\n",
    "    rho_pairs = stat_dict[key]['rho_pairs']\n",
    "    ff_over_windows = stat_dict[key]['ff_over_windows']\n",
    "\n",
    "    # plotting \n",
    "    plt.subplot(231)\n",
    "    # plot the rates \n",
    "    plt.hist(rates, bins=40, range=[0, 15], alpha=.3, lw=3.)\n",
    "    plt.axvline(np.mean(rates), linestyle='--', label='mean={}'.format(np.round(np.mean(rates), 2)), \n",
    "                color=colors[idx])\n",
    "    plt.title('Rates for uniform (blue) and clustered (orange) connectivity')\n",
    "    plt.legend()  \n",
    "    plt.xlabel('Rate (spikes/sec)')\n",
    "    \n",
    "    # the ffs\n",
    "    plt.subplot(233)\n",
    "    plt.hist(ff, bins=40, range=[0, 3.5], alpha=.3, lw=3.)\n",
    "    plt.title('Fano factors over trials and {}s windows'.format(window_length_ff))\n",
    "    plt.axvline(np.mean(ff), linestyle='--', label='mean={}'.format(np.round(np.mean(ff), 2)), \n",
    "                color=colors[idx])\n",
    "    plt.legend()\n",
    "    plt.xlabel('Fano factor')\n",
    "    \n",
    "    # the rho\n",
    "    plt.subplot(234)\n",
    "    plt.hist(rho, bins=40, range=[-.5, .5], alpha=.3)\n",
    "    plt.title('Corr over {}s windows'.format(window_length_rho))\n",
    "    plt.axvline(np.mean(rho), linestyle='--', label='mean={}'.format(np.round(np.mean(rho), 2)), \n",
    "                color=colors[idx])\n",
    "    plt.legend()\n",
    "    plt.xlabel('Correlation (all pairs)')\n",
    "    \n",
    "    # the rho pairs \n",
    "    plt.subplot(235)\n",
    "    plt.hist(rho_pairs, bins=40, range=[-.5, .5], alpha=.3)\n",
    "    plt.title('Corr over {}s windows'.format(window_length_rho))\n",
    "    plt.axvline(np.mean(rho_pairs), linestyle='--', label='mean={}'.format(np.round(np.mean(rho_pairs), 2)), \n",
    "                color=colors[idx])\n",
    "    plt.legend()\n",
    "    plt.xlabel('Correlation (same cluster)')\n",
    "    \n",
    "    # fanos over windows \n",
    "    plt.subplot(236)\n",
    "    plt.title('Fano factors over different time windows')\n",
    "    plt.plot(time_windows, ff_over_windows, '-o')\n",
    "    plt.xlabel('Window (ms)')\n",
    "    plt.ylabel('Fano factor')\n",
    "    \n",
    "save_figure(filename=figure_filename + '.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:brian1]",
   "language": "python",
   "name": "conda-env-brian1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
