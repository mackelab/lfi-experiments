{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 'iw_loss.yaml'\n",
    "%run -i ../template.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_of_runs(input_list):\n",
    "    runs = []\n",
    "    for k in input_list:\n",
    "        run = k.split('_')[1]\n",
    "        if run not in runs:\n",
    "            runs.append(run)\n",
    "    return runs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = os.listdir(netsdir)\n",
    "\n",
    "runs = [x for x in runs if prefix in x]\n",
    "loruns = list_of_runs(runs)  # to iterate over\n",
    "\n",
    "print(len(loruns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = loruns[70]\n",
    "wildcard = prefix + '_' + name + '*'\n",
    "dist_dicts, info_dicts, loss_dicts, net_dicts, posterior_dicts, sim_dicts = io.load_prefix(netsdir, '*074669aa*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(net_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = io.nth(net_dicts, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = net.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in p.keys():\n",
    "    print(np.var(p[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nth(posterior_dicts,1).xs[0].S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nth(info_dicts,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to = len(nth(loss_dicts, 1)['trn_out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = []\n",
    "for t in range(to):\n",
    "    weights = nth(loss_dicts, 1)['trn_out'][t][1]\n",
    "    wm = np.sum(np.log(weights))\n",
    "    w.append(wm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(nth(loss_dicts, 0)['val_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(nth(loss_dicts, 3)['trn_val'])\n",
    "#plt.ylim([-1,4])\n",
    "plt.xlim([1000, 2500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for r in tqdm(range(len(loruns))):\n",
    "    name = loruns[r]\n",
    "    wildcard = prefix + '_' + name + '*'\n",
    "    \n",
    "    path = netsdir\n",
    "    #dist_dicts = io.load_wildcard(path, wildcard + '_dist')\n",
    "    info_dicts = io.load_wildcard(path, wildcard + '_info')\n",
    "    \n",
    "    info = last(info_dicts)\n",
    "    #if int(nth(info_dicts, 3)['datetime'][11:13]) < 20:\n",
    "    #    continue\n",
    "        \n",
    "    #loss_dicts = io.load_wildcard(path, wildcard + '_loss')\n",
    "    #net_dicts = io.load_wildcard(path, wildcard + '_net')\n",
    "    posterior_dicts = io.load_wildcard(path, wildcard + '_posterior')\n",
    "    sim_dicts = io.load_wildcard(path, wildcard + '_sim')\n",
    "    \n",
    "\n",
    "        \n",
    "    sim = last(sim_dicts)\n",
    "    approx_posterior = last(posterior_dicts)\n",
    "    \n",
    "    try:\n",
    "\n",
    "        posterior_mu = approx_posterior.xs[0].m[0]\n",
    "        posterior_cov = approx_posterior.xs[0].S[0,0]\n",
    "\n",
    "        true_mu = sim.posterior.m[0]\n",
    "        true_cov = sim.posterior.S[0,0]\n",
    "\n",
    "        std1 = np.sqrt(true_cov)\n",
    "        std2 = np.sqrt(posterior_cov)\n",
    "        mu1 = true_mu\n",
    "        mu2 = posterior_mu\n",
    "        kltp = np.log(std2/std1) + (std1**2 + (mu1-mu2)**2)/(2*std2**2) - 0.5\n",
    "\n",
    "        iw_loss = info['iw_loss']\n",
    "        svi = info['svi']\n",
    "        prior_alpha = info['prior_alpha']\n",
    "        prior_true = type(nth(info_dicts, -1)['prior_true'])\n",
    "        prior_true = 'Gaussian' in str(prior_true)\n",
    "\n",
    "        dim = nth(sim_dicts, -1).dim\n",
    "\n",
    "        n_summary = last(sim_dicts).n_summary\n",
    "        #n_samples = len(last(dist_dicts))\n",
    "\n",
    "        seed = first(info_dicts)['seed']\n",
    "\n",
    "        data = [\n",
    "                    [name],\n",
    "                    [seed],\n",
    "                    [dim],\n",
    "                    [iw_loss],\n",
    "                    [svi],\n",
    "                    [prior_alpha],\n",
    "                    [prior_true],\n",
    "                    [posterior_mu],\n",
    "                    [posterior_cov],\n",
    "                    [true_mu],\n",
    "                    [true_cov],\n",
    "                    [kltp],\n",
    "                    [info['reg_scale_iw']],\n",
    "                    [info['keep_n']],\n",
    "                    [info['ess']],\n",
    "                    [info['ess_lc']],\n",
    "                    [info['loss_calib']],\n",
    "                    [info['normalize_weights']]\n",
    "                ]\n",
    "\n",
    "        data = pd.DataFrame(data).T\n",
    "        data.columns = ['name', 'seed', 'dim', 'iw_loss', 'svi', 'prior_alpha', 'prior_true', 'p_mu', 'p_cov', \n",
    "                        't_mu', 't_cov', 'kltp', 'rsiw','keep','ess','ess_lc','loss_calib', 'norm']\n",
    "\n",
    "        df = df.append(data)    \n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "df['abserr_cov_tp'] = np.abs(df['t_cov'] - df['p_cov'])\n",
    "df['abserr_mu_tp'] = np.abs(df['t_mu'] - df['p_mu'])\n",
    "\n",
    "df = df.reset_index()\n",
    "df = df.drop('index', 1)\n",
    "\n",
    "print(len(df))\n",
    "df.head()\n",
    "\n",
    "df.to_pickle('iw_loss.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in range(len(df['loss_calib'])):\n",
    "    if df.loc[r, 'loss_calib'] is None:\n",
    "        df.loc[r, 'loss_calib'] = 0.\n",
    "    else:\n",
    "        df.loc[r, 'loss_calib'] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('iw_loss.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('iw_loss.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfa = df.copy()\n",
    "dfc = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = dfc.query('ess == True').copy()\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = dfc.query('dim == 1 & iw_loss == True & svi == True & prior_true == False').copy()\n",
    "subset = subset.reset_index()\n",
    "subset = subset.drop('index', 1)\n",
    "\n",
    "sns.set(font_scale=2)\n",
    "g = sns.factorplot(x=\"prior_alpha\", y=\"p_mu\", data=subset,\n",
    "                   capsize=.1, palette=\"YlGnBu_d\", size=10, aspect=1., markers='.',\n",
    "                   linestyles='-', legend=False, col=\"ess\", row=\"keep\", sharey=True)\n",
    "ax = plt.gca()\n",
    "plt.legend()\n",
    "#ax.set_ylim([0, 0.012])\n",
    "#ax.set_ylim([0, 0.05])\n",
    "#ax.semilogy()\n",
    "#saverep('loss_calib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = dfc.query('dim == 1 & iw_loss == False & svi == True') # & loss_calib == 1 & ess == True & keep == True & norm == True & ess_lc == True').copy()\n",
    "subset = subset.reset_index()\n",
    "subset = subset.drop('index', 1)\n",
    "\n",
    "sns.set(font_scale=2)\n",
    "g = sns.factorplot(x=\"prior_alpha\", y=\"abserr_cov_tp\", data=subset,\n",
    "                   capsize=.1, palette=\"YlGnBu_d\", size=10, aspect=1., markers='.',\n",
    "                   linestyles='-', legend=False, sharey=False)\n",
    "ax = plt.gca()\n",
    "#ax.set_ylim([0, 0.012])\n",
    "#ax.set_ylim([0, 0.02])\n",
    "#ax.semilogy()\n",
    "#plt.legend()\n",
    "#saverep('loss_calib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = dfc.query('dim == 1 & iw_loss == False & svi == False').copy()\n",
    "subset = subset.reset_index()\n",
    "subset = subset.drop('index', 1)\n",
    "\n",
    "plt.hist(subset['abserr_cov_tp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = dfc.query('dim == 1 & iw_loss == False & svi == True').copy()\n",
    "subset = subset.reset_index()\n",
    "subset = subset.drop('index', 1)\n",
    "\n",
    "plt.hist(subset['abserr_cov_tp'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
