{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deep identity mapping\n",
    "\n",
    "learning receptive field parameters from inputs (white-noise videos) and outputs (spike trains) of linear-nonlinear neuron models with parameterized linear filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%matplotlib inline\n",
    "# notebook currently depends on code found only in feature_maprf-branch of lfi_models !\n",
    "\n",
    "import delfi.neuralnet as dn\n",
    "import delfi.distribution as dd\n",
    "import delfi.generator as dg\n",
    "import delfi.inference as infer\n",
    "import delfi.utils.io as io\n",
    "import delfi.summarystats as ds\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import lfimodels.maprf.utils as utils\n",
    "\n",
    "from lfimodels.maprf.maprf import maprf\n",
    "from lfimodels.maprf.maprfStats import maprfStats\n",
    "from delfi.utils.viz import plot_pdf\n",
    "\n",
    "import lasagne.layers as ll\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "import collections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "seed = 42\n",
    "\n",
    "## simulation model\n",
    "\n",
    "d = 41                    # edge length of (quadratic) receptive field\n",
    "parametrization = 'gabor' # ['full', 'gaussian', 'gabor']\n",
    "\n",
    "params_ls = {'glm': ('bias',),\n",
    "             'kernel': {'s' : ('vec_A', 'vec_f', 'ratio', 'width', ),\n",
    "                        't' : ('value',)}}\n",
    "\n",
    "filter_shape = np.array((d,d,2))\n",
    "m = maprf(filter_shape=filter_shape, \n",
    "          parametrization=parametrization,\n",
    "          params_ls = params_ls,\n",
    "          seed=seed, \n",
    "          dt = 0.025, \n",
    "          duration=500 )\n",
    "\n",
    "\n",
    "## prior over simulation parameters\n",
    "prior = collections.OrderedDict()\n",
    "if 'bias' in m.params_ls['glm']:\n",
    "    prior['bias'] = {'mu' : np.array([0]), 'sigma' : np.array([1.]) }\n",
    "if 'vec_A' in m.params_ls['kernel']['s']:\n",
    "    prior['vec_A']  = {'mu' : np.zeros(2), 'sigma' : 1.0 * np.ones(2) }\n",
    "if 'vec_f' in m.params_ls['kernel']['s']:\n",
    "    prior['vec_f']  = {'mu' : np.zeros(2), 'sigma' : 0.4 * np.ones(2) }\n",
    "if 'ratio' in m.params_ls['kernel']['s']:\n",
    "    prior['log_γ']  = {'mu' : np.array([-0.098]), 'sigma' : np.array([0.256])}\n",
    "if 'width' in m.params_ls['kernel']['s']:\n",
    "    prior['log_b']  = {'mu' : np.array([ 0.955]), 'sigma' : np.array([0.236])}\n",
    "if 'xo' in m.params_ls['kernel']['s']:\n",
    "    prior['xo'] = {'mu' : np.array([0.]), 'sigma' : np.array([5/np.sqrt(.5)])}\n",
    "if 'yo' in m.params_ls['kernel']['s']:\n",
    "    prior['yo'] = {'mu' : np.array([0.]), 'sigma' : np.array([5/np.sqrt(.5)])}\n",
    "L = np.diag(np.concatenate([prior[i]['sigma'] for i in list(prior.keys())]))\n",
    "if 'value' in m.params_ls['kernel']['t']:\n",
    "    ax_t = m._gen.axis_t\n",
    "    Λ =  np.diag(ax_t / 0.075 * np.exp(1 - ax_t / 0.075))\n",
    "    D = np.eye(ax_t.shape[0]) - np.eye(ax_t.shape[0], k=-1)\n",
    "    F = np.dot(D, D.T)\n",
    "    Σ = np.dot(Λ, np.linalg.inv(F).dot(Λ))\n",
    "    prior['kt'] = {'mu': np.zeros_like(ax_t), 'sigma': np.linalg.inv(D).dot(Λ)}\n",
    "    L = np.block([[L, np.zeros((L.shape[0], ax_t.size))], \n",
    "                  [np.zeros((ax_t.size, L.shape[1])), prior['kt']['sigma']]])\n",
    "mu  = np.concatenate([prior[i][ 'mu'  ] for i in prior.keys()])\n",
    "p = dd.Gaussian(m=mu, S=L.T.dot(L), seed=seed)\n",
    "\n",
    "## data summary staistics\n",
    "\n",
    "s = maprfStats(n_summary=d*d)\n",
    "\n",
    "g = dg.Default(model=m, prior=p, summary=s)\n",
    "\n",
    "## network \n",
    "\n",
    "n_hiddens=[30,30]\n",
    "n_filters=[16,16,16]\n",
    "n_inputs = [d,d]\n",
    "network = dn.NeuralNet.NeuralNet(n_inputs = n_inputs, \n",
    "                     n_outputs = m.n_params, \n",
    "                     n_components = 1, \n",
    "                     n_filters=n_filters, \n",
    "                     n_hiddens=n_hiddens,\n",
    "                     seed=seed,\n",
    "                     svi=False)\n",
    "loss = -tt.mean(network.lprobs)\n",
    "\n",
    "\n",
    "#test_fun = theano.function([network.stats], [ll.get_output(network.layer['conv_'+str(i)]) for i in range(1,len(n_filters)+1)])\n",
    "#print('conv layer shapes:',  [test_fun(np.zeros((10,1,d,d)))[i].shape  for i in range(len(n_filters))])\n",
    "\n",
    "trn_inputs = [network.params, network.stats]\n",
    "\n",
    "## training data and true parameters, data, statistics\n",
    "\n",
    "params_dict_true = {'glm': {'binsize': m.dt,\n",
    "                            'bias': -0.5},\n",
    "                    'kernel': {'s': {'angle': 0.7,\n",
    "                                     'freq': .3,\n",
    "                                     'gain': 2,\n",
    "                                     'phase': 1.,\n",
    "                                     'ratio': 1.,\n",
    "                                     'width': 2.5},\n",
    "#                                    'xo': 0.,\n",
    "#                                    'yo': 0.},\n",
    "                               't': {'value': np.array([1.,0.])}}}\n",
    "m.params_dict = params_dict_true\n",
    "pars_true = m.read_params_buffer()\n",
    "\n",
    "obs = m.gen_single()\n",
    "obs_stats = s.calc([obs])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_hiddens=[30,30]\n",
    "n_filters=[16,16,16]\n",
    "n_inputs = [d,d]\n",
    "\n",
    "n_train=5000\n",
    "epochs=200\n",
    "minibatch=50\n",
    "n_rounds=3\n",
    "\n",
    "inf = infer.SNPE(generator=g, obs=obs_stats, prior_norm=False, pilot_samples=None, convert_to_T=False, seed=seed, \n",
    "                n_hiddens=n_filters, n_filters=n_filters, n_inputs = [d,d])\n",
    "logs = inf.run(n_train=n_train, epochs=epochs, minibatch=minibatch, n_rounds=n_rounds)\n",
    "\n",
    "posterior = inf.predict(obs_stats)\n",
    "\n",
    "# bunch of example prior draws\n",
    "plt.figure(figsize=(16,10))\n",
    "for i in range(15):\n",
    "    plt.subplot(3,5,i+1)\n",
    "    plt.imshow(m.params_to_rf(p.gen().reshape(-1))[0], interpolation='None')\n",
    "plt.title('RF prior draws')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16,5))\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(m.params_to_rf(p.m)[0], interpolation='None')\n",
    "plt.title('prior mean RF')\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(obs_stats.reshape(d,d), interpolation='None')\n",
    "plt.title('data STA')\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(m.params_to_rf(pars_true)[0], interpolation='None')\n",
    "plt.title('ground-truth RF')\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(m.params_to_rf(posterior.xs[0].m)[0], interpolation='None')\n",
    "plt.title('posterior mean RF')\n",
    "plt.show()\n",
    "\n",
    "# bunch of example posterior draws\n",
    "plt.figure(figsize=(16,10))\n",
    "for i in range(15):\n",
    "    plt.subplot(3,5,i+1)\n",
    "    plt.imshow(m.params_to_rf(posterior.gen().reshape(-1))[0], interpolation='None')\n",
    "plt.title('RF posterior draws')\n",
    "plt.show()\n",
    "\n",
    "# all pairwise marginals of fitted posterior\n",
    "plot_pdf(posterior.xs[0], lims=[-5,5], gt=pars_true.reshape(-1), figsize=(16,16),\n",
    "labels_params=['b','A_1','A_2','f_1','f_2','log ratio','log width']+['kt_'+str(i) for i in range(filter_shape[2])]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.imshow(obs_stats.reshape(d,d), interpolation='None')\n",
    "plt.title('x0')\n",
    "plt.show()\n",
    "\n",
    "for r in range(3):\n",
    "    print('round ', str(r))\n",
    "    parameters =  logs[1][r][0]\n",
    "    samples = logs[1][r][1]\n",
    "\n",
    "    x_dists = np.sum( (samples[:,0,:,:] - obs_stats.reshape(1, d,d))**2, axis=(1,2))\n",
    "    thresh = np.sort(x_dists)[x_dists.size//20]\n",
    "    idx_0 = np.where(x_dists < thresh)[0]\n",
    "    print(len(idx_0))\n",
    "\n",
    "    plt.hist(x_dists, bins=np.linspace(0, 100, 50) )\n",
    "    plt.plot([thresh, thresh], [0, 50], 'r')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(12,8))\n",
    "    for i in range(np.min((25, len(idx_0)))):\n",
    "        plt.subplot(5,5,i+1)\n",
    "        j = i# np.random.randint(len(idx_0))\n",
    "        plt.imshow(samples[idx_0[j],0,:,:], interpolation='None')\n",
    "    plt.show()\n",
    "\n",
    "    m_,S_ = parameters.mean(axis=0), np.cov(parameters.T)\n",
    "    #S_[0,0] = 1.\n",
    "    posterior_sampled = dd.Gaussian(m=m_, S=S_)\n",
    "\n",
    "    # all pairwise marginals of fitted posterior\n",
    "    plot_pdf(posterior_sampled, lims=[-5,5], figsize=(16,16), samples=parameters[idx_0,:].T);\n",
    "\n",
    "    print('posterior mean:', posterior.xs[0].m)\n",
    "    print('sampled mean:', posterior_sampled.m)\n",
    "    plt.plot(posterior.xs[0].m)\n",
    "    plt.plot(posterior_sampled.m)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# all pairwise marginals of fitted posterior\n",
    "plot_pdf(posterior.xs[0], lims=[-5,5], gt=pars_true.reshape(-1), figsize=(16,16),\n",
    "labels_params=['b','A_1','A_2','f_1','f_2','log ratio','log width']+['kt_'+str(i) for i in range(filter_shape[2])]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compare with pairwise prior marginals\n",
    "plot_pdf(p, lims=[-2,2], gt=pars_true.reshape(-1), figsize=(16,16),\n",
    "labels_params=['b','A_1','A_2','f_1','f_2','log ratio','log width']+['kt_'+str(i) for i in range(filter_shape[2])]);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare with maprf sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "import maprf.config as config\n",
    "import maprf.rfs.v1 as V1\n",
    "import maprf.invlink as invlink\n",
    "import maprf.glm as glm \n",
    "from maprf.utils import *\n",
    "from maprf.data import SymbolicData\n",
    "import time\n",
    "import maprf.filters as filters\n",
    "import maprf.kernels as kernels\n",
    "# from maprf.sampling.slice import EllipticalSliceSampler as ESS\n",
    "\n",
    "import theano.printing as printing\n",
    "import theano.tensor as tt\n",
    "\n",
    "import theano\n",
    "from theano import In\n",
    "\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from os import path\n",
    "from maprf.inference import *\n",
    "\n",
    "def pyprint(var, filename):\n",
    "    printing.pydotprint(var, format='pdf', outfile=filename, high_contrast=False, with_ids=True)\n",
    "\n",
    "cfg = config.load(path.join('config.yaml'))\n",
    "\n",
    "# The forward part of the model\n",
    "rf = V1.SimpleLinear()\n",
    "emt = glm.Poisson()\n",
    "# inputs and outputs\n",
    "data = [theano.shared(empty(3), 'frames'),\n",
    "        theano.shared(empty(1, dtype='int64'))]\n",
    "frames, spikes = data\n",
    "\n",
    "# fill the grids\n",
    "rf.grids['s'][0].set_value(m._gen.grid_x)\n",
    "rf.grids['s'][1].set_value(m._gen.grid_y)\n",
    "rf.grids['t'][0].set_value(m._gen.axis_t)\n",
    "\n",
    "import numpy.linalg as linalg\n",
    "# build prior for temporal kernel\n",
    "ax_t = rf.grids['t'][0].get_value()\n",
    "s = ax_t / 0.075\n",
    "n = ax_t.shape[0]\n",
    "Λ =  np.diag(s * np.exp(1 - s))\n",
    "D = np.eye(n) - np.eye(n, k=-1)\n",
    "F = np.dot(D, D.T)\n",
    "Σ = np.dot(Λ, linalg.inv(F).dot(Λ))\n",
    "\n",
    "# inference model\n",
    "inference = Inference(rf, emt)\n",
    "inference.priors = cfg['priors']\n",
    "inference.priors['kernel']['t'] = {'mu': np.zeros_like(ax_t), 'sigma': linalg.cholesky(Σ)}\n",
    "\n",
    "\n",
    "inference.add_sampler(GaborSampler())\n",
    "inference.add_sampler(KernelSampler())\n",
    "\n",
    "plt.imshow(Σ, interpolation='None')\n",
    "plt.show()\n",
    "\n",
    "print('inputs: ', inference.inputs)\n",
    "print('priors: ', inference.priors)\n",
    "\n",
    "inference.build(data)\n",
    "inference.compile()\n",
    "\n",
    "\n",
    "inference.loglik['xo'] = 0\n",
    "inference.loglik['yo'] = 0\n",
    "#inference.loglik['kt'] = np.array([ 0.02047043,  0.51640702,  0.61731474,  0.01362172, -0.37586342,\n",
    "#       -0.3750627 , -0.23319645, -0.1131711 , -0.04670192, -0.01714343,\n",
    "#       -0.00575457])\n",
    "inference.loglik['kt'] = np.array([0.5, 0.])\n",
    "inference.loglik['vec_A'] = np.zeros(2)  # np.array([2.0, 0.0])\n",
    "inference.loglik['vec_f'] = np.zeros(2)  # 0.3 * np.array([np.cos(0.7), np.sin(0.7)])\n",
    "inference.loglik['log_γ'] = 0.0\n",
    "inference.loglik['log_b'] = np.log(2.5)\n",
    "\n",
    "frames.set_value(obs['I'].reshape(-1,d,d))\n",
    "spikes.set_value(obs['data'])\n",
    "plt.plot(spikes.get_value())\n",
    "\n",
    "print(np.sum(obs['data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "x_dists = np.sum( (trn_data[1][:,0,:,:] - obs_stats.reshape(1, d,d))**2, axis=(1,2))\n",
    "thresh = 5.\n",
    "idx_0 = np.where(x_dists < thresh)[0]\n",
    "print(len(idx_0))\n",
    "\n",
    "plt.hist(x_dists, bins=np.linspace(0, 100, 50) )\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.imshow(obs_stats.reshape(d,d), interpolation='None')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    j = i# np.random.randint(len(idx_0))\n",
    "    plt.imshow(trn_data[1][idx_0[j],0,:,:], interpolation='None')\n",
    "plt.show()\n",
    "\n",
    "# all pairwise marginals of fitted posterior\n",
    "plot_pdf(posterior.xs[0], lims=[-5,5], figsize=(16,16), samples=trn_data[0][idx_0,:].T);\n",
    "\n",
    "\n",
    "\n",
    "S=np.cov(samples.T)\n",
    "S[0,0] = 1.\n",
    "posterior_sampled = dd.Gaussian(m=samples.mean(axis=0), S=S)\n",
    "\n",
    "# all pairwise marginals of fitted posterior\n",
    "plot_pdf(posterior_sampled, lims=[-5,5], figsize=(16,16), samples=trn_data[0][idx_0,:].T);\n",
    "\n",
    "print('posterior mean:', posterior.xs[0].m)\n",
    "print('sampled mean:', posterior_sampled.m)\n",
    "plt.plot(posterior.xs[0].m)\n",
    "plt.plot(posterior_sampled.m)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "T, L = inference.sample(5000)\n",
    "T = {k.name: t for k, t in T.items()}\n",
    "\n",
    "x = T['xo']\n",
    "y = T['yo']\n",
    "\n",
    "plt.figure(figsize=(15, 4))\n",
    "plt.subplot(121)\n",
    "plt.plot(x[500:])\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.hist(x[500:], alpha=0.5, normed=True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 4))\n",
    "plt.subplot(121)\n",
    "plt.plot(x[500:], y[500:], '.k', alpha=0.1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "try: \n",
    "    np.savez('posterior_samples', {'T' : T})\n",
    "except:\n",
    "    pass\n",
    "T = np.load('posterior_samples.npz')['arr_0'].tolist()['T']\n",
    "\n",
    "T['b'] = np.zeros((T['vec_A'].shape[0], 1))\n",
    "\n",
    "samples = np.hstack([np.atleast_2d(T[key].T).T for key in ['b','vec_A','vec_f','log_γ','log_b', 'kt']])\n",
    "\n",
    "# compare with pairwise priors\n",
    "plot_pdf(posterior.xs[0], lims=[-5,5], gt=pars_true.reshape(-1), figsize=(16,16), samples=samples.T,\n",
    "labels_params=['b','A_1','A_2','f_1','f_2','log ratio','log width']+['kt_'+str(i) for i in range(filter_shape[2])]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "S=np.cov(samples.T)\n",
    "S[0,0] = 1.\n",
    "posterior_sampled = dd.Gaussian(m=samples.mean(axis=0), S=S)\n",
    "\n",
    "# all pairwise marginals of fitted posterior\n",
    "plot_pdf(posterior_sampled, lims=[-5,5], figsize=(16,16), samples=samples.T);\n",
    "\n",
    "print('posterior mean:', posterior.xs[0].m)\n",
    "print('sampled mean:', posterior_sampled.m)\n",
    "plt.plot(posterior.xs[0].m)\n",
    "plt.plot(posterior_sampled.m)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_pdf(posterior_sampled, lims=[-5,5], figsize=(16,16), samples=samples.T);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import delfi.distribution as dd\n",
    "\n",
    "def save_mog(mog, filename=None):\n",
    "    \"\"\"Save mixture of Gaussians (avoiding pickle)\n",
    "    \n",
    "    Saves the key arrays of a Mixture of Gaussians. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    mog : (Mixture of) Gaussian object\n",
    "        mixture \n",
    "    filename : string\n",
    "        desired save file location. If None, does not\n",
    "        save and returns dictionary with arrays instead.\n",
    "    \n",
    "    \"\"\"        \n",
    "    assert isinstance(posterior, (dd.MoG, dd.Gaussian))\n",
    "    \n",
    "    if isinstance(mog, dd.MoG):\n",
    "        \n",
    "        save_dict = {'a'  : mog.a,\n",
    "                     'ms' : [x.m for x in mog.xs],\n",
    "                     'Ss' : [x.S for x in mog.xs],\n",
    "                     'seed' : mog.seed}\n",
    "        \n",
    "    elif isinstance(mog, dd.Gaussian):\n",
    "        \n",
    "        save_dict = {'a'  : np.ones(1),\n",
    "                     'ms' : [mog.m], \n",
    "                     'Ss' : [mog.S],\n",
    "                     'seed' : mog.seed}\n",
    "        \n",
    "            \n",
    "    if not filename is None: \n",
    "        np.save(filename, save_dict)\n",
    "    else:\n",
    "        return save_dict\n",
    "    \n",
    "def load_mog(filename):\n",
    "    \"\"\"Load mixture of Gaussians (avoiding pickle)\n",
    "    \n",
    "    Loads key arrays of a Mixture of Gaussians and returns the \n",
    "    corresponding object. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : string\n",
    "        save file location (with or without file extension)\n",
    "    \n",
    "    \"\"\"\n",
    "    if not filename[-4:]=='.npy':\n",
    "        filename += '.npy'\n",
    "    \n",
    "    sd = np.load(filename)[()]\n",
    "    \n",
    "    mog = dd.MoG(a=sd['a'], ms=sd['ms'], Ss=sd['Ss'], seed=sd['seed'])\n",
    "    \n",
    "    return mog\n",
    "\n",
    "def save_res(p, posterior, network, filename)\n",
    "\n",
    "    prior = save_mog(p)\n",
    "    posterior = save_mog(posterior)\n",
    "    \n",
    "    net_pars = network.params_dict\n",
    "    net_spec = network.spec_dict\n",
    "    \n",
    "    np.savez(filename, prior, posterior, net_pars, net_spec)\n",
    "    \n",
    "    \n",
    "def load_res(filename):\n",
    "    \n",
    "    load_file = np.load(filename)\n",
    "\n",
    "    ld = load_file['p']\n",
    "    p = dd.MoG(a=ld['a'], ms=ld['ms'], Ss=ld['Ss'], seed=ld['seed'])\n",
    "\n",
    "    ld = load_file['posterior']\n",
    "    posterior = dd.MoG(a=ld['a'], ms=ld['ms'], Ss=ld['Ss'], seed=ld['seed'])\n",
    "    \n",
    "    ns = load_file['net_spec']\n",
    "    network = NeuralNetwork(n_inputs=ns['n_inputs'],\n",
    "                            n_outputs=ns['n_outputs'],\n",
    "                            n_components=ns['n_components'],\n",
    "                            n_filters=ns['n_filters'],\n",
    "                            n_hiddens=ns['n_hiddens'],\n",
    "                            n_rnn=ns['n_rnn'],\n",
    "                            seed=ns['seed']\n",
    "                            svi=ns['svi'])\n",
    "    network.params_dict = load_file['net_pars']\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
