{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deep identity mapping\n",
    "\n",
    "learning receptive field parameters from inputs (white-noise videos) and outputs (spike trains) of linear-nonlinear neuron models with parameterized linear filters\n",
    "\n",
    "## simplistic setup: \n",
    "- model parameters $\\theta$ are the full spatiotemporal kernel (of size d*d, with d < 10), \n",
    "- summary statistic $x_0$ is spike-triggered average\n",
    "- for sufficiently long simulations, posterior mean is just data summary statistic $x_0$. \n",
    "- purely spatial kernel for now (kernel-size in temporal dimentions fixed to 1)  \n",
    "- *very* basic spiking non-linearity and noise model: threshold crossing, no spiking noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# notebook currently depends on code found only in feature_maprf-branch of lfi_models !\n",
    "\n",
    "import delfi.distribution as dd\n",
    "import delfi.generator as dg\n",
    "import delfi.inference as infer\n",
    "import delfi.utils.io as io\n",
    "import delfi.summarystats as ds\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import lfimodels.maprf.utils as utils\n",
    "\n",
    "from lfimodels.maprf.maprf import maprf\n",
    "from lfimodels.maprf.maprfStats import maprfStats\n",
    "from delfi.utils.viz import plot_pdf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "seed = 42\n",
    "\n",
    "d = 51 # edge length of (quadratic) receptive field\n",
    "parametrization = 'gaussian' # RF is Gaussian bump with specific mean and cov \n",
    "\n",
    "filter_shape = np.array((d,d,1))\n",
    "m = maprf(filter_shape=filter_shape, \n",
    "          parametrization=parametrization,\n",
    "          seed=seed, \n",
    "          duration=1000 )\n",
    "\n",
    "if parametrization=='gaussian':\n",
    "    p = dd.GaussianRF(ab=[-2,-0],\n",
    "                      dd=[-d//2,d//2,-d//2,d//2],\n",
    "                      ks = np.array([3,3]), cd = [-.9,0.9])\n",
    "elif parametrization=='full':\n",
    "    p = dd.Gaussian(m=np.zeros(d*d+1), P=1/100*np.eye(d*d+1))\n",
    "\n",
    "s = maprfStats(n_summary=m.n_params)\n",
    "g = dg.Default(model=m, prior=p, summary=s)\n",
    "\n",
    "true_params, labels_params = utils.obs_params(filter_shape,parametrization)\n",
    "true_params = np.array([-d, -d//4,-d//4,10,15,0.7])\n",
    "obs = m.gen_single(true_params)\n",
    "obs_stats = s.calc([obs])\n",
    "\n",
    "h_true = m.params_to_rf(true_params[1:])\n",
    "plt.figure(figsize=(16,7))\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(np.dot( obs['I'], h_true) + true_params[0])\n",
    "plt.title('neural activation function over observed data')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(h_true.reshape(d,d), interpolation='None')\n",
    "plt.title('ground-truth filter')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(obs_stats.T[1:].reshape(filter_shape[0],filter_shape[1]), \n",
    "          interpolation='None')\n",
    "plt.title('summary statistics')\n",
    "plt.show()\n",
    "\n",
    "# bunch of example prior draws\n",
    "plt.figure(figsize=(16,7))\n",
    "for i in range(10):\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.imshow(m.params_to_rf(p.gen()[0,1:]).reshape(d,d), interpolation='None')\n",
    "plt.subplot(2,5,3)\n",
    "plt.title('RF prior samples')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "obs['data'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "res = infer.SNPE(g, obs=obs_stats, n_hiddens=[20,20])\n",
    "\n",
    "out = res.run(10000, n_rounds=1, minibatch=50, epochs=1000)\n",
    "posterior = res.predict(obs_stats)\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(1,4,1)\n",
    "h_prior = m.params_to_rf(p.mean[1:])\n",
    "plt.imshow(h_prior.reshape(d,d), interpolation='None')\n",
    "plt.title('prior mean filter')\n",
    "plt.subplot(1,4,2)\n",
    "h_est =  m.params_to_rf(posterior.calc_mean_and_cov()[0][1:])\n",
    "plt.imshow(h_est.reshape(d,d), interpolation='None')\n",
    "plt.title('posterior mean filter')\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(h_true.reshape(d,d), \n",
    "          interpolation='None')\n",
    "plt.title('true spatial filter')\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(obs_stats.T[1:].reshape(filter_shape[0],filter_shape[1]), \n",
    "          interpolation='None')\n",
    "plt.title('x0')\n",
    "plt.show()\n",
    "\n",
    "#print('prior mean\\n', p.mean[1:].reshape(-1,1))\n",
    "#print('post mean\\n', posterior.calc_mean_and_cov()[0][1:].reshape(-1,1))\n",
    "#print('true pars\\n', true_params[1:].reshape(-1,1))\n",
    "#print('x0\\n', obs_stats.T[1:]) \n",
    "\n",
    "posterior = res.predict(obs_stats)\n",
    "plot_pdf(posterior.xs[0], lims=[-5,5], gt=true_params, figsize=(12,12));\n",
    "tmp=posterior.xs[0]\n",
    "tmp.eval(true_params.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# construction site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lasagne\n",
    "import lasagne.init as linit\n",
    "import lasagne.layers as ll\n",
    "import lasagne.nonlinearities as lnl\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "import collections\n",
    "import delfi.distribution as dd\n",
    "import delfi.neuralnet.layers as dl\n",
    "from delfi.neuralnet.Trainer import Trainer\n",
    "\n",
    "from delfi.utils.odict import first, last, nth\n",
    "\n",
    "dtype = theano.config.floatX\n",
    "\n",
    "class cNeuralNet(object):\n",
    "    def __init__(self, n_inputs, n_outputs, n_components=1, n_filters=[10,10], n_hiddens=[10, 10],\n",
    "                 n_rnn=None, seed=None, svi=True):\n",
    "        \"\"\"Initialize a mixture density network with custom layers\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_inputs : (int, int)\n",
    "            Dimensionality of input\n",
    "        n_outputs : int\n",
    "            Dimensionality of output\n",
    "        n_components : int\n",
    "            Number of components of the mixture density\n",
    "        n_filters : list of ints\n",
    "            Number of filters  per convolutional layer\n",
    "        n_hiddens : list of ints\n",
    "            Number of hidden units per fully connected layer\n",
    "        n_rnn : None or int\n",
    "            Number of RNN units\n",
    "        seed : int or None\n",
    "            If provided, random number generator will be seeded\n",
    "        svi : bool\n",
    "            Whether to use SVI version or not\n",
    "        \"\"\"\n",
    "        self.n_components = n_components\n",
    "        self.n_hiddens = n_hiddens\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_outputs = n_outputs\n",
    "        self.n_rnn = n_rnn\n",
    "        self.svi = svi\n",
    "\n",
    "        self.seed = seed\n",
    "        if seed is not None:\n",
    "            self.rng = np.random.RandomState(seed=seed)\n",
    "        else:\n",
    "            self.rng = np.random.RandomState()\n",
    "        lasagne.random.set_rng(self.rng)\n",
    "\n",
    "        # placeholders\n",
    "        # stats : input placeholder, (batch, self.n_inputs)\n",
    "        # params : output placeholder, (batch, self.n_outputs)\n",
    "        self.stats = tt.tensor4('stats', dtype=dtype)\n",
    "        self.params = tt.matrix('params', dtype=dtype)\n",
    "\n",
    "        # compose layers\n",
    "        self.layer = collections.OrderedDict()\n",
    "\n",
    "        # input layer\n",
    "        self.layer['input'] = ll.InputLayer(\n",
    "            (None, 1, self.n_inputs[0], self.n_inputs[1]), input_var=self.stats)\n",
    "        # ... or substitute NaN for zero\n",
    "        # ... or learn replacement values\n",
    "        # ... or a recurrent neural net\n",
    "\n",
    "        # convolutional layers\n",
    "        for l in range(len(n_filters)):\n",
    "            self.layer['conv_' + str(l + 1)] = ll.Conv2DLayer(\n",
    "                           incoming=last(self.layer), \n",
    "                           num_filters=n_filters[l], \n",
    "                           filter_size=3, \n",
    "                           stride=(2, 2), \n",
    "                           pad=0, \n",
    "                           untie_biases=False, \n",
    "                           W=lasagne.init.GlorotUniform(), \n",
    "                           b=lasagne.init.Constant(0.), \n",
    "                           nonlinearity=lasagne.nonlinearities.rectify, \n",
    "                           flip_filters=True, \n",
    "                           convolution=theano.tensor.nnet.conv2d)\n",
    "        \n",
    "        self.layer['flatten'] = ll.FlattenLayer(\n",
    "                            incoming=last(self.layer), \n",
    "                            outdim = 2)\n",
    "        # if len(n_filters)==0, this directly reshapes the input layer to 2D\n",
    "        \n",
    "        # hidden layers\n",
    "        for l in range(len(n_hiddens)):\n",
    "            self.layer['hidden_' + str(l + 1)] = dl.FullyConnectedLayer(\n",
    "                last(self.layer), n_units=n_hiddens[l],\n",
    "                svi=svi, name='h' + str(l + 1))\n",
    "            \n",
    "            \n",
    "        last_hidden = last(self.layer)\n",
    "\n",
    "        # mixture layers\n",
    "        self.layer['mixture_weights'] = dl.MixtureWeightsLayer(\n",
    "            last_hidden, n_units=n_components, actfun=lnl.softmax, svi=svi,\n",
    "            name='weights')\n",
    "        self.layer['mixture_means'] = dl.MixtureMeansLayer(\n",
    "            last_hidden, n_components=n_components, n_dim=n_outputs, svi=svi,\n",
    "            name='means')\n",
    "        self.layer['mixture_precisions'] = dl.MixturePrecisionsLayer(\n",
    "            last_hidden, n_components=n_components, n_dim=n_outputs, svi=svi,\n",
    "            name='precisions')\n",
    "        last_mog = [self.layer['mixture_weights'],\n",
    "                    self.layer['mixture_means'],\n",
    "                    self.layer['mixture_precisions']]\n",
    "\n",
    "        # mixture parameters\n",
    "        # a : weights, matrix with shape (batch, n_components)\n",
    "        # ms : means, list of len n_components with (batch, n_dim, n_dim)\n",
    "        # Us : precision factors, n_components list with (batch, n_dim, n_dim)\n",
    "        # ldetUs : log determinants of precisions, n_comp list with (batch, )\n",
    "        self.a, self.ms, precision_out = ll.get_output(last_mog,\n",
    "                                                       deterministic=False)\n",
    "\n",
    "        self.Us = precision_out['Us']\n",
    "        self.ldetUs = precision_out['ldetUs']\n",
    "\n",
    "        self.comps = {\n",
    "            **{'a': self.a},\n",
    "            **{'m' + str(i): self.ms[i] for i in range(self.n_components)},\n",
    "            **{'U' + str(i): self.Us[i] for i in range(self.n_components)}}\n",
    "\n",
    "        # log probability of y given the mixture distribution\n",
    "        # lprobs_comps : log probs per component, list of len n_components with (batch, )\n",
    "        # probs : log probs of mixture, (batch, )\n",
    "        \n",
    "        self.lprobs_comps = [-0.5 * tt.sum(tt.sum((self.params - m).dimshuffle(\n",
    "            [0, 'x', 1]) * U, axis=2)**2, axis=1) + ldetU\n",
    "            for m, U, ldetU in zip(self.ms, self.Us, self.ldetUs)]\n",
    "        self.lprobs = tt.log(tt.sum(tt.exp(tt.stack(self.lprobs_comps,\n",
    "                                                    axis=1) + tt.log(self.a)),\n",
    "                                    axis=1)) - (0.5 * self.n_outputs * np.log(2 * np.pi))\n",
    "\n",
    "        # the quantities from above again, but with deterministic=True\n",
    "        # --- in the svi case, this will disable injection of randomness;\n",
    "        # the mean of weights is used instead\n",
    "        self.da, self.dms, dprecision_out = ll.get_output(last_mog,\n",
    "                                                          deterministic=True)\n",
    "        self.dUs = dprecision_out['Us']\n",
    "        self.dldetUs = dprecision_out['ldetUs']\n",
    "        self.dcomps = {\n",
    "            **{'a': self.da},\n",
    "            **{'m' + str(i): self.dms[i] for i in range(self.n_components)},\n",
    "            **{'U' + str(i): self.dUs[i] for i in range(self.n_components)}}\n",
    "        self.dlprobs_comps = [-0.5 * tt.sum(tt.sum((self.params - m).dimshuffle(\n",
    "            [0, 'x', 1]) * U, axis=2)**2, axis=1) + ldetU\n",
    "            for m, U, ldetU in zip(self.dms, self.dUs, self.dldetUs)]\n",
    "        self.dlprobs = tt.log(tt.sum(tt.exp(tt.stack(self.dlprobs_comps,\n",
    "                                                     axis=1) + tt.log(self.da)),\n",
    "                                     axis=1)) - (0.5 * self.n_outputs * np.log(2 * np.pi))        \n",
    "\n",
    "        # parameters of network\n",
    "        self.aps = ll.get_all_params(last_mog)  # all parameters\n",
    "        self.mps = ll.get_all_params(last_mog, mp=True)  # means\n",
    "        self.sps = ll.get_all_params(last_mog, sp=True)  # log stds\n",
    "\n",
    "        # weight and bias parameter sets as seperate lists\n",
    "        self.mps_wp = ll.get_all_params(last_mog, mp=True, wp=True)\n",
    "        self.sps_wp = ll.get_all_params(last_mog, sp=True, wp=True)\n",
    "        self.mps_bp = ll.get_all_params(last_mog, mp=True, bp=True)\n",
    "        self.sps_bp = ll.get_all_params(last_mog, sp=True, bp=True)\n",
    "\n",
    "        # theano functions\n",
    "        self.compile_funs()\n",
    "\n",
    "    def compile_funs(self):\n",
    "        \"\"\"Compiles theano functions\"\"\"\n",
    "        self._f_eval_comps = theano.function(\n",
    "            inputs=[self.stats],\n",
    "            outputs=self.dcomps)\n",
    "        self._f_eval_lprobs = theano.function(\n",
    "            inputs=[self.params, self.stats],\n",
    "            outputs=self.dlprobs)\n",
    "\n",
    "    def eval_comps(self, stats):\n",
    "        \"\"\"Evaluate the parameters of all mixture components at given inputs\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        stats : np.array\n",
    "            rows are input locations\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        mixing coefficients, means and scale matrices\n",
    "        \"\"\"\n",
    "        return self._f_eval_comps(stats.astype(dtype))\n",
    "\n",
    "    def eval_lprobs(self, params, stats):\n",
    "        \"\"\"Evaluate log probabilities for given input-output pairs.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        params : np.array\n",
    "        stats : np.array\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        log probabilities : log p(params|stats)\n",
    "        \"\"\"\n",
    "        return self._f_eval_lprobs(params.astype(dtype), stats.astype(dtype))\n",
    "\n",
    "    def get_mog(self, stats, n_samples=None):\n",
    "        \"\"\"Return the conditional MoG at location x\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        stats : np.array\n",
    "            single input location\n",
    "        n_samples : None or int\n",
    "            ...\n",
    "        \"\"\"\n",
    "        assert stats.shape[0] == 1, 'x.shape[0] needs to be 1'\n",
    "\n",
    "        comps = self.eval_comps(stats)\n",
    "        a = comps['a'][0]\n",
    "        ms = [comps['m' + str(i)][0] for i in range(self.n_components)]\n",
    "        Us = [comps['U' + str(i)][0] for i in range(self.n_components)]\n",
    "\n",
    "        return dd.MoG(a=a, ms=ms, Us=Us, seed=self.gen_newseed())\n",
    "\n",
    "    def gen_newseed(self):\n",
    "        \"\"\"Generates a new random seed\"\"\"\n",
    "        if self.seed is None:\n",
    "            return None\n",
    "        else:\n",
    "            return self.rng.randint(0, 2**31)\n",
    "\n",
    "    @property\n",
    "    def params_dict(self):\n",
    "        \"\"\"Getter for params as dict\"\"\"\n",
    "        pdict = {}\n",
    "        for p in self.aps:\n",
    "            pdict[str(p)] = p.get_value()\n",
    "        return pdict\n",
    "\n",
    "    @params_dict.setter\n",
    "    def params_dict(self, pdict):\n",
    "        \"\"\"Setter for params as dict\"\"\"\n",
    "        for p in self.aps:\n",
    "            if str(p) in pdict.keys():\n",
    "                p.set_value(pdict[str(p)])\n",
    "\n",
    "    @property\n",
    "    def spec_dict(self):\n",
    "        \"\"\"Specs as dict\"\"\"\n",
    "        return {'n_inputs': self.n_inputs,\n",
    "                'n_outputs': self.n_outputs,\n",
    "                'n_components': self.n_components,\n",
    "                'n_hiddens': self.n_hiddens,\n",
    "                'n_rnn': self.n_rnn,\n",
    "                'seed': self.seed,\n",
    "                'svi': self.svi}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_inputs = [d,d]\n",
    "n_outputs = m.n_params\n",
    "n_components=1\n",
    "n_hiddens=[10,10]\n",
    "n_filters=[10,10,10]\n",
    "n_train_round = 1\n",
    "\n",
    "trn_data = g.gen(1000)\n",
    "trn_data = (trn_data[0], trn_data[1][:,1:].reshape(-1,1,d,d))\n",
    "\n",
    "network = cNeuralNet(n_inputs, \n",
    "                     n_outputs, \n",
    "                     n_components, \n",
    "                     n_filters=n_filters, \n",
    "                     n_hiddens=n_hiddens,\n",
    "                     seed=seed,\n",
    "                     svi=False)\n",
    "loss = -tt.mean(network.lprobs)\n",
    "\n",
    "\n",
    "trn_inputs = [network.params, network.stats]\n",
    "t = Trainer(network, loss,\n",
    "            trn_data=trn_data, trn_inputs=trn_inputs)\n",
    "\n",
    "epochs = 200\n",
    "minibatch = 50\n",
    "logs=[]\n",
    "logs.append(t.train(epochs=epochs, minibatch=minibatch))\n",
    "\n",
    "posterior = network.get_mog(obs_stats[0,1:].reshape(1,1,d,d))\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(1,4,1)\n",
    "h_prior = m.params_to_rf(p.mean[1:])\n",
    "plt.imshow(h_prior.reshape(d,d), interpolation='None')\n",
    "plt.title('prior mean filter')\n",
    "plt.subplot(1,4,2)\n",
    "h_est =  m.params_to_rf(posterior.calc_mean_and_cov()[0][1:])\n",
    "plt.imshow(h_est.reshape(d,d), interpolation='None')\n",
    "plt.title('posterior mean filter')\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(h_true.reshape(d,d), \n",
    "          interpolation='None')\n",
    "plt.title('true spatial filter')\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(obs_stats.T[1:].reshape(filter_shape[0],filter_shape[1]), \n",
    "          interpolation='None')\n",
    "plt.title('x0')\n",
    "plt.show()\n",
    "\n",
    "plot_pdf(posterior.xs[0], lims=[-5,5], gt=true_params, figsize=(12,12));\n",
    "\n",
    "\n",
    "# bunch of example posterior draws\n",
    "plt.figure(figsize=(16,7))\n",
    "for i in range(10):\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.imshow(m.params_to_rf(posterior.xs[0].gen()[0,1:]).reshape(d,d), interpolation='None')\n",
    "plt.subplot(2,5,3)\n",
    "plt.title('RF posterior samples')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.signal as ss\n",
    "from scipy.stats import multivariate_normal as mvn\n",
    "\n",
    "from delfi.simulator.BaseSimulator import BaseSimulator\n",
    "\n",
    "import maprf.rfs.v1 as v1\n",
    "import maprf.glm as glm\n",
    "from maprf.generation import Generator\n",
    "\n",
    "class maprf(BaseSimulator):\n",
    "    \n",
    "    def __init__(self, \n",
    "        duration=10, \n",
    "        filter_shape=np.array((1,1,1)), \n",
    "        parametrization='full',\n",
    "        seed=None):\n",
    "        \"\"\"GLM simulator\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        duration : int\n",
    "            Duration of traces in ms\n",
    "        size_filter : (Nx, Ny, T)\n",
    "            Size of spatiotemporal filter\n",
    "        parametrization : string\n",
    "            parametrization of linear filter\n",
    "        seed : int or None\n",
    "            If set, randomness across runs is disabled\n",
    "        \"\"\"\n",
    "        super(maprf, self).__init__(dim_param=np.prod(filter_shape).astype(np.int)+1, \n",
    "                                    seed=seed)\n",
    "\n",
    "        self.duration = duration\n",
    "        self.filter_shape = filter_shape\n",
    "        self.len_filter  = filter_shape[-1]\n",
    "        self.size_filter = np.prod(filter_shape[:-1]).astype(np.int)\n",
    "        self.parametrization = parametrization\n",
    "        \n",
    "        # parameters that globally govern the simulations\n",
    "        self.dt = 0.025\n",
    "        self.t = np.arange(0, self.duration, self.dt)                \n",
    "        \n",
    "        # input: gaussian white noise N(0, 1)\n",
    "        self.rng_input = np.random.RandomState(seed=self.gen_newseed())        \n",
    "        self.I = self.rng_input.randn(len(self.t),self.size_filter)        \n",
    "                \n",
    "        if parametrization=='full':\n",
    "\n",
    "            self.n_params = np.prod(filter_shape).astype(np.int) + 1\n",
    "\n",
    "        elif  parametrization=='gaussian':\n",
    "\n",
    "            self.n_params = self.len_filter + 5 # offset + 2x (2D mean) + 3x (cov)\n",
    "\n",
    "        elif  parametrization=='gabor':\n",
    "            \n",
    "            self.n_params = 10 # 'glm':         'bias', 'binsize'\n",
    "                              # 'kernel': 's': 'angle','freq','gain','phase','ratio','width',\n",
    "                              #           't': 'tau'\n",
    "                    \n",
    "            kernel = v1.SimpleLinear_full_kt()\n",
    "            spikes = glm.Poisson()\n",
    "\n",
    "            self._gen = Generator(kernel, spikes, seed=seed)\n",
    "            d = self.filter_shape[0]\n",
    "            self._gen.axis_x = np.linspace(-5, 5, d)\n",
    "            d = self.filter_shape[1]\n",
    "            self._gen.axis_y = np.linspace(-5, 5, d)\n",
    "            self._gen.axis_t = self.dt * np.arange(0,self.len_filter)\n",
    "            \n",
    "            self._gen.grid_x, self._gen.grid_y = np.meshgrid(\n",
    "                                 self._gen.axis_x, \n",
    "                                 self._gen.axis_y)            \n",
    "            \n",
    "            self._gen.build()\n",
    "            \n",
    "            self._gen.x = self.I.reshape(len(self.t), \n",
    "                                         self.filter_shape[0], \n",
    "                                         self.filter_shape[1])\n",
    "            \n",
    "                \n",
    "        else:\n",
    "            raise NotImplementedError        \n",
    "\n",
    "    def gen_single(self, params):\n",
    "        \"\"\"Forward model for simulator for single parameter set\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        params : list or np.array, 1d of length dim_param\n",
    "            Parameter vector\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict : dictionary with data\n",
    "            The dictionary must contain a key data that contains the results of the forward run. Additional entries can be present.\n",
    "        \"\"\"\n",
    "        params = np.asarray(params)\n",
    "\n",
    "        assert params.ndim == 1, 'params.ndim must be 1'\n",
    "        assert params.shape[0] == self.n_params, 'params.shape[0] must be dim params long'\n",
    "\n",
    "        if self.parametrization=='full':\n",
    "            \n",
    "            b0 = params[0]\n",
    "            b0.astype(float)            \n",
    "            h = params[1:]\n",
    "            h.astype(float)\n",
    "\n",
    "        # construct h from parameters\n",
    "        elif  self.parametrization=='gaussian':\n",
    "\n",
    "            b0 = params[0]\n",
    "            b0.astype(float)\n",
    "            h = self.params_to_rf(params[1:])\n",
    "\n",
    "        if self.parametrization in ('full', 'gaussian'):    \n",
    "        \n",
    "            assert self.filter_shape[2] == 1 # else not yet implemented            \n",
    "        \n",
    "            # simulation\n",
    "            assert self.len_filter == 1 # temporal filtering not implemented yet!\n",
    "            psi = b0 + np.dot(self.I, h) #ss.lfilter(h, 1, self.I, axis=0).sum(axis=1)\n",
    "\n",
    "            # psi goes through a sigmoid non-linearity: firing probability\n",
    "            z = 1 /(1 + np.exp(-psi)).reshape(-1,1)        \n",
    "\n",
    "            # sample the spikes\n",
    "            N = 1   # number of trials\n",
    "            y = self.rng.uniform(size=(len(self.t), N)) < z\n",
    "            y = np.sum(y, axis=1)\n",
    "            \n",
    "        elif self.parametrization == 'gabor':\n",
    "                        \n",
    "            params_dict = {'glm': {'bias': params[0], \n",
    "                                   'binsize': params[1]},\n",
    "                          'kernel': {'s': {'angle': params[2],\n",
    "                                           'freq': params[3],\n",
    "                                           'gain': params[4],\n",
    "                                           'phase': params[5],\n",
    "                                           'ratio': params[6],\n",
    "                                           'width': params[7]},\n",
    "                                     't': {'value': params[8:].reshape(-1)}}}   \n",
    "            \n",
    "            self._gen.set_params(params_dict)\n",
    "            self._gen._sample()\n",
    "            y = self._gen.y.copy()\n",
    "            \n",
    "        return {'data': y, 'I': self.I}\n",
    "\n",
    "    def params_to_rf(self, params_rf):\n",
    "\n",
    "        if self.parametrization=='full':\n",
    "            \n",
    "            h = params_rf\n",
    "\n",
    "        elif self.parametrization=='gaussian':\n",
    "\n",
    "            c = params_rf[4] * params_rf[2] * params_rf[3] # corr to cov\n",
    "            C = np.array([[params_rf[2]**2,c],[c,params_rf[3]**2]])\n",
    "            dx, dy = self.filter_shape[0]//2, self.filter_shape[1]//2\n",
    "            assert self.filter_shape[0]>2*dx and self.filter_shape[1]>2*dy\n",
    "\n",
    "            dx, dy = range(-dx,dx+1), range(-dy,dy+1)\n",
    "            h = mvn.pdf(np.mgrid[dx, dy].reshape(2,-1).T, \n",
    "                        mean=params_rf[:2],  \n",
    "                        cov=C + 1e-5*np.eye(2))\n",
    "            h -= h.mean()\n",
    "            std = h.std() \n",
    "            if std>0: \n",
    "                h /= std            \n",
    "\n",
    "\n",
    "            \"\"\" # Old Gaussian parametrization with sq. of full cov matrix \n",
    "            B = params_rf[2:].reshape(2,2)\n",
    "            dx, dy = self.filter_shape[0]//2, self.filter_shape[1]//2\n",
    "            assert self.filter_shape[0]>2*dx and self.filter_shape[1]>2*dy\n",
    "\n",
    "            dx, dy = range(-dx,dx+1), range(-dy,dy+1)\n",
    "            h = mvn.pdf(np.mgrid[dx, dy].reshape(2,-1).T, \n",
    "                        mean=params_rf[:2],  \n",
    "                        cov=B.dot(B.T) + 1e-5*np.eye(2))\n",
    "            h -= h.mean()\n",
    "            std = h.std() \n",
    "            if std>0: \n",
    "                h /= std            \n",
    "            \"\"\"\n",
    "        return h        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lfimodels.maprf.maprfStats import maprfStats\n",
    "import theano\n",
    "\n",
    "seed = 42\n",
    "\n",
    "s = maprfStats(n_summary=10)\n",
    "\n",
    "d = 21 # edge length of (quadratic) receptive field\n",
    "parametrization = 'gabor' # RF is Gaussian bump with specific mean and cov \n",
    "\n",
    "filter_shape = np.array((d,d,2))\n",
    "m = maprf(filter_shape=filter_shape, \n",
    "          parametrization=parametrization,\n",
    "          seed=seed, \n",
    "          duration=1000 )\n",
    "\n",
    "eval_ks = theano.function(list(m._gen.inputs.values()), m._gen.rf.ks, on_unused_input='ignore')\n",
    "eval_kt = theano.function(list(m._gen.inputs.values()), m._gen.rf.kt, on_unused_input='ignore')\n",
    "def rf(params): \n",
    "    \n",
    "    ks = eval_ks(bias=params[0], \n",
    "                 binsize=params[1],\n",
    "                 angle=params[2],\n",
    "                 freq=params[3],\n",
    "                 gain=params[4],\n",
    "                 phase=params[5],\n",
    "                 ratio=params[6],\n",
    "                 width=params[7])\n",
    "    kt = eval_kt(value=params[8:])\n",
    "    \n",
    "    return ks,kt\n",
    "\n",
    "\n",
    "pars_true = np.array([-0.5,.025,.7,.3,2.,1.,1.,2.5,1.,0.])\n",
    "\n",
    "out = m.gen_single(pars_true)\n",
    "sta = s.calc([out])[0,1:].reshape(d,d)\n",
    "\n",
    "# 'glm':         'bias', 'binsize'\n",
    "# 'kernel': 's': 'angle','freq','gain','phase','ratio','width',\n",
    "#           't': 'value'\n",
    "\n",
    "p = dd.Uniform(lower = np.array([-1,  0.2, -1, -1, 0, -1, 0, .5, 0, 0]), \n",
    "               upper = np.array([ 1,  0.3,  1,  1, 5,  1, 2,  2, 1, 1]))\n",
    "#p = dd.Gaussian(m=np.zeros(10), P=1/10*np.eye(10))\n",
    "\n",
    "g = dg.Default(model=m, prior=p, summary=s)\n",
    "\n",
    "obs = m.gen_single(pars_true)\n",
    "obs_stats = s.calc([obs])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "n_inputs = [d,d]\n",
    "n_outputs = m.n_params\n",
    "n_components=1\n",
    "n_hiddens=[20,20]\n",
    "n_filters=[16,16,32]\n",
    "n_train_round = 1\n",
    "\n",
    "trn_data = g.gen(10000)\n",
    "trn_data = (trn_data[0], trn_data[1][:,1:].reshape(-1,1,d,d))\n",
    "\n",
    "network = cNeuralNet(n_inputs, \n",
    "                     n_outputs, \n",
    "                     n_components, \n",
    "                     n_filters=n_filters, \n",
    "                     n_hiddens=n_hiddens,\n",
    "                     seed=seed,\n",
    "                     svi=False)\n",
    "loss = -tt.mean(network.lprobs)\n",
    "\n",
    "\n",
    "trn_inputs = [network.params, network.stats]\n",
    "t = Trainer(network, loss,\n",
    "            trn_data=trn_data, trn_inputs=trn_inputs)\n",
    "\n",
    "epochs = 100\n",
    "minibatch = 50\n",
    "logs=[]\n",
    "logs.append(t.train(epochs=epochs, minibatch=minibatch))\n",
    "\n",
    "posterior = network.get_mog(obs_stats[0,1:].reshape(1,1,d,d))\n",
    "\n",
    "\n",
    "# bunch of example prior draws\n",
    "plt.figure(figsize=(16,10))\n",
    "for i in range(15):\n",
    "    plt.subplot(3,5,i+1)\n",
    "    pars = p.gen().reshape(-1)\n",
    "    plt.imshow(rf(pars)[0], interpolation='None')\n",
    "plt.title('RF prior STAs')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(sta, interpolation='None')\n",
    "plt.title('data STA')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(rf(pars_true)[0], interpolation='None')\n",
    "plt.title('ground-truth posterior RF')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(rf(posterior.xs[0].m)[0], interpolation='None')\n",
    "plt.title('posterior mean STA')\n",
    "plt.show()\n",
    "\n",
    "# bunch of example posterior draws\n",
    "plt.figure(figsize=(16,10))\n",
    "for i in range(15):\n",
    "    plt.subplot(3,5,i+1)\n",
    "    pars = posterior.gen().reshape(-1)\n",
    "    plt.imshow(rf(pars)[0], interpolation='None')\n",
    "plt.title('RF posterior STAs')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plot_pdf(posterior, lims=[-5,5], gt=np.asarray(pars_true).reshape(-1), figsize=(12,12));\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lfimodels.maprf.maprfStats import maprfStats\n",
    "import theano\n",
    "\n",
    "seed = 42\n",
    "\n",
    "s = maprfStats(n_summary=10)\n",
    "\n",
    "d = 21 # edge length of (quadratic) receptive field\n",
    "parametrization = 'gabor' # RF is Gaussian bump with specific mean and cov \n",
    "\n",
    "filter_shape = np.array((d,d,2))\n",
    "m = maprf(filter_shape=filter_shape, \n",
    "          parametrization=parametrization,\n",
    "          seed=seed, \n",
    "          duration=10000 )\n",
    "\n",
    "eval_ks = theano.function(list(m._gen.inputs.values()), m._gen.rf.ks, on_unused_input='ignore')\n",
    "eval_kt = theano.function(list(m._gen.inputs.values()), m._gen.rf.kt, on_unused_input='ignore')\n",
    "def rf(params): \n",
    "    \n",
    "    ks = eval_ks(bias=params[0], \n",
    "                 binsize=params[1],\n",
    "                 angle=params[2],\n",
    "                 freq=params[3],\n",
    "                 gain=params[4],\n",
    "                 phase=params[5],\n",
    "                 ratio=params[6],\n",
    "                 width=params[7])\n",
    "    kt = eval_kt(value=params[8:])\n",
    "    \n",
    "    return ks,kt\n",
    "\n",
    "\n",
    "pars_true = np.array([-0.5,.025,.7,.3,2.,1.,1.,2.5,1.,0.])\n",
    "\n",
    "out = m.gen_single(pars_true)\n",
    "sta = s.calc([out])[0,1:].reshape(d,d)\n",
    "\n",
    "# 'glm':         'bias', 'binsize'\n",
    "# 'kernel': 's': 'angle','freq','gain','phase','ratio','width',\n",
    "#           't': 'value'\n",
    "\n",
    "p = dd.Uniform(lower = np.array([-1,  0.2, -1, -1, 0, -1, 0, .5, 0, 0]), \n",
    "               upper = np.array([ 1,  0.3,  1,  1, 5,  1, 2,  2, 1, 1]))\n",
    "#p = dd.Gaussian(m=np.zeros(10), P=1/10*np.eye(10))\n",
    "\n",
    "g = dg.Default(model=m, prior=p, summary=s)\n",
    "\n",
    "obs = m.gen_single(pars_true)\n",
    "obs_stats = s.calc([obs])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "n_inputs = [d,d]\n",
    "n_outputs = m.n_params\n",
    "n_components=1\n",
    "n_hiddens=[20,20]\n",
    "n_filters=[16,16,32]\n",
    "n_train_round = 1\n",
    "\n",
    "trn_data = g.gen(10000)\n",
    "trn_data = (trn_data[0], trn_data[1][:,1:].reshape(-1,1,d,d))\n",
    "\n",
    "network = cNeuralNet(n_inputs, \n",
    "                     n_outputs, \n",
    "                     n_components, \n",
    "                     n_filters=n_filters, \n",
    "                     n_hiddens=n_hiddens,\n",
    "                     seed=seed,\n",
    "                     svi=False)\n",
    "loss = -tt.mean(network.lprobs)\n",
    "\n",
    "\n",
    "trn_inputs = [network.params, network.stats]\n",
    "t = Trainer(network, loss,\n",
    "            trn_data=trn_data, trn_inputs=trn_inputs)\n",
    "\n",
    "epochs = 100\n",
    "minibatch = 50\n",
    "logs=[]\n",
    "logs.append(t.train(epochs=epochs, minibatch=minibatch))\n",
    "\n",
    "posterior = network.get_mog(obs_stats[0,1:].reshape(1,1,d,d))\n",
    "\n",
    "\n",
    "# bunch of example prior draws\n",
    "plt.figure(figsize=(16,10))\n",
    "for i in range(15):\n",
    "    plt.subplot(3,5,i+1)\n",
    "    pars = p.gen().reshape(-1)\n",
    "    plt.imshow(rf(pars)[0], interpolation='None')\n",
    "plt.title('RF prior STAs')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(sta, interpolation='None')\n",
    "plt.title('data STA')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(rf(pars_true)[0], interpolation='None')\n",
    "plt.title('ground-truth posterior RF')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(rf(posterior.xs[0].m)[0], interpolation='None')\n",
    "plt.title('posterior mean STA')\n",
    "plt.show()\n",
    "\n",
    "# bunch of example posterior draws\n",
    "plt.figure(figsize=(16,10))\n",
    "for i in range(15):\n",
    "    plt.subplot(3,5,i+1)\n",
    "    pars = posterior.gen().reshape(-1)\n",
    "    plt.imshow(rf(pars)[0], interpolation='None')\n",
    "plt.title('RF posterior STAs')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plot_pdf(posterior, lims=[-5,5], gt=np.asarray(pars_true).reshape(-1), figsize=(12,12));\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from maprf.inference import *\n",
    "\n",
    "rf = v1.SimpleLinear()\n",
    "emt = glm.Poisson()\n",
    "\n",
    "\n",
    "# inference model\n",
    "inference = Inference(rf, emt)\n",
    "inference.priors = cfg['priors']\n",
    "inference.priors['kernel']['t'] = {'mu': np.zeros_like(ax_t), 'sigma': linalg.cholesky(Σ)}\n",
    "\n",
    "\n",
    "inference.add_sampler(GaborSampler())\n",
    "inference.add_sampler(KernelSampler())\n",
    "\n",
    "inference.build(data)\n",
    "inference.updates\n",
    "inference.compile()\n",
    "\n",
    "fname = 'example_trace_1'\n",
    "with open(fname + '.npy', 'rb') as file:\n",
    "    __s, __y, __kt = pickle.load(file)\n",
    "inference.loglik['xo'] = 0\n",
    "inference.loglik['yo'] = 0\n",
    "# inference.loglik['dt'] = 0.025\n",
    "# inference.loglik['bias'] = -1.0\n",
    "inference.loglik['kt'] = __kt\n",
    "inference.loglik['vec_A'] = np.zeros(2)  # np.array([2.0, 0.0])\n",
    "inference.loglik['vec_f'] = np.zeros(2)  # 0.3 * np.array([np.cos(0.7), np.sin(0.7)])\n",
    "inference.loglik['log_γ'] = 0.0\n",
    "inference.loglik['log_b'] = np.log(2.5)\n",
    "\n",
    "frames.set_value(__s)\n",
    "spikes.set_value(__y)\n",
    "plt.plot(spikes.get_value())\n",
    "\n",
    "print(np.sum(__y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
