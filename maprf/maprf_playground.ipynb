{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deep identity mapping\n",
    "\n",
    "learning receptive field parameters from inputs (white-noise videos) and outputs (spike trains) of linear-nonlinear neuron models with parameterized linear filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%matplotlib inline\n",
    "# notebook currently depends on code found only in feature_maprf-branch of lfi_models !\n",
    "\n",
    "import delfi.neuralnet as dn\n",
    "import delfi.distribution as dd\n",
    "import delfi.generator as dg\n",
    "import delfi.inference as infer\n",
    "import delfi.utils.io as io\n",
    "import delfi.summarystats as ds\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import lfimodels.maprf.utils as utils\n",
    "\n",
    "from lfimodels.maprf.maprf import maprf\n",
    "from lfimodels.maprf.maprfStats import maprfStats\n",
    "from delfi.utils.viz import plot_pdf\n",
    "\n",
    "import lasagne.layers as ll\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "import collections\n",
    "\n",
    "\n",
    "def pol2cart(v):\n",
    "    return v[0] * np.stack([np.cos(v[1]), np.sin(v[1])])\n",
    "\n",
    "\n",
    "def cart2pol(v):\n",
    "    u1 = np.sqrt(v[0]**2 + v[1]**2)\n",
    "    u2 = np.arctan2(v[1], v[0])\n",
    "    return np.stack([u1, u2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "seed = 42\n",
    "\n",
    "## simulation model\n",
    "\n",
    "d = 41                    # edge length of (quadratic) receptive field\n",
    "parametrization = 'gabor' # ['full', 'gaussian', 'gabor']\n",
    "filter_shape = np.array((d,d,2))\n",
    "m = maprf(filter_shape=filter_shape, \n",
    "          parametrization=parametrization,\n",
    "          seed=seed, \n",
    "          duration=1000 )\n",
    "\n",
    "\n",
    "## prior over simulation parameters\n",
    "\n",
    "prior = collections.OrderedDict()\n",
    "prior['b0'] = {'mu' : np.array([0.]), 'sigma' : np.array([1]) }\n",
    "prior['vec_f']  = {'mu' : np.zeros(2), 'sigma' : 0.4 * np.ones(2) }\n",
    "prior['vec_A']  = {'mu' : np.zeros(2), 'sigma' : 1.0 * np.ones(2) }\n",
    "#prior = priors['kernel']['s']['width'] # fields 'a', 'b', 'f'\n",
    "#mu, sigma = normal_from_ci(*zip(prior['b'], prior['a']), prior['f'])\n",
    "prior['log_γ']  = {'mu' : np.array([-0.098]), 'sigma' : np.array([0.256])}\n",
    "prior['log_b']  = {'mu' : np.array([ 0.955]), 'sigma' : np.array([0.236])}\n",
    "#prior['xo'] = {'mu' : np.array([0.]), 'sigma' : np.array([5/np.sqrt(.5)])}\n",
    "#prior['yo'] = {'mu' : np.array([0.]), 'sigma' : np.array([5/np.sqrt(.5)])}\n",
    "ax_t = m._gen.axis_t\n",
    "Λ =  np.diag(ax_t / 0.075 * np.exp(1 - ax_t / 0.075))\n",
    "D = np.eye(ax_t.shape[0]) - np.eye(ax_t.shape[0], k=-1)\n",
    "F = np.dot(D, D.T)\n",
    "Σ = np.dot(Λ, np.linalg.inv(F).dot(Λ))\n",
    "prior['kt'] = {'mu': np.zeros_like(ax_t), 'sigma': np.linalg.inv(D).dot(Λ)}\n",
    "mu  = np.concatenate([prior[i][ 'mu'  ] for i in prior.keys()])\n",
    "L = np.diag(np.concatenate([prior[i]['sigma'] for i in list(prior.keys())[:-1]]))\n",
    "L = np.block([[L, np.zeros((L.shape[0], ax_t.size))], \n",
    "              [np.zeros((ax_t.size, L.shape[1])), prior['kt']['sigma']]])\n",
    "p = dd.Gaussian(m=mu, S=L.T.dot(L), seed=seed)\n",
    "\n",
    "## data summary staistics\n",
    "\n",
    "s = maprfStats(n_summary=d*d)\n",
    "\n",
    "g = dg.Default(model=m, prior=p, summary=s)\n",
    "\n",
    "## network \n",
    "\n",
    "n_hiddens=[30,30]\n",
    "n_filters=[16,16,16]\n",
    "n_train_round = 1\n",
    "\n",
    "network = dn.NeuralNet.NeuralNet(n_inputs = [d,d], \n",
    "                     n_outputs = m.n_params, \n",
    "                     n_components = 1, \n",
    "                     n_filters=n_filters, \n",
    "                     n_hiddens=n_hiddens,\n",
    "                     seed=seed,\n",
    "                     svi=False)\n",
    "loss = -tt.mean(network.lprobs)\n",
    "\n",
    "\n",
    "test_fun = theano.function([network.stats], [ll.get_output(network.layer['conv_'+str(i)]) for i in range(1,len(n_filters)+1)])\n",
    "print('conv layer shapes:',  [test_fun(np.zeros((10,1,d,d)))[i].shape  for i in range(len(n_filters))])\n",
    "\n",
    "trn_inputs = [network.params, network.stats]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "minibatch = 50\n",
    "n_samples = 5000\n",
    "\n",
    "## training data and true parameters, data, statistics\n",
    "\n",
    "pars_true = np.array([-0.5, \n",
    "                      *pol2cart([0.7, 0.3]), \n",
    "                      *pol2cart([2., 1.]), \n",
    "                      np.log(1.),np.log(2.5), \n",
    "                      1.,0.])\n",
    "obs = m.gen_single(pars_true)\n",
    "obs_stats = s.calc([obs])\n",
    "\n",
    "trn_data = g.gen(n_samples)\n",
    "trn_data = (trn_data[0], trn_data[1].reshape(-1,1,d,d))\n",
    "\n",
    "## training\n",
    "\n",
    "t = dn.Trainer.Trainer(network, loss,\n",
    "            trn_data=trn_data, trn_inputs=trn_inputs)\n",
    "logs=[]\n",
    "logs.append(t.train(epochs=epochs, minibatch=minibatch))\n",
    "\n",
    "posterior = network.get_mog(obs_stats.reshape(1,1,d,d))\n",
    "\n",
    "\n",
    "# bunch of example prior draws\n",
    "plt.figure(figsize=(16,10))\n",
    "for i in range(15):\n",
    "    plt.subplot(3,5,i+1)\n",
    "    plt.imshow(m.params_to_rf(p.gen().reshape(-1))[0], interpolation='None')\n",
    "plt.title('RF prior draws')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(obs_stats.reshape(d,d), interpolation='None')\n",
    "plt.title('data STA')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(m.params_to_rf(pars_true)[0], interpolation='None')\n",
    "plt.title('ground-truth RF')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(m.params_to_rf(posterior.xs[0].m)[0], interpolation='None')\n",
    "plt.title('posterior mean RF')\n",
    "plt.show()\n",
    "\n",
    "# bunch of example posterior draws\n",
    "plt.figure(figsize=(16,10))\n",
    "for i in range(15):\n",
    "    plt.subplot(3,5,i+1)\n",
    "    plt.imshow(m.params_to_rf(posterior.gen().reshape(-1))[0], interpolation='None')\n",
    "plt.title('RF posterior draws')\n",
    "plt.show()\n",
    "\n",
    "plot_pdf(posterior.xs[0], lims=[-5,5], gt=pars_true.reshape(-1), figsize=(16,16),\n",
    "labels_params=['b','A_1','A_2','f_1','f_2','log ratio','log width']+['kt_'+str(i) for i in range(filter_shape[2])]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_pdf(p, lims=[-2,2], gt=pars_true.reshape(-1), figsize=(16,16),\n",
    "labels_params=['b','A_1','A_2','f_1','f_2','log ratio','log width']+['kt_'+str(i) for i in range(filter_shape[2])]);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare with maprf sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m._gen.grid_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "import maprf.config as config\n",
    "import maprf.rfs.v1 as V1\n",
    "import maprf.invlink as invlink\n",
    "import maprf.glm as glm \n",
    "from maprf.utils import *\n",
    "from maprf.data import SymbolicData\n",
    "import time\n",
    "import maprf.filters as filters\n",
    "import maprf.kernels as kernels\n",
    "# from maprf.sampling.slice import EllipticalSliceSampler as ESS\n",
    "\n",
    "import theano.printing as printing\n",
    "import theano.tensor as tt\n",
    "\n",
    "import theano\n",
    "from theano import In\n",
    "\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from os import path\n",
    "from maprf.inference import *\n",
    "\n",
    "def pyprint(var, filename):\n",
    "    printing.pydotprint(var, format='pdf', outfile=filename, high_contrast=False, with_ids=True)\n",
    "\n",
    "cfg = config.load(path.join('config.yaml'))\n",
    "\n",
    "# The forward part of the model\n",
    "rf = V1.SimpleLinear()\n",
    "emt = glm.Poisson()\n",
    "# inputs and outputs\n",
    "data = [theano.shared(empty(3), 'frames'),\n",
    "        theano.shared(empty(1, dtype='int64'))]\n",
    "frames, spikes = data\n",
    "\n",
    "# fill the grids\n",
    "rf.grids['s'][0].set_value(m._gen.grid_x)\n",
    "rf.grids['s'][1].set_value(m._gen.grid_y)\n",
    "rf.grids['t'][0].set_value(m._gen.axis_t)\n",
    "\n",
    "import numpy.linalg as linalg\n",
    "# build prior for temporal kernel\n",
    "ax_t = rf.grids['t'][0].get_value()\n",
    "s = ax_t / 0.075\n",
    "n = ax_t.shape[0]\n",
    "Λ =  np.diag(s * np.exp(1 - s))\n",
    "D = np.eye(n) - np.eye(n, k=-1)\n",
    "F = np.dot(D, D.T)\n",
    "Σ = np.dot(Λ, linalg.inv(F).dot(Λ))\n",
    "\n",
    "# inference model\n",
    "inference = Inference(rf, emt)\n",
    "inference.priors = cfg['priors']\n",
    "inference.priors['kernel']['t'] = {'mu': np.zeros_like(ax_t), 'sigma': linalg.cholesky(Σ)}\n",
    "\n",
    "\n",
    "inference.add_sampler(GaborSampler())\n",
    "inference.add_sampler(KernelSampler())\n",
    "\n",
    "plt.imshow(Σ, interpolation='None')\n",
    "plt.show()\n",
    "\n",
    "print('inputs: ', inference.inputs)\n",
    "print('priors: ', inference.priors)\n",
    "\n",
    "inference.build(data)\n",
    "inference.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m._gen.axis_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "inference.loglik['xo'] = 0\n",
    "inference.loglik['yo'] = 0\n",
    "#inference.loglik['kt'] = np.array([ 0.02047043,  0.51640702,  0.61731474,  0.01362172, -0.37586342,\n",
    "#       -0.3750627 , -0.23319645, -0.1131711 , -0.04670192, -0.01714343,\n",
    "#       -0.00575457])\n",
    "inference.loglik['kt'] = np.array([0.5, 0.])\n",
    "inference.loglik['vec_A'] = np.zeros(2)  # np.array([2.0, 0.0])\n",
    "inference.loglik['vec_f'] = np.zeros(2)  # 0.3 * np.array([np.cos(0.7), np.sin(0.7)])\n",
    "inference.loglik['log_γ'] = 0.0\n",
    "inference.loglik['log_b'] = np.log(2.5)\n",
    "\n",
    "frames.set_value(obs['I'].reshape(-1,d,d))\n",
    "spikes.set_value(obs['data'])\n",
    "plt.plot(spikes.get_value())\n",
    "\n",
    "print(np.sum(obs['data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inference.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for v, b in inference.buffer.items():\n",
    "    print('{} = {}'.format(v, b.get_value()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "T, L = inference.sample(10)\n",
    "T = {k.name: t for k, t in T.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = T['xo']\n",
    "y = T['yo']\n",
    "\n",
    "plt.figure(figsize=(15, 4))\n",
    "plt.subplot(121)\n",
    "plt.plot(x[500:])\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.hist(x[500:], alpha=0.5, normed=True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 4))\n",
    "plt.subplot(121)\n",
    "plt.plot(x[500:], y[500:], '.k', alpha=0.1)\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(T['vec_f'][:,0], T['vec_f'][:,1], '.k', alpha=0.1)\n",
    "# plt.xlim((-.7, .7))\n",
    "# plt.ylim((-.7, .7))\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(T['width'], T['gain'], '.-k', alpha=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
