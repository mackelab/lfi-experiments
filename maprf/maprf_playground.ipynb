{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deep identity mapping\n",
    "\n",
    "learning receptive field parameters from inputs (white-noise videos) and outputs (spike trains) of linear-nonlinear neuron models with parameterized linear filters\n",
    "\n",
    "## simplistic setup: \n",
    "- model parameters $\\theta$ are the full spatiotemporal kernel (of size d*d, with d < 10), \n",
    "- summary statistic $x_0$ is spike-triggered average\n",
    "- for sufficiently long simulations, posterior mean is just data summary statistic $x_0$. \n",
    "- purely spatial kernel for now (kernel-size in temporal dimentions fixed to 1)  \n",
    "- *very* basic spiking non-linearity and noise model: threshold crossing, no spiking noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# notebook currently depends on code found only in feature_maprf-branch of lfi_models !\n",
    "\n",
    "import delfi.distribution as dd\n",
    "import delfi.generator as dg\n",
    "import delfi.inference as infer\n",
    "import delfi.utils.io as io\n",
    "import delfi.summarystats as ds\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import lfimodels.maprf.utils as utils\n",
    "\n",
    "from lfimodels.maprf.maprf import maprf\n",
    "from lfimodels.maprf.maprfStats import maprfStats\n",
    "from delfi.utils.viz import plot_pdf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "seed = 42\n",
    "\n",
    "d = 51 # edge length of (quadratic) receptive field\n",
    "parametrization = 'gaussian' # RF is Gaussian bump with specific mean and cov \n",
    "\n",
    "filter_shape = np.array((d,d,1))\n",
    "m = maprf(filter_shape=filter_shape, \n",
    "          parametrization=parametrization,\n",
    "          seed=seed, \n",
    "          duration=1000 )\n",
    "\n",
    "if parametrization=='gaussian':\n",
    "    p = dd.GaussianRF(ab=[-2,-0],\n",
    "                      dd=[-d//2,d//2,-d//2,d//2],\n",
    "                      ks = np.array([3,3]), cd = [-.9,0.9])\n",
    "elif parametrization=='full':\n",
    "    p = dd.Gaussian(m=np.zeros(d*d+1), P=1/100*np.eye(d*d+1))\n",
    "\n",
    "s = maprfStats(n_summary=m.n_params)\n",
    "g = dg.Default(model=m, prior=p, summary=s)\n",
    "\n",
    "true_params, labels_params = utils.obs_params(filter_shape,parametrization)\n",
    "true_params = np.array([-d, -d//4,-d//4,10,15,0.7])\n",
    "obs = m.gen_single(true_params)\n",
    "obs_stats = s.calc([obs])\n",
    "\n",
    "h_true = m.params_to_rf(true_params[1:])\n",
    "plt.figure(figsize=(16,7))\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(np.dot( obs['I'], h_true) + true_params[0])\n",
    "plt.title('neural activation function over observed data')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(h_true.reshape(d,d), interpolation='None')\n",
    "plt.title('ground-truth filter')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(obs_stats.T[1:].reshape(filter_shape[0],filter_shape[1]), \n",
    "          interpolation='None')\n",
    "plt.title('summary statistics')\n",
    "plt.show()\n",
    "\n",
    "# bunch of example prior draws\n",
    "plt.figure(figsize=(16,7))\n",
    "for i in range(10):\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.imshow(m.params_to_rf(p.gen()[0,1:]).reshape(d,d), interpolation='None')\n",
    "plt.subplot(2,5,3)\n",
    "plt.title('RF prior samples')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "obs['data'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "res = infer.SNPE(g, obs=obs_stats, n_hiddens=[20,20])\n",
    "\n",
    "out = res.run(10000, n_rounds=1, minibatch=50, epochs=1000)\n",
    "posterior = res.predict(obs_stats)\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(1,4,1)\n",
    "h_prior = m.params_to_rf(p.mean[1:])\n",
    "plt.imshow(h_prior.reshape(d,d), interpolation='None')\n",
    "plt.title('prior mean filter')\n",
    "plt.subplot(1,4,2)\n",
    "h_est =  m.params_to_rf(posterior.calc_mean_and_cov()[0][1:])\n",
    "plt.imshow(h_est.reshape(d,d), interpolation='None')\n",
    "plt.title('posterior mean filter')\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(h_true.reshape(d,d), \n",
    "          interpolation='None')\n",
    "plt.title('true spatial filter')\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(obs_stats.T[1:].reshape(filter_shape[0],filter_shape[1]), \n",
    "          interpolation='None')\n",
    "plt.title('x0')\n",
    "plt.show()\n",
    "\n",
    "#print('prior mean\\n', p.mean[1:].reshape(-1,1))\n",
    "#print('post mean\\n', posterior.calc_mean_and_cov()[0][1:].reshape(-1,1))\n",
    "#print('true pars\\n', true_params[1:].reshape(-1,1))\n",
    "#print('x0\\n', obs_stats.T[1:]) \n",
    "\n",
    "posterior = res.predict(obs_stats)\n",
    "plot_pdf(posterior.xs[0], lims=[-5,5], gt=true_params, figsize=(12,12));\n",
    "tmp=posterior.xs[0]\n",
    "tmp.eval(true_params.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# construction site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%matplotlib inline\n",
    "# notebook currently depends on code found only in feature_maprf-branch of lfi_models !\n",
    "\n",
    "import delfi.neuralnet as dn\n",
    "import delfi.distribution as dd\n",
    "import delfi.generator as dg\n",
    "import delfi.inference as infer\n",
    "import delfi.utils.io as io\n",
    "import delfi.summarystats as ds\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import lfimodels.maprf.utils as utils\n",
    "\n",
    "from lfimodels.maprf.maprf import maprf\n",
    "from lfimodels.maprf.maprfStats import maprfStats\n",
    "from delfi.utils.viz import plot_pdf\n",
    "\n",
    "import lasagne.layers as ll\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "seed = 42\n",
    "\n",
    "## simulation model\n",
    "\n",
    "d = 41                    # edge length of (quadratic) receptive field\n",
    "parametrization = 'gabor' # ['full', 'gaussian', 'gabor']\n",
    "filter_shape = np.array((d,d,2))\n",
    "m = maprf(filter_shape=filter_shape, \n",
    "          parametrization=parametrization,\n",
    "          seed=seed, \n",
    "          duration=500 )\n",
    "\n",
    "\n",
    "## prior over simulation parameters\n",
    "\n",
    "prior = collections.OrderedDict()\n",
    "prior['b0'] = {'mu' : np.array([0.]), 'sigma' : np.array([1]) }\n",
    "prior['vec_f']  = {'mu' : np.zeros(2), 'sigma' : 0.4 * np.ones(2) }\n",
    "prior['vec_A']  = {'mu' : np.zeros(2), 'sigma' : 1.0 * np.ones(2) }\n",
    "#prior = priors['kernel']['s']['width'] # fields 'a', 'b', 'f'\n",
    "#mu, sigma = normal_from_ci(*zip(prior['b'], prior['a']), prior['f'])\n",
    "prior['log_γ']  = {'mu' : np.array([-0.098]), 'sigma' : np.array([0.256])}\n",
    "prior['log_b']  = {'mu' : np.array([ 0.955]), 'sigma' : np.array([0.236])}\n",
    "#prior['xo'] = {'mu' : np.array([0.]), 'sigma' : np.array([5/np.sqrt(.5)])}\n",
    "#prior['yo'] = {'mu' : np.array([0.]), 'sigma' : np.array([5/np.sqrt(.5)])}\n",
    "ax_t = m._gen.axis_t\n",
    "Λ =  np.diag(ax_t / 0.075 * np.exp(1 - ax_t / 0.075))\n",
    "D = np.eye(ax_t.shape[0]) - np.eye(ax_t.shape[0], k=-1)\n",
    "F = np.dot(D, D.T)\n",
    "Σ = np.dot(Λ, np.linalg.inv(F).dot(Λ))\n",
    "prior['kt'] = {'mu': np.zeros_like(ax_t), 'sigma': np.linalg.inv(D).dot(Λ)}\n",
    "mu  = np.concatenate([prior[i][ 'mu'  ] for i in prior.keys()])\n",
    "L = np.diag(np.concatenate([prior[i]['sigma'] for i in list(prior.keys())[:-1]]))\n",
    "L = np.block([[L, np.zeros((L.shape[0], ax_t.size))], \n",
    "              [np.zeros((ax_t.size, L.shape[1])), prior['kt']['sigma']]])\n",
    "p = dd.Gaussian(m=mu, S=L.T.dot(L))\n",
    "\n",
    "## data summary staistics\n",
    "\n",
    "s = maprfStats(n_summary=d*d)\n",
    "\n",
    "g = dg.Default(model=m, prior=p, summary=s)\n",
    "\n",
    "## network \n",
    "\n",
    "n_inputs = [d,d]\n",
    "n_outputs = m.n_params\n",
    "n_components=1\n",
    "n_hiddens=[50]\n",
    "n_filters=[30,30]\n",
    "n_train_round = 1\n",
    "\n",
    "network = dn.NeuralNet.NeuralNet(n_inputs, \n",
    "                     n_outputs, \n",
    "                     n_components, \n",
    "                     n_filters=n_filters, \n",
    "                     n_hiddens=n_hiddens,\n",
    "                     seed=seed,\n",
    "                     svi=False)\n",
    "loss = -tt.mean(network.lprobs)\n",
    "\n",
    "\n",
    "test_fun = theano.function([network.stats], [ll.get_output(network.layer['conv_'+str(i)]) for i in range(1,len(n_filters)+1)])\n",
    "print('conv layer shapes:',  [test_fun(np.zeros((10,1,d,d)))[i].shape  for i in range(len(n_filters))])\n",
    "\n",
    "trn_inputs = [network.params, network.stats]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "minibatch = 50\n",
    "n_samples = 1000\n",
    "\n",
    "## training data and true parameters, data, statistics\n",
    "\n",
    "pars_true = np.array([-0.5,.7,.3,2.,1.,1.,2.5,1.,0.])\n",
    "obs = m.gen_single(pars_true)\n",
    "obs_stats = s.calc([obs])\n",
    "\n",
    "trn_data = g.gen(n_samples)\n",
    "trn_data = (trn_data[0], trn_data[1].reshape(-1,1,d,d))\n",
    "\n",
    "## training\n",
    "\n",
    "t = dn.Trainer.Trainer(network, loss,\n",
    "            trn_data=trn_data, trn_inputs=trn_inputs)\n",
    "logs=[]\n",
    "logs.append(t.train(epochs=epochs, minibatch=minibatch))\n",
    "\n",
    "posterior = network.get_mog(obs_stats.reshape(1,1,d,d))\n",
    "\n",
    "\n",
    "# bunch of example prior draws\n",
    "plt.figure(figsize=(16,10))\n",
    "for i in range(15):\n",
    "    plt.subplot(3,5,i+1)\n",
    "    plt.imshow(m.params_to_rf(p.gen().reshape(-1))[0], interpolation='None')\n",
    "plt.title('RF prior STAs')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(obs_stats.reshape(d,d), interpolation='None')\n",
    "plt.title('data STA')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(m.params_to_rf(pars_true)[0], interpolation='None')\n",
    "plt.title('ground-truth posterior RF')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(m.params_to_rf(posterior.xs[0].m)[0], interpolation='None')\n",
    "plt.title('posterior mean STA')\n",
    "plt.show()\n",
    "\n",
    "# bunch of example posterior draws\n",
    "plt.figure(figsize=(16,10))\n",
    "for i in range(15):\n",
    "    plt.subplot(3,5,i+1)\n",
    "    plt.imshow(m.params_to_rf(posterior.gen().reshape(-1))[0], interpolation='None')\n",
    "plt.title('RF posterior STAs')\n",
    "plt.show()\n",
    "\n",
    "plot_pdf(posterior, lims=[-5,5], gt=np.asarray(pars_true).reshape(-1), figsize=(12,12));\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
