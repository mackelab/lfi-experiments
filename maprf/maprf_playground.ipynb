{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SNPE & RF\n",
    "\n",
    "learning receptive field parameters from inputs (white-noise videos) and outputs (spike trains) of linear-nonlinear neuron models with parameterized linear filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%matplotlib inline\n",
    "# notebook currently depends on code found only in feature_maprf-branch of lfi_models !\n",
    "\n",
    "import delfi.neuralnet as dn\n",
    "import delfi.distribution as dd\n",
    "import delfi.generator as dg\n",
    "import delfi.inference as infer\n",
    "import delfi.utils.io as io\n",
    "import delfi.summarystats as ds\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import lfimodels.maprf.utils as utils\n",
    "\n",
    "from lfimodels.maprf.maprf import maprf\n",
    "from lfimodels.maprf.maprfStats import maprfStats\n",
    "from delfi.utils.viz import plot_pdf\n",
    "\n",
    "import lasagne.layers as ll\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "import collections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "seed = 42\n",
    "\n",
    "## simulation model\n",
    "\n",
    "d = 21 # edge length of (quadratic) receptive field\n",
    "parametrization = 'gabor' # ['full', 'gaussian', 'gabor']\n",
    "len_kt = 2\n",
    "\n",
    "params_ls = {'glm': ('bias',),\n",
    "             'kernel': {'s' : ('gain', 'phase', 'vec_f', 'ratio', 'width'),\n",
    "                        'l' : [],\n",
    "                        't' : []}}\n",
    "\n",
    "\n",
    "#params_ls = {'glm': ('bias',),\n",
    "#             'kernel': {'s' : ('vec_A', 'vec_f', 'ratio', 'width'),\n",
    "#                        'l' : [],\n",
    "#                        't' : ('value',)}}\n",
    "\n",
    "\n",
    "filter_shape = np.array((d,d,2))\n",
    "m = maprf(filter_shape=filter_shape, \n",
    "          parametrization=parametrization,\n",
    "          params_ls = params_ls,\n",
    "          seed=seed, \n",
    "          dt = 0.025, \n",
    "          duration= 20 )\n",
    "\n",
    "## prior over simulation parameters\n",
    "prior = collections.OrderedDict()\n",
    "if 'bias' in m.params_ls['glm']:\n",
    "    prior['λo'] = {'mu' : np.array([-0.57]), 'sigma' : np.array([np.sqrt(1.63)]) }\n",
    "if 'vec_A' in m.params_ls['kernel']['s']:\n",
    "    prior['vec_A']  = {'mu' : np.zeros(2), 'sigma' : 1.0 * np.ones(2) }\n",
    "if 'gain' in m.params_ls['kernel']['s']:\n",
    "    #prior['log_A'] = {'mu' : np.array([1.]), 'sigma' : np.array([1/np.sqrt(.5)])}  \n",
    "    prior['float_A'] = {'mu' : np.array([0]), 'sigma' : np.array([1.])}  \n",
    "if 'phase' in m.params_ls['kernel']['s']:\n",
    "    prior['logit_φ']  = {'mu' : np.array([0]), 'sigma' : np.array([1.78]) }    \n",
    "if 'vec_f' in m.params_ls['kernel']['s']:\n",
    "    prior['vec_f']  = {'mu' : np.zeros(2), 'sigma' : 1.0 * np.ones(2) }\n",
    "if 'ratio' in m.params_ls['kernel']['s']:\n",
    "    prior['log_γ']  = {'mu' : np.array([-0.098]), 'sigma' : np.array([0.256])}\n",
    "if 'width' in m.params_ls['kernel']['s']:\n",
    "    prior['log_b']  = {'mu' : np.array([ 0.955]), 'sigma' : np.array([0.236])}\n",
    "if 'xo' in m.params_ls['kernel']['l']:\n",
    "    prior['xo'] = {'mu' : np.array([0.]), 'sigma' : np.array([1/np.sqrt(.5)])}\n",
    "if 'yo' in m.params_ls['kernel']['l']:\n",
    "    prior['yo'] = {'mu' : np.array([0.]), 'sigma' : np.array([1/np.sqrt(.5)])}    \n",
    "L = np.diag(np.concatenate([prior[i]['sigma'] for i in list(prior.keys())]))\n",
    "if 'value' in m.params_ls['kernel']['t']:\n",
    "    ax_t = m.dt * np.arange(1,len_kt+1)\n",
    "    Λ =  np.diag(ax_t / 0.075 * np.exp(1 - ax_t / 0.075))\n",
    "    D = np.eye(ax_t.shape[0]) - np.eye(ax_t.shape[0], k=-1)\n",
    "    F = np.dot(D, D.T)\n",
    "    Σ = np.dot(Λ, np.linalg.inv(F).dot(Λ))\n",
    "    prior['kt'] = {'mu': np.zeros_like(ax_t), 'sigma': np.linalg.inv(D).dot(Λ)}\n",
    "    L = np.block([[L, np.zeros((L.shape[0], ax_t.size))], \n",
    "                  [np.zeros((ax_t.size, L.shape[1])), prior['kt']['sigma']]])\n",
    "mu  = np.concatenate([prior[i][ 'mu'  ] for i in prior.keys()])\n",
    "p = dd.Gaussian(m=mu, S=L.T.dot(L), seed=seed)\n",
    "\n",
    "#p_gauss = dd.Gaussian(m=mu, S=L.T.dot(L), seed=seed)\n",
    "#if 'bias' in m.params_ls['glm']:\n",
    "#    prior['λo'] = {'alpha' : np.array([1.]), 'beta' : np.array([1.]) }\n",
    "#p_gamma = dd.Gamma(alpha=prior['λo']['alpha'], beta=prior['λo']['beta'])\n",
    "#p = dd.StackedDistribution(ps=[p_gamma, p_gauss])\n",
    "\n",
    "## data summary staistics\n",
    "\n",
    "s = maprfStats(n_summary=d*d)\n",
    "\n",
    "g = dg.Default(model=m, prior=p, summary=s)\n",
    "\n",
    "## training data and true parameters, data, statistics\n",
    "\n",
    "params_dict_true = {'glm': {'binsize': m.dt,\n",
    "                            'bias': 1.54546216004078},\n",
    "                    'kernel': {'s': {'angle': 0.7,\n",
    "                                     'freq': 1.2,\n",
    "                                     'gain': 0.357703095858336,\n",
    "                                     'phase': np.pi/2,\n",
    "                                     'ratio': 1.,\n",
    "                                     'width': 2.5},\n",
    "                               'l': {'xo': 0.,\n",
    "                                     'yo': 0.},\n",
    "                               't': {'value': np.array([1., 0.])}}}\n",
    "#                               't': {'tau': 0.015}}}\n",
    "m.params_dict = params_dict_true\n",
    "pars_true = m.read_params_buffer()\n",
    "\n",
    "obs = m.gen_single()\n",
    "obs_stats = s.calc([obs])\n",
    "\n",
    "print('firing rate: ', np.sum(obs['data'])/m.duration)\n",
    "print('total spikes: ', np.sum(obs['data']))\n",
    "\n",
    "\n",
    "# bunch of example prior draws\n",
    "plt.figure(figsize=(16,10))\n",
    "for i in range(15):\n",
    "    plt.subplot(3,5,i+1)\n",
    "    plt.imshow(m.params_to_rf(p.gen().reshape(-1))[0], interpolation='None')\n",
    "plt.subplot(3,5,3)\n",
    "plt.title('RF prior draws')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(m.params_to_rf(p.mean)[0], interpolation='None')\n",
    "plt.title('prior mean RF')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(obs_stats.reshape(d,d), interpolation='None')\n",
    "plt.title('data STA')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(m.params_to_rf(pars_true)[0], interpolation='None')\n",
    "plt.title('ground-truth RF')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_hiddens=(50,50,50)\n",
    "n_filters=(32,32)\n",
    "\n",
    "n_train=5000\n",
    "epochs=100\n",
    "minibatch=50\n",
    "n_rounds=3\n",
    "n_components=2\n",
    "\n",
    "inf = infer.SNPE(generator=g, obs=obs_stats, prior_norm=False, pilot_samples=None, seed=seed, \n",
    "                 n_components=n_components, n_hiddens=n_hiddens, n_filters=n_filters, n_inputs = (1,d,d),\n",
    "                 convert_to_T=None)\n",
    "\n",
    "logs = inf.run(n_train=n_train, epochs=epochs, minibatch=minibatch, n_rounds=n_rounds, round_cl=1000,\n",
    "               kernel_loss='x_kl', lr_decay=0.99)\n",
    "\n",
    "posterior = inf.predict(obs_stats)\n",
    "\n",
    "#posterior_raw = inf.predict(obs_stats)\n",
    "#posterior = (posterior_raw * p) / p_CDELFI\n",
    "\n",
    "posterior.ndim = posterior.xs[0].ndim\n",
    "\n",
    "# bunch of example prior draws\n",
    "plt.figure(figsize=(16,10))\n",
    "for i in range(15):\n",
    "    plt.subplot(3,5,i+1)\n",
    "    plt.imshow(m.params_to_rf(p.gen().reshape(-1))[0], interpolation='None')\n",
    "plt.subplot(3,5,3)\n",
    "plt.title('RF prior draws')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16,5))\n",
    "plt.subplot(1,5,1)\n",
    "plt.imshow(m.params_to_rf(p.mean)[0], interpolation='None')\n",
    "plt.title('prior mean RF')\n",
    "plt.subplot(1,5,2)\n",
    "plt.imshow(obs_stats.reshape(d,d), interpolation='None')\n",
    "plt.title('data STA')\n",
    "plt.subplot(1,5,3)\n",
    "plt.imshow(m.params_to_rf(pars_true)[0], interpolation='None')\n",
    "plt.title('ground-truth RF')\n",
    "plt.subplot(1,5,4)\n",
    "plt.imshow(m.params_to_rf(posterior.calc_mean_and_cov()[0])[0], interpolation='None')\n",
    "plt.title('posterior mean RF')\n",
    "plt.subplot(1,5,5)\n",
    "a_max = np.argmax(posterior.a)\n",
    "plt.imshow(m.params_to_rf(posterior.xs[a_max].m)[0], interpolation='None')\n",
    "plt.title('posterior mode RF')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# bunch of example posterior draws\n",
    "plt.figure(figsize=(16,10))\n",
    "for i in range(15):\n",
    "    plt.subplot(3,5,i+1)\n",
    "    plt.imshow(m.params_to_rf(posterior.gen().reshape(-1))[0], interpolation='None')\n",
    "plt.subplot(3,5,3)\n",
    "plt.title('RF posterior draws')\n",
    "plt.show()\n",
    "\n",
    "# all pairwise marginals of fitted posterior\n",
    "fig, _ = plot_pdf(posterior, pdf2=p, lims=[-3,3], gt=pars_true.reshape(-1), figsize=(16,16), \n",
    "                  labels_params=['exp_b', 'vec_A1', 'vec_A2', 'vec_f1', 'vec_f2', 'log ratio', 'log width'])\n",
    "fig.savefig('res.pdf')\n",
    "\n",
    "# bunch of example prior draws\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(obs_stats.reshape(d,d), interpolation='None', cmap='gray')\n",
    "for i in range(100):\n",
    "    rfm = m.params_to_rf(posterior.gen().reshape(-1))[0]\n",
    "    plt.contour(rfm, levels=[-0.1, 0.1])\n",
    "    #print(rfm.min(), rfm.max())\n",
    "    plt.hold(True)\n",
    "plt.title('RF posterior draws')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, _ = plot_pdf(posterior, pdf2=p, lims=[-3,3], gt=pars_true.reshape(-1), figsize=(16,16), samples=samples.T, \n",
    "                  labels_params=['exp_b', 'vec_A1', 'vec_A2', 'vec_f1', 'vec_f2', 'log ratio', 'log width'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(logs[1][r][1].reshape(n_train,-1).var(axis=0))\n",
    "\n",
    "r = 1\n",
    "plt.semilogy(np.sort(1./logs[0][r]['cbkrnl'].A**2)[:100])\n",
    "plt.show()\n",
    "plt.semilogy(logs[1][r][1].reshape(n_train,-1).var(axis=0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_hiddens=(50,50,50)\n",
    "n_filters=(32,32)\n",
    "\n",
    "n_train=10000\n",
    "epochs=100\n",
    "minibatch=50\n",
    "n_rounds=2\n",
    "n_components=1\n",
    "\n",
    "#inf = infer.SNPE(generator=g, obs=obs_stats, prior_norm=True, pilot_samples=100, seed=seed, \n",
    "#                 convert_to_T=3,\n",
    "#                 n_components=n_components, n_hiddens=n_hiddens, n_filters=n_filters, n_inputs = (1,d,d))\n",
    "\n",
    "inf_CDELFI = infer.CDELFI(generator=g, obs=obs_stats, prior_norm=False, pilot_samples=None, seed=seed,\n",
    "                 n_components=n_components, n_hiddens=n_hiddens, n_filters=n_filters, n_inputs = (1,d,d))\n",
    "\n",
    "logs_CDELFI = inf_CDELFI.run(n_train=n_train, epochs=epochs, minibatch=minibatch, n_rounds=n_rounds)\n",
    "\n",
    "posterior_CDELFI = inf_CDELFI.predict(obs_stats)\n",
    "posterior_CDELFI.ndim = posterior_CDELFI.xs[0].ndim\n",
    "\n",
    "# bunch of example prior draws\n",
    "plt.figure(figsize=(16,10))\n",
    "for i in range(15):\n",
    "    plt.subplot(3,5,i+1)\n",
    "    plt.imshow(m.params_to_rf(p.gen().reshape(-1))[0], interpolation='None')\n",
    "plt.subplot(3,5,3)\n",
    "plt.title('RF prior draws')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16,5))\n",
    "plt.subplot(1,5,1)\n",
    "plt.imshow(m.params_to_rf(p.mean)[0], interpolation='None')\n",
    "plt.title('prior mean RF')\n",
    "plt.subplot(1,5,2)\n",
    "plt.imshow(obs_stats.reshape(d,d), interpolation='None')\n",
    "plt.title('data STA')\n",
    "plt.subplot(1,5,3)\n",
    "plt.imshow(m.params_to_rf(pars_true)[0], interpolation='None')\n",
    "plt.title('ground-truth RF')\n",
    "plt.subplot(1,5,4)\n",
    "plt.imshow(m.params_to_rf(posterior_CDELFI.calc_mean_and_cov()[0])[0], interpolation='None')\n",
    "plt.title('posterior mean RF')\n",
    "plt.subplot(1,5,5)\n",
    "a_max = np.argmax(posterior_CDELFI.a)\n",
    "plt.imshow(m.params_to_rf(posterior_CDELFI.xs[a_max].m)[0], interpolation='None')\n",
    "plt.title('posterior mode RF')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# bunch of example posterior draws\n",
    "plt.figure(figsize=(16,10))\n",
    "for i in range(15):\n",
    "    plt.subplot(3,5,i+1)\n",
    "    plt.imshow(m.params_to_rf(posterior_CDELFI.gen().reshape(-1))[0], interpolation='None')\n",
    "plt.subplot(3,5,3)\n",
    "plt.title('RF posterior draws')\n",
    "plt.show()\n",
    "\n",
    "# all pairwise marginals of fitted posterior\n",
    "fig, _ = plot_pdf(posterior_CDELFI, pdf2=p, lims=[-3,3], gt=pars_true.reshape(-1), figsize=(16,16), \n",
    "                  labels_params=['exp_b', 'vec_A1', 'vec_A2', 'vec_f1', 'vec_f2', 'log ratio', 'log width'])\n",
    "fig.savefig('res.pdf')\n",
    "\n",
    "# bunch of example prior draws\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(obs_stats.reshape(d,d), interpolation='None', cmap='gray')\n",
    "for i in range(100):\n",
    "    rfm = m.params_to_rf(posterior_CDELFI.gen().reshape(-1))[0]\n",
    "    plt.contour(rfm, levels=[-0.1, 0.1])\n",
    "    #print(rfm.min(), rfm.max())\n",
    "    plt.hold(True)\n",
    "plt.title('RF posterior draws')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from delfi.distribution.mixture.DefensiveDistribution import DefensiveDistribution as DefD\n",
    "# defensive sampling\n",
    "#a = 0.1\n",
    "#proposal = DefD(a=np.array([a,1.-a]),\n",
    "#        xs=[p, p_CDELFI])\n",
    "\n",
    "assert len(posterior_CDELFI.xs)==1\n",
    "p_CDELFI = logs_CDELFI[2][0].project_to_gaussian() #posterior_CDELFI.project_to_gaussian() #.convert_to_T(dofs=3)\n",
    "#p_CDELFI.S *= 2\n",
    "\n",
    "n_hiddens=(50,50,50)\n",
    "n_filters=(32,32)\n",
    "\n",
    "n_train=20000\n",
    "epochs=100\n",
    "minibatch=200\n",
    "n_rounds=3\n",
    "n_components=2\n",
    "\n",
    "\n",
    "gSNPE = dg.Default(model=m, prior=p, summary=s)\n",
    "\n",
    "inf = infer.SNPE(generator=gSNPE, obs=obs_stats, prior_norm=False, pilot_samples=None, seed=seed, \n",
    "                 n_components=n_components, n_hiddens=n_hiddens, n_filters=n_filters, n_inputs = (1,d,d),\n",
    "                 convert_to_T=3)\n",
    "#inf.generator.proposal = proposal #.convert_to_T(dofs=10)\n",
    "logs = inf.run(n_train=n_train, epochs=epochs, minibatch=minibatch, n_rounds=n_rounds, round_cl=1000,\n",
    "                 lr_decay=0.99)\n",
    "\n",
    "posterior = inf.predict(obs_stats)\n",
    "\n",
    "#posterior_raw = inf.predict(obs_stats)\n",
    "#posterior = (posterior_raw * p) / p_CDELFI\n",
    "\n",
    "posterior.ndim = posterior.xs[0].ndim\n",
    "\n",
    "# bunch of example prior draws\n",
    "plt.figure(figsize=(16,10))\n",
    "for i in range(15):\n",
    "    plt.subplot(3,5,i+1)\n",
    "    plt.imshow(m.params_to_rf(p.gen().reshape(-1))[0], interpolation='None')\n",
    "plt.subplot(3,5,3)\n",
    "plt.title('RF prior draws')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16,5))\n",
    "plt.subplot(1,5,1)\n",
    "plt.imshow(m.params_to_rf(p.mean)[0], interpolation='None')\n",
    "plt.title('prior mean RF')\n",
    "plt.subplot(1,5,2)\n",
    "plt.imshow(obs_stats.reshape(d,d), interpolation='None')\n",
    "plt.title('data STA')\n",
    "plt.subplot(1,5,3)\n",
    "plt.imshow(m.params_to_rf(pars_true)[0], interpolation='None')\n",
    "plt.title('ground-truth RF')\n",
    "plt.subplot(1,5,4)\n",
    "plt.imshow(m.params_to_rf(posterior.calc_mean_and_cov()[0])[0], interpolation='None')\n",
    "plt.title('posterior mean RF')\n",
    "plt.subplot(1,5,5)\n",
    "a_max = np.argmax(posterior.a)\n",
    "plt.imshow(m.params_to_rf(posterior.xs[a_max].m)[0], interpolation='None')\n",
    "plt.title('posterior mode RF')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# bunch of example posterior draws\n",
    "plt.figure(figsize=(16,10))\n",
    "for i in range(15):\n",
    "    plt.subplot(3,5,i+1)\n",
    "    plt.imshow(m.params_to_rf(posterior.gen().reshape(-1))[0], interpolation='None')\n",
    "plt.subplot(3,5,3)\n",
    "plt.title('RF posterior draws')\n",
    "plt.show()\n",
    "\n",
    "# all pairwise marginals of fitted posterior\n",
    "fig, _ = plot_pdf(posterior, pdf2=p, lims=[-3,3], gt=pars_true.reshape(-1), figsize=(16,16), \n",
    "                  labels_params=['exp_b', 'vec_A1', 'vec_A2', 'vec_f1', 'vec_f2', 'log ratio', 'log width'])\n",
    "fig.savefig('res.pdf')\n",
    "\n",
    "# bunch of example prior draws\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(obs_stats.reshape(d,d), interpolation='None', cmap='gray')\n",
    "for i in range(100):\n",
    "    rfm = m.params_to_rf(posterior.gen().reshape(-1))[0]\n",
    "    plt.contour(rfm, levels=[-0.1, 0.1])\n",
    "    #print(rfm.min(), rfm.max())\n",
    "    plt.hold(True)\n",
    "plt.title('RF posterior draws')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of samples \n",
    "print(logs[1][-1][2].shape, n_train)\n",
    "\n",
    "# effective sample size\n",
    "\n",
    "print([ np.sum(logs[1][r][2]/n_train)**2 / np.sum((logs[1][r][2]/n_train)**2) for r in range(n_rounds)])\n",
    "\n",
    "# smallest 99% together have x% of total weight mass\n",
    "plt.semilogy((np.cumsum(np.sort(logs[1][-1][2]))/np.sum(logs[1][-1][2]))[np.int(0.99*n_train):])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network_pars_backup = inf.network.params_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp=inf.generator.proposal.gen(10000)\n",
    "\n",
    "tmp = inf.generator.prior.eval(tmp, log=False)/inf.generator.proposal.eval(tmp, log=False)\n",
    "\n",
    "tmp.sum()**2/np.sum(tmp**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_train=500000\n",
    "epochs=50\n",
    "minibatch=250\n",
    "n_rounds=2\n",
    "\n",
    "inf.round = 0\n",
    "\n",
    "g = dg.Default(model=m, prior=p, summary=s)\n",
    "\n",
    "\n",
    "inf2 = infer.SNPE(generator=g, obs=obs_stats, prior_norm=False, pilot_samples=None, seed=seed, \n",
    "                 n_components=n_components, n_hiddens=n_hiddens, n_filters=n_filters, n_inputs = (1,d,d),\n",
    "                 convert_to_T=3)\n",
    "inf2.generator.proposal = posterior.convert_to_T(dofs=3)\n",
    "\n",
    "log2s = inf2.run(n_train=n_train, epochs=epochs, minibatch=minibatch, n_rounds=n_rounds, round_cl=1000,\n",
    "                 lr_decay=0.99)\n",
    "\n",
    "posterior2 = inf2.predict(obs_stats)\n",
    "\n",
    "#posterior2 = (posterior2 * p) / p_CDELFI\n",
    "\n",
    "posterior2.ndim = posterior2.xs[0].ndim\n",
    "\n",
    "fig, _ = plot_pdf(posterior2, pdf2=posterior, lims=[-3,3], gt=pars_true.reshape(-1), figsize=(16,16), \n",
    "                  labels_params=['exp_b', 'vec_A1', 'vec_A2', 'vec_f1', 'vec_f2', 'log ratio', 'log width'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare with maprf sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "import maprf.config as config\n",
    "import maprf.rfs.v1 as V1\n",
    "import maprf.invlink as invlink\n",
    "import maprf.glm as glm \n",
    "from maprf.utils import *\n",
    "from maprf.data import SymbolicData\n",
    "import time\n",
    "import maprf.filters as filters\n",
    "import maprf.kernels as kernels\n",
    "# from maprf.sampling.slice import EllipticalSliceSampler as ESS\n",
    "\n",
    "import theano.printing as printing\n",
    "import theano.tensor as tt\n",
    "\n",
    "import theano\n",
    "from theano import In\n",
    "\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from os import path\n",
    "from maprf.inference import *\n",
    "\n",
    "def pyprint(var, filename):\n",
    "    printing.pydotprint(var, format='pdf', outfile=filename, high_contrast=False, with_ids=True)\n",
    "\n",
    "cfg = config.load(path.join('config.yaml'))\n",
    "\n",
    "# The forward part of the model\n",
    "rf = V1.SimpleLinear_full_kt()\n",
    "emt = glm.Poisson()\n",
    "# inputs and outputs\n",
    "data = [theano.shared(empty(3), 'frames'),\n",
    "        theano.shared(empty(1, dtype='int64'))]\n",
    "frames, spikes = data\n",
    "\n",
    "# fill the grids\n",
    "rf.grids['s'][0].set_value(m._gen.grid_x)\n",
    "rf.grids['s'][1].set_value(m._gen.grid_y)\n",
    "rf.grids['t'][0].set_value(m._gen.axis_t)\n",
    "\n",
    "# inference model\n",
    "inference = Inference(rf, emt)\n",
    "inference.priors = {\n",
    "    'glm': {         'bias':  {'name':  'gamma',\n",
    "                               'varname': 'λo',\n",
    "                               'alpha': 1.0, #prior['λo']['alpha'][0],\n",
    "                               'beta':  1.0}}, #prior['λo']['beta'][0]}},\n",
    "    'kernel': {'s': {'freq':  {'name': 'Rayleigh',\n",
    "                               'varname': 'vec_f',\n",
    "                               'sigma': prior['vec_f']['sigma'][0]},            \n",
    "                     'ratio':  {'name': 'normal',\n",
    "                                'varname': 'log_γ',\n",
    "                                'sigma': prior['log_γ']['sigma'][0],\n",
    "                                'mu':    prior['log_γ']['mu'][0]}, \n",
    "                     'width':  {'name': 'normal',\n",
    "                                'varname': 'log_b',\n",
    "                                'sigma': prior['log_b']['sigma'][0],\n",
    "                                'mu':    prior['log_b']['mu'][0]}}}}        \n",
    "if 'vec_A' in prior.keys():\n",
    "    inference.priors['kernel']['s']['phase'] =   {'name': 'Rayleigh',\n",
    "                                                  'varname': 'vec_A',\n",
    "                                                  'sigma': prior['vec_A']['sigma'][0]}            \n",
    "elif 'log_A' in prior.keys() and 'logit_φ' in prior.keys():\n",
    "    inference.priors['kernel']['s']['gain'] =  {'name': 'lognormal',\n",
    "                                                  'varname': 'log_A',\n",
    "                                                  'mu': prior['log_A']['mu'][0],\n",
    "                                                  'sigma': prior['log_A']['sigma'][0]}            \n",
    "    inference.priors['kernel']['s']['phase'] =  {'name': 'logitnormal',\n",
    "                                                  'varname': 'logit_φ',\n",
    "                                                  'mu': prior['logit_φ']['mu'][0],\n",
    "                                                  'sigma': prior['logit_φ']['sigma'][0]}            \n",
    "elif 'float_A' in prior.keys() and 'logit_φ' in prior.keys():\n",
    "    inference.priors['kernel']['s']['gain'] =  {'name': 'normal',\n",
    "                                                  'varname': 'float_A',\n",
    "                                                  'mu': prior['float_A']['mu'][0],\n",
    "                                                  'sigma': prior['float_A']['sigma'][0]}            \n",
    "    inference.priors['kernel']['s']['phase'] =  {'name': 'logitnormal',\n",
    "                                                  'varname': 'logit_φ',\n",
    "                                                  'mu': prior['logit_φ']['mu'][0],\n",
    "                                                  'sigma': prior['logit_φ']['sigma'][0]}      \n",
    "else:\n",
    "    raise NotImplemented()\n",
    "\n",
    "\n",
    "if 'kt' in prior.keys():\n",
    "    inference.priors['kernel']['t'] = prior['kt']\n",
    "\n",
    "\n",
    "inference.add_sampler(GaborSampler(fix_position=True, parametrization='logit_φ'))\n",
    "print(inference.samplers[0].params)\n",
    "\n",
    "#inference.add_sampler(KernelSampler())\n",
    "kt = tt.vector('kt')\n",
    "inference.rf.filter.kernel['t'] = kt / tt.sqrt(tt.dot(kt, kt))\n",
    "#inference.add_update(kt, kt)\n",
    "inference.add_inputs(kt)\n",
    "\n",
    "print('inputs: ', inference.inputs)\n",
    "print('priors: ', inference.priors)\n",
    "\n",
    "inference.build(data)\n",
    "inference.compile()\n",
    "\n",
    "\n",
    "inference.loglik['xo'] = 0.\n",
    "inference.loglik['yo'] = 0.\n",
    "#inference.loglik['logit_φ'] = 0.0  # np.array([2.0, 0.0])\n",
    "ks = params_dict_true['kernel']['s']\n",
    "vec_f = m.pol2cart(np.atleast_2d([ks['freq'], ks['angle']])).reshape(-1)\n",
    "log_γ = np.log(ks['ratio'])\n",
    "log_b = np.log(ks['width'])\n",
    "inference.loglik['vec_f'] = vec_f  # np.zeros(2)  # 0.3 * np.array([np.cos(0.7), np.sin(0.7)])\n",
    "inference.loglik['log_γ'] = log_γ  # 0.\n",
    "inference.loglik['log_b'] = log_b # np.log(2.5)\n",
    "inference.loglik['kt'] =    params_dict_true['kernel']['t']['value'].copy()  # np.array([0.5, 0.0])\n",
    "\n",
    "if 'vec_A' in prior.keys():\n",
    "    vec_A = m.pol2cart(np.atleast_2d([ks['gain'], ks['phase']])).reshape(-1)\n",
    "    inference.loglik['vec_A'] = vec_A  # np.zeros(2)  # 0.3 * np.array([np.cos(0.7), np.sin(0.7)])\n",
    "elif 'log_A' in prior.keys() and 'logit_φ' in prior.keys():\n",
    "    log_A, logit_φ = ks['gain'], ks['phase']\n",
    "    inference.loglik['log_A'] = log_A  # np.zeros(2)  # 0.3 * np.array([np.cos(0.7), np.sin(0.7)])\n",
    "    inference.loglik['logit_φ'] = logit_φ  # np.zeros(2)  # 0.3 * np.array([np.cos(0.7), np.sin(0.7)])\n",
    "elif 'float_A' in prior.keys() and 'logit_φ' in prior.keys():\n",
    "    float_A, logit_φ = ks['gain'], ks['phase']\n",
    "    inference.loglik['float_A'] = float_A  # np.zeros(2)  # 0.3 * np.array([np.cos(0.7), np.sin(0.7)])\n",
    "    inference.loglik['logit_φ'] = logit_φ  # np.zeros(2)  # 0.3 * np.array([np.cos(0.7), np.sin(0.7)])\n",
    "\n",
    "\n",
    "\n",
    "frames.set_value(obs['I'][:,:].reshape(-1,d,d))\n",
    "spikes.set_value(obs['data'][:])\n",
    "\n",
    "#frames.set_value(0*obs['I'][:1,:].reshape(-1,d,d))\n",
    "#spikes.set_value(0*obs['data'][:1])\n",
    "\n",
    "\n",
    "#frames.set_value(np.zeros((1,d,d)))\n",
    "#spikes.set_value(np.zeros(1,dtype=np.int))\n",
    "\n",
    "plt.plot(spikes.get_value())\n",
    "\n",
    "print(np.sum(obs['data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import datetime\n",
    "\n",
    "T, L = inference.sample(100000)\n",
    "T = {k.name: t for k, t in T.items()}\n",
    "\n",
    "x = T['xo']\n",
    "y = T['yo']\n",
    "\n",
    "plt.figure(figsize=(15, 4))\n",
    "plt.subplot(121)\n",
    "plt.plot(x[500:])\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.hist(x[500:], alpha=0.5, normed=True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15, 4))\n",
    "plt.subplot(121)\n",
    "plt.plot(x[500:], y[500:], '.k', alpha=0.1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inference.sample_biases(data, T, cfg['sim']['dt'])\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(T['bias'])\n",
    "print('mean: ' + str(T['bias'].mean()) + ', var: ' + str(T['bias'].var()))\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(T['λo'])\n",
    "print('mean: ' + str(T['λo'].mean()) + ', var: ' + str(T['λo'].var()))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for t in np.sort(np.random.choice(T['vec_f'].shape[0], 100, replace=False)):\n",
    "    params_dict = {'kernel' : {'s' : {}}, 'glm': {}}\n",
    "    params_dict['glm']['bias'] = T['bias'][t]\n",
    "    params_dict['kernel']['s']['phase'] = T['phase'][t]\n",
    "    params_dict['kernel']['s']['angle'] = T['angle'][t] \n",
    "    params_dict['kernel']['s']['freq']  = T['freq'][t]\n",
    "    params_dict['kernel']['s']['ratio'] = T['ratio'][t]\n",
    "    params_dict['kernel']['s']['width'] = T['width'][t]\n",
    "    params_dict['kernel']['s']['gain'] = T['gain'][t]\n",
    "\n",
    "    ks = m._eval_ks(bias=-0.5, \n",
    "                             angle=params_dict['kernel']['s']['angle'],\n",
    "                             freq=params_dict['kernel']['s']['freq'],\n",
    "                             gain=params_dict['kernel']['s']['gain'],\n",
    "                             phase=params_dict['kernel']['s']['phase'],\n",
    "                             ratio=params_dict['kernel']['s']['ratio'],\n",
    "                             width=params_dict['kernel']['s']['width'])\n",
    "\n",
    "    plt.imshow(ks.reshape(d,d), interpolation='None')\n",
    "    plt.title('t =' + str(t))\n",
    "    plt.show()\n",
    "\n",
    "    print('loc:' , [T['xo'][t], T['yo'][t]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=T['ratio'][50:]\n",
    "plt.hist(x, bins=np.linspace(x.min(), x.max(), 20), alpha=0.5, normed=True)\n",
    "plt.title('ratio')\n",
    "plt.show()\n",
    "print('mean:', T['ratio'].mean())\n",
    "print('var:', T['ratio'].var())\n",
    "\n",
    "x=T['log_γ'][50:]\n",
    "plt.hist(x, bins=np.linspace(x.min(), x.max(), 20), alpha=0.5, normed=True)\n",
    "plt.title('log ratio')\n",
    "plt.show()\n",
    "print('mean:', T['log_γ'].mean())\n",
    "print('var:', T['log_γ'].var())\n",
    "\n",
    "x=T['width'][50:]\n",
    "plt.hist(x, bins=np.linspace(x.min(), x.max(), 20), alpha=0.5, normed=True)\n",
    "plt.title('width')\n",
    "plt.show()\n",
    "print('mean:', T['width'].mean())\n",
    "print('var:', T['width'].var())\n",
    "\n",
    "x=T['log_b'][50:]\n",
    "plt.hist(x, bins=np.linspace(x.min(), x.max(), 20), alpha=0.5, normed=True)\n",
    "plt.title('log width')\n",
    "plt.show()\n",
    "print('mean:', T['log_b'].mean())\n",
    "print('var:', T['log_b'].var())\n",
    "\n",
    "\n",
    "x=T['angle'][50:]\n",
    "plt.hist(x, bins=np.linspace(x.min(), x.max(), 20), alpha=0.5, normed=True)\n",
    "plt.title('angle')\n",
    "plt.show()\n",
    "print('mean:', T['angle'].mean())\n",
    "print('var:', T['angle'].var())\n",
    "\n",
    "x=T['freq'][50:]\n",
    "plt.hist(x, bins=np.linspace(x.min(), x.max(), 20), alpha=0.5, normed=True)\n",
    "plt.title('freq')\n",
    "plt.show()\n",
    "print('mean:', T['freq'].mean())\n",
    "print('var:', T['freq'].var())\n",
    "\n",
    "x=T['vec_f'][50:,0]\n",
    "plt.hist(x, bins=np.linspace(x.min(), x.max(), 20), alpha=0.5, normed=True)\n",
    "plt.title('vec_f[0]')\n",
    "plt.show()\n",
    "print('mean:', T['vec_f'][:,0].mean())\n",
    "print('var:',  T['vec_f'][:,0].var())\n",
    "\n",
    "x=T['vec_f'][50:,1]\n",
    "plt.hist(x, bins=np.linspace(x.min(), x.max(), 20), alpha=0.5, normed=True)\n",
    "plt.title('vec_f[1]')\n",
    "plt.show()\n",
    "print('mean:', T['vec_f'][:,1].mean())\n",
    "print('var:',  T['vec_f'][:,1].var())\n",
    "\n",
    "\n",
    "x=T['phase'][50:]\n",
    "plt.hist(x, bins=np.linspace(x.min(), x.max(), 20), alpha=0.5, normed=True)\n",
    "plt.title('phase')\n",
    "plt.show()\n",
    "print('mean:', T['phase'].mean())\n",
    "print('var:', T['phase'].var())\n",
    "\n",
    "if 'logit_φ' in T.keys():\n",
    "    x=T['logit_φ'][50:]\n",
    "    plt.hist(x, bins=np.linspace(x.min(), x.max(), 20), alpha=0.5, normed=True)\n",
    "    plt.title('logit phase')\n",
    "    plt.show()\n",
    "    print('mean:', T['logit_φ'].mean())\n",
    "    print('var:', T['logit_φ'].var())\n",
    "\n",
    "if 'log_A' in T.keys():\n",
    "    x=T['log_A'][50:]\n",
    "    plt.hist(x, bins=np.linspace(x.min(), x.max(), 20), alpha=0.5, normed=True)\n",
    "    plt.title('log_A')\n",
    "    plt.show()\n",
    "    print('mean:', T['log_A'][:].mean())\n",
    "    print('var:',  T['log_A'][:].var())\n",
    "\n",
    "if 'vec_A' in T.keys():\n",
    "    x=T['vec_A'][50:,0]\n",
    "    plt.hist(x, bins=np.linspace(x.min(), x.max(), 20), alpha=0.5, normed=True)\n",
    "    plt.title('vec_A[0]')\n",
    "    plt.show()\n",
    "    print('mean:', T['vec_A'][:,0].mean())\n",
    "    print('var:',  T['vec_A'][:,0].var())    \n",
    "    x=T['vec_A'][50:,1]\n",
    "    plt.hist(x, bins=np.linspace(x.min(), x.max(), 20), alpha=0.5, normed=True)\n",
    "    plt.title('vec_A[1]')\n",
    "    plt.show()\n",
    "    print('mean:', T['vec_A'][:,1].mean())\n",
    "    print('var:',  T['vec_A'][:,1].var())\n",
    "    \n",
    "if 'bias' in T.keys():\n",
    "    x=T['bias'][50:]\n",
    "    plt.hist(x, bins=np.linspace(x.min(), x.max(), 20), alpha=0.5, normed=True)\n",
    "    plt.title('bias')\n",
    "    plt.show()\n",
    "    print('mean:', T['bias'].mean())\n",
    "    print('var:', T['bias'].var())\n",
    "\n",
    "if 'λo' in T.keys():\n",
    "    x=T['λo'][50:]\n",
    "    plt.hist(x, bins=np.linspace(x.min(), x.max(), 20), alpha=0.5, normed=True)\n",
    "    plt.title('exp bias')\n",
    "    plt.show()\n",
    "    print('mean:', T['λo'].mean())\n",
    "    print('var:', T['λo'].var())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try: \n",
    "    np.savez('posterior_samples', {'T' : T})\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T = np.load('posterior_samples.npz')['arr_0'].tolist()['T']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#T['b'] = np.zeros((T['vec_f'].shape[0], 1))\n",
    "if 'vec_A' in prior.keys(): \n",
    "    samples = np.hstack([np.atleast_2d(T[key].T).T for key in ['bias','vec_A','vec_f','log_γ','log_b']])\n",
    "elif 'log_A' in prior.keys() and 'logit_φ' in prior.keys(): \n",
    "    samples = np.hstack([np.atleast_2d(T[key].T).T for key in ['bias','log_A', 'logit_φ', 'vec_f','log_γ','log_b']])\n",
    "elif 'float_A' in prior.keys() and 'logit_φ' in prior.keys(): \n",
    "    samples = np.hstack([np.atleast_2d(T[key].T).T for key in ['bias','float_A', 'logit_φ', 'vec_f','log_γ','log_b']])\n",
    "\n",
    "\n",
    "S=np.cov(samples.T)\n",
    "posterior_sampled = dd.Gaussian(m=samples.mean(axis=0), S=S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# results gallery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# student-t proposals (seed #1)\n",
    "plot_pdf((logs[2][1]*p)/p_CDELFI, pdf2=(logs[2][0]*p)/p_CDELFI, lims=[-5,5], figsize=(16,16), samples=samples.T);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# all pairwise marginals of fitted posterior\n",
    "plot_pdf(posterior, pdf2=posterior_CDELFI, lims=[-5,5], figsize=(16,16), samples=samples.T);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import delfi.distribution as dd\n",
    "from delfi.neuralnet.NeuralNet import NeuralNet\n",
    "\n",
    "def save_mog(mog, filename=None):\n",
    "    \"\"\"Save mixture of Gaussians (avoiding pickle)\n",
    "    \n",
    "    Saves the key arrays of a Mixture of Gaussians. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    mog : (Mixture of) Gaussian object\n",
    "        mixture \n",
    "    filename : string\n",
    "        desired save file location. If None, does not\n",
    "        save and returns dictionary with arrays instead.\n",
    "    \n",
    "    \"\"\"        \n",
    "    assert isinstance(posterior, (dd.MoG, dd.Gaussian))\n",
    "    \n",
    "    if isinstance(mog, dd.MoG):\n",
    "        \n",
    "        save_dict = {'a'  : mog.a,\n",
    "                     'ms' : [x.m for x in mog.xs],\n",
    "                     'Ss' : [x.S for x in mog.xs],\n",
    "                     'seed' : mog.seed}\n",
    "        \n",
    "    elif isinstance(mog, dd.Gaussian):\n",
    "        \n",
    "        save_dict = {'a'  : np.ones(1),\n",
    "                     'ms' : [mog.m], \n",
    "                     'Ss' : [mog.S],\n",
    "                     'seed' : mog.seed}\n",
    "        \n",
    "            \n",
    "    if not filename is None: \n",
    "        np.save(filename, save_dict)\n",
    "    else:\n",
    "        return save_dict\n",
    "    \n",
    "def load_mog(filename):\n",
    "    \"\"\"Load mixture of Gaussians (avoiding pickle)\n",
    "    \n",
    "    Loads key arrays of a Mixture of Gaussians and returns the \n",
    "    corresponding object. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : string\n",
    "        save file location (with or without file extension)\n",
    "    \n",
    "    \"\"\"\n",
    "    if not filename[-4:]=='.npy':\n",
    "        filename += '.npy'\n",
    "    \n",
    "    sd = np.load(filename)[()]\n",
    "    \n",
    "    mog = dd.MoG(a=sd['a'], ms=sd['ms'], Ss=sd['Ss'], seed=sd['seed'])\n",
    "    \n",
    "    return mog\n",
    "\n",
    "def save_res(p, posterior, network, filename, proposal=None):\n",
    "\n",
    "    prior = save_mog(p)\n",
    "    posterior = save_mog(posterior)\n",
    "    \n",
    "    net_pars = network.params_dict\n",
    "    net_spec = network.spec_dict\n",
    "    \n",
    "    if proposal is None:\n",
    "        np.savez(filename, \n",
    "                 p=prior,\n",
    "                 posterior=posterior,\n",
    "                 net_pars=net_pars,\n",
    "                 net_spec=net_spec)\n",
    "    else:\n",
    "        proposal=save_mog(proposal)\n",
    "        np.savez(filename, \n",
    "                 p=prior,\n",
    "                 proposal=proposal,\n",
    "                 posterior=posterior,\n",
    "                 net_pars=net_pars,\n",
    "                 net_spec=net_spec)\n",
    "        \n",
    "    \n",
    "def load_res(filename):\n",
    "    \n",
    "    load_file = np.load(filename)\n",
    "\n",
    "    ld = load_file['p'][()]\n",
    "    p = dd.MoG(a=ld['a'], ms=ld['ms'], Ss=ld['Ss'], seed=ld['seed'])\n",
    "    \n",
    "    if 'proposal' in load_file.keys():\n",
    "        ld = load_file['proposal'][()]\n",
    "        proposal = dd.MoG(a=ld['a'], ms=ld['ms'], Ss=ld['Ss'], seed=ld['seed'])\n",
    "    else:\n",
    "        proposal = None\n",
    "\n",
    "    ld = load_file['posterior'][()]\n",
    "    posterior = dd.MoG(a=ld['a'], ms=ld['ms'], Ss=ld['Ss'], seed=ld['seed'])\n",
    "    \n",
    "    ns = load_file['net_spec'][()]\n",
    "    network = NeuralNet(n_inputs=ns['n_inputs'],\n",
    "                            n_outputs=ns['n_outputs'],\n",
    "                            n_components=ns['n_components'],\n",
    "                            n_filters=ns['n_filters'],\n",
    "                            n_hiddens=ns['n_hiddens'],\n",
    "                            n_rnn=ns['n_rnn'],\n",
    "                            seed=ns['seed'],\n",
    "                            svi=ns['svi'])\n",
    "    network.params_dict = load_file['net_pars'][()]\n",
    "    \n",
    "    return p, posterior, network, proposal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_res(p, posterior, inf.network, filename='maprf_2modes_proofOfConcept_fit', proposal=p_CDELFI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_, posterior_, network_, proposal_ = load_res('maprf_2modes_proofOfConcept_fit.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inf3 = infer.SNPE(generator=gSNPE, obs=obs_stats, prior_norm=False, pilot_samples=None, seed=seed, \n",
    "                 n_components=n_components, n_hiddens=n_hiddens, n_filters=n_filters, n_inputs = (1,d,d),\n",
    "                 convert_to_T=3)\n",
    "inf3.network = network_\n",
    "inf3.predict(obs_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
