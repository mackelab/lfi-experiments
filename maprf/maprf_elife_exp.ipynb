{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SNPE & RF\n",
    "\n",
    "learning receptive field parameters from inputs (white-noise videos) and outputs (spike trains) of linear-nonlinear neuron models with parameterized linear filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import delfi.distribution as dd\n",
    "import delfi.generator as dg\n",
    "import delfi.inference as infer\n",
    "import delfi.utils.io as io\n",
    "from delfi.utils.viz import plot_pdf\n",
    "\n",
    "from lfimodels.maprf.utils import get_maprf_prior_01, setup_sim, setup_sampler, get_data_o, quick_plot, contour_draws\n",
    "\n",
    "from lfimodels.maprf.maprf import maprf as model\n",
    "from lfimodels.maprf.maprfStats import maprfStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "duration = 20\n",
    "\n",
    "idx_cell = 3 # load toy cell number i "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## training data and true parameters, data, statistics\n",
    "\n",
    "sim_info = np.load('./results/sim_info.npy')[()]\n",
    "d, params_ls = sim_info['d'], sim_info['params_ls']\n",
    "\n",
    "m = model(filter_shape= np.array((d,d,2)),\n",
    "          parametrization=sim_info['parametrization'],\n",
    "          params_ls=params_ls,\n",
    "          seed=seed,\n",
    "          dt=sim_info['dt'],\n",
    "          duration=duration)\n",
    "\n",
    "p, prior = get_maprf_prior_01(params_ls, seed)\n",
    "\n",
    "s = maprfStats(n_summary=d*d+1) # summary stats (d x d RF + spike_count)\n",
    "\n",
    "\n",
    "def rej(x):\n",
    "    # rejects summary statistic if number of spikes == 0\n",
    "    return x[:,-1] > 0\n",
    "\n",
    "# generator object that auto-rejects some data-pairs (theta_i, x_i) right at sampling\n",
    "g = dg.RejKernel(model=m, prior=p, summary=s, rej=rej, seed=seed)\n",
    "\n",
    "# load cell, generate xo\n",
    "filename = './results/toy_cells/toy_cell_' + str(idx_cell) + '.npy'\n",
    "params_dict_true = np.load(filename)[()]\n",
    "m.rng = np.random.RandomState(seed=seed)\n",
    "m.params_dict = params_dict_true.copy()\n",
    "pars_true = m.read_params_buffer()\n",
    "obs_stats = s.calc([m.gen_single()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour_draws(g.prior, g, obs_stats, d=d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNPE-A version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network architecture: 8 layer network [4x conv, 3x fully conn., 1x MoG], 20k parameters in total \n",
    "\n",
    "filter_sizes=[3,3,3,2]   # 4 conv ReLU layers\n",
    "n_filters=(16,16,32,32)  # 16 to 32 filters\n",
    "pool_sizes=[1,2,2,1]     # \n",
    "n_hiddens=[50,50,50]     # 3 fully connected layers\n",
    "\n",
    "# N = 50k per round\n",
    "\n",
    "n_train=50000\n",
    "\n",
    "# single component (posterior at most STAs is well-approximated by single Gaussian - we also want to run more SNPE-A)\n",
    "\n",
    "n_components=1\n",
    "\n",
    "# single rounds (first round is always'amortized' and can be used with any other STA covered by the prior)\n",
    "\n",
    "n_rounds=1\n",
    "\n",
    "# new feature for CNN architectures: passing a value directly to the hidden layers (bypassing the conv layers).\n",
    "# In this case, we pass the number of spikes (single number) directly, which allows to normalize the STAs \n",
    "# and hence help out the conv layers. Without that extra input, we couldn't recover the RF gain anymore. \n",
    "n_inputs_hidden = 1\n",
    "\n",
    "# some learning-schedule parameters\n",
    "lr_decay = 0.99\n",
    "epochs=50\n",
    "minibatch=50\n",
    "\n",
    "svi=False          # large N should make this do nothing anyways\n",
    "reg_lambda=0.      # just to make doubly sure SVI is switched off...\n",
    "\n",
    "pilot_samples=1000 # z-scoring only applies to extra inputs (here: firing rate) directly fed to fully connected layers\n",
    "\n",
    "prior_norm = True  # doesn't hurt. \n",
    "init_norm = False  # didn't yet figure how to best normalize initialization through conv- and ReLU- layers\n",
    "\n",
    "inf = infer.CDELFI(generator=g, obs=obs_stats, prior_norm=prior_norm, init_norm=init_norm,\n",
    "                 pilot_samples=pilot_samples, seed=seed, reg_lambda=reg_lambda, svi=svi,\n",
    "                 n_components=1, n_hiddens=n_hiddens, n_filters=n_filters, n_inputs = (1,d,d),\n",
    "                 filter_sizes=filter_sizes, pool_sizes=pool_sizes, n_inputs_hidden=n_inputs_hidden,verbose=True)\n",
    "\n",
    "# print parameter numbers per layer (just weights, not biases)\n",
    "def get_shape(i):\n",
    "    return inf.network.aps[i].get_value().shape\n",
    "print([get_shape(i) for i in range(1,17,2)])\n",
    "print([np.prod(get_shape(i)) for i in range(1,17,2)])\n",
    "\n",
    "# run SNPE-A for one round\n",
    "log, trn_data, posteriors = inf.run(n_train=n_train, epochs=epochs, minibatch=minibatch, n_rounds=n_rounds,  \n",
    "               lr_decay=lr_decay,n_components=n_components)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNPE-B version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network architecture: 8 layer network [4x conv, 3x fully conn., 1x MoG], 20k parameters in total \n",
    "\n",
    "filter_sizes=[3,3,3,2]   # 4 conv ReLU layers\n",
    "n_filters=(16,16,32,32)  # 16 to 32 filters\n",
    "pool_sizes=[1,2,2,1]     # \n",
    "n_hiddens=[50,50,50]     # 3 fully connected layers\n",
    "\n",
    "# N = 10k per round\n",
    "\n",
    "n_train=10000\n",
    "\n",
    "# MoG with n_component mixture components\n",
    "\n",
    "n_components=4\n",
    "\n",
    "# single rounds (first round is always'amortized' and can be used with any other STA covered by the prior)\n",
    "\n",
    "n_rounds=1\n",
    "\n",
    "# new feature for CNN architectures: passing a value directly to the hidden layers (bypassing the conv layers).\n",
    "# In this case, we pass the number of spikes (single number) directly, which allows to normalize the STAs \n",
    "# and hence help out the conv layers. Without that extra input, we couldn't recover the RF gain anymore. \n",
    "n_inputs_hidden = 1\n",
    "\n",
    "# some learning-schedule parameters\n",
    "lr_decay = 0.99\n",
    "epochs=100\n",
    "minibatch=50\n",
    "\n",
    "svi=False          # large N should make this do nothing anyways\n",
    "reg_lambda=0.      # just to make doubly sure SVI is switched off...\n",
    "\n",
    "pilot_samples=1000 # z-scoring only applies to extra inputs (here: firing rate) directly fed to fully connected layers\n",
    "\n",
    "prior_norm = True  # doesn't hurt. \n",
    "init_norm = False  # didn't yet figure how to best normalize initialization through conv- and ReLU- layers\n",
    "\n",
    "inf = infer.SNPE(generator=g, obs=obs_stats, prior_norm=prior_norm, init_norm=init_norm,\n",
    "                 pilot_samples=pilot_samples, seed=seed, reg_lambda=reg_lambda, svi=svi,\n",
    "                 n_components=n_components, n_hiddens=n_hiddens, n_filters=n_filters, n_inputs = (1,d,d),\n",
    "                 filter_sizes=filter_sizes, pool_sizes=pool_sizes, n_inputs_hidden=n_inputs_hidden,verbose=True)\n",
    "\n",
    "# print parameter numbers per layer (just weights, not biases)\n",
    "def get_shape(i):\n",
    "    return inf.network.aps[i].get_value().shape\n",
    "print([get_shape(i) for i in range(1,17,2)])\n",
    "print([np.prod(get_shape(i)) for i in range(1,17,2)])\n",
    "\n",
    "# run SNPE-B for one round\n",
    "log, trn_data, posteriors = inf.run(n_train=n_train, epochs=epochs, minibatch=minibatch, n_rounds=n_rounds,  \n",
    "               lr_decay=lr_decay)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# round #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 20000\n",
    "\n",
    "savefile = './results/MCMC/elife/maprf_MCMC_prior01_run_1_'+ str(n_samples)+'samples_param7'\n",
    "tmp = np.load(savefile + '.npz')['arr_0'][()]\n",
    "T = tmp['T']\n",
    "samples = np.hstack([np.atleast_2d(T[key].T).T for key in ['bias','A','logit_φ','log_f','logit_θ','log_γ','log_b']])\n",
    "\n",
    "fig, _ = plot_pdf(posteriors[-1], pdf2=g.prior, lims=[-3,3], samples=samples.T, \n",
    "                  gt=pars_true.reshape(-1), figsize=(16,16), resolution=100,\n",
    "                  labels_params=['bias', 'gain', 'logit phase', 'log freq', 'logit angle', 'log ratio', 'log width'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# round #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components=4\n",
    "log, trn_data, posteriors = inf.run(n_train=n_train, epochs=epochs, minibatch=minibatch, n_rounds=n_rounds,  \n",
    "               lr_decay=lr_decay, n_components=n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.semilogx(log[-1]['loss'])\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(log[-1]['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, _ = plot_pdf(posteriors[-1], pdf2=g.prior, lims=[-3,3], samples=samples.T, \n",
    "                  gt=pars_true.reshape(-1), figsize=(16,16), resolution=200,\n",
    "                  labels_params=['bias', 'gain', 'logit phase', 'log freq', 'logit angle', 'log ratio', 'log width'])\n",
    "#fig.savefig('quadro_posterior_2rounds_CDELFI_110k_total.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, _ = plot_pdf(posteriors[-1], lims=[-3,3], samples=samples.T, \n",
    "                  gt=pars_true.reshape(-1), figsize=(16,16), resolution=100,\n",
    "                  labels_params=['bias', 'gain', 'logit phase', 'log freq', 'logit angle', 'log ratio', 'log width'])\n",
    "#fig.savefig('quadro_posterior_2rounds_CDELFI_110k_total_noPrior.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, _ = plot_pdf(posteriors[-1], lims=[-3,3],\n",
    "                  gt=pars_true.reshape(-1), figsize=(16,16), resolution=100,\n",
    "                  labels_params=['bias', 'gain', 'logit phase', 'log freq', 'logit angle', 'log ratio', 'log width'])\n",
    "#fig.savefig('quadro_posterior_2rounds_CDELFI_110k_total_noSamples.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour_draws(posteriors[-1], g, obs_stats, d=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hasattr(inf.network, 'extra_stats')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save & load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import delfi.utils.io as io\n",
    "\n",
    "try: \n",
    "    inf.observables\n",
    "except:\n",
    "    inf.observables = []\n",
    "\n",
    "filename1 = './results/SNPE/elife/maprf_10k_amortized_prior01_run_1_round2_param7_nosvi_CDELFI.pkl'\n",
    "filename2 = './results/SNPE/elife/maprf_10k_amortized_prior01_run_1_round2_param7_nosvi_CDELFI_res.pkl'\n",
    "filename3 = './results/SNPE/elife/maprf_10k_amortized_prior01_run_1_round2_param7_nosvi_CDELFI_conf.pkl'\n",
    "filename4 = './results/SNPE/elife/maprf_10k_amortized_prior01_run_1_round2_param7_nosvi_CDELFI_net_only.pkl'\n",
    "\n",
    "io.save_pkl((log, trn_data, posteriors),filename1)\n",
    "np.save(filename3, params_dict_true)\n",
    "io.save_pkl(inf.network, filename4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf.generator.model = None\n",
    "io.save(inf, filename2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare with maprf sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# MCMC chain length (including burnin)\n",
    "n_samples = 20000\n",
    "\n",
    "g, prior, d = setup_sim(seed, path='.')\n",
    "\n",
    "filename = './results/toy_cells/toy_cell_' + str(idx_cell) + '.npy'\n",
    "params_dict_true = np.load(filename)[()]\n",
    "\n",
    "m = model(filter_shape= np.array((d,d,2)),\n",
    "          parametrization=sim_info['parametrization'],\n",
    "          params_ls=params_ls,\n",
    "          seed=seed,\n",
    "          dt=sim_info['dt'],\n",
    "          duration=duration)\n",
    "m.params_dict = params_dict_true.copy()\n",
    "m.rng = np.random.RandomState(seed=seed)\n",
    "obs = m.gen_single()    \n",
    "\n",
    "inference, data = setup_sampler(prior, obs, d, g, params_dict=params_dict_true, \n",
    "                      fix_position=True, parametrization='logit_φ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('- sampling RF params')\n",
    "T, L = inference.sample(n_samples)\n",
    "T = {k.name: t for k, t in T.items()}\n",
    "print('- sampling Poisson params')\n",
    "inference.sample_biases(data, T, g.model.dt);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savefile = './results/MCMC/elife/maprf_MCMC_prior01_run_1_'+ str(n_samples)+'samples_param7'\n",
    "np.savez(savefile, {'T' : T, 'params_dict_true' : params_dict_true})    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# inspect results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savefile = './results/MCMC/elife/maprf_MCMC_prior01_run_1_'+ str(n_samples)+'samples_param7'\n",
    "tmp = np.load(savefile + '.npz')['arr_0'][()]\n",
    "T = tmp['T']\n",
    "samples = np.hstack([np.atleast_2d(T[key].T).T for key in ['bias','A','logit_φ','log_f','logit_θ','log_γ','log_b']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "burnin = 50\n",
    "\n",
    "for key in ['bias', 'λo', \n",
    "            'gain', 'log_A', 'phase', 'logit_φ',\n",
    "            'angle', 'logit_θ', 'freq', 'log_f',\n",
    "            'ratio', 'width', 'log_γ', 'log_b', \n",
    "            ]:\n",
    "    \n",
    "    if key in T.keys():\n",
    "        x = T[key][burnin:]\n",
    "        plt.hist(x, bins=np.linspace(x.min(), x.max(), 20), alpha=0.5, normed=True)\n",
    "        plt.title(key)\n",
    "        plt.show()\n",
    "        print('mean:', x.mean())\n",
    "        print('var:', x.var())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, _ = plot_pdf(posteriors[-1], pdf2=g.prior, lims=[-3,3], gt=pars_true.reshape(-1), figsize=(16,16), resolution=100,\n",
    "                  samples=samples.T,\n",
    "                  labels_params=['bias', 'log gain', 'logit phase', 'log freq', 'logit angle', 'log ratio', 'log width'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
