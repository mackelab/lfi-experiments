{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SNPE & RF\n",
    "\n",
    "learning receptive field parameters from inputs (white-noise videos) and outputs (spike trains) of linear-nonlinear neuron models with parameterized linear filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import delfi.distribution as dd\n",
    "import delfi.generator as dg\n",
    "import delfi.inference as infer\n",
    "import delfi.utils.io as io\n",
    "from delfi.utils.viz import plot_pdf\n",
    "\n",
    "from lfimodels.maprf.maprf import maprf as model\n",
    "from lfimodels.maprf.maprfStats import maprfStats\n",
    "from lfimodels.maprf.utils import setup_sim, setup_sampler, get_data_o, quick_plot, contour_draws\n",
    "\n",
    "\n",
    "# parameters for this experiment\n",
    "\n",
    "seed = 42\n",
    "\n",
    "n_cells = 3 # number of toy cells\n",
    "\n",
    "# N = 10k per round\n",
    "n_train=10000\n",
    "\n",
    "# two components\n",
    "n_components=2\n",
    "\n",
    "# extra rounds (rough idea: 1st to refine the proposal locally, 2nd to figure if posterior is non-Gaussian)\n",
    "n_rounds=1\n",
    "\n",
    "# number of features passing directly to the hidden layers (number of spikes)\n",
    "n_inputs_hidden = 1\n",
    "\n",
    "# some learning-schedule parameters\n",
    "lr_decay = 1.0\n",
    "epochs=100\n",
    "minibatch=50\n",
    "\n",
    "# MCMC chain length (including burnin)\n",
    "n_samples = 500000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# learn posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for idx_cell in range(1,n_cells+1):\n",
    "\n",
    "    print('\\n')\n",
    "    print('cell #' + str(idx_cell))\n",
    "    print('\\n')\n",
    "    \n",
    "    path = '../results/SNPE/toycell_' + str(idx_cell)\n",
    "\n",
    "    filename1 = path + '/maprf_2x10k_refined_prior01_run_1_round2_param7_nosvi_CDELFI.pkl'\n",
    "    filename2 = path + '/maprf_100k_amortized_prior01_run_1_round2_param7_nosvi_base_res.pkl'\n",
    "    filename3 = path + '/maprf_100k_amortized_prior01_run_1_round2_param7_nosvi_CDELFI_inference.pkl'\n",
    "\n",
    "    savefile = '../results/MCMC/toycell_' + str(idx_cell) + '/maprf_MCMC_prior01_run_1_'+ str(n_samples)+'samples_param7'\n",
    "    \n",
    "\n",
    "    #\"\"\"\n",
    "    # MCMC    \n",
    "    print('MCMC')\n",
    "    g, prior, d = setup_sim(seed, path='..')\n",
    "    filename = '../results/toy_cells/toy_cell_' + str(idx_cell) + '.npy'\n",
    "    obs_stats, pars_true = get_data_o(filename, g, seed)\n",
    "    \n",
    "    filename = '../results/toy_cells/toy_cell_' + str(idx_cell) + '.npy'\n",
    "    params_dict_true = np.load(filename)[()]\n",
    "    m = g.model\n",
    "    m.params_dict = params_dict_true.copy()\n",
    "    m.rng = np.random.RandomState(seed=seed)\n",
    "    obs = m.gen_single()    \n",
    "    \n",
    "    inference, data = setup_sampler(prior, obs, d, g, params_dict=params_dict_true, \n",
    "                          fix_position=True, parametrization='logit_Ï†')\n",
    "    \n",
    "    print('- sampling RF params')\n",
    "    T, L = inference.sample(n_samples)\n",
    "    T = {k.name: t for k, t in T.items()} \n",
    "    print('- sampling Poisson params')\n",
    "    inference.sample_biases(data, T, g.model.dt)\n",
    "    \n",
    "    np.savez(savefile, {'T' : T, 'params_dict_true' : params_dict_true})    \n",
    "    #\"\"\"\n",
    "    \n",
    "    #\"\"\"\n",
    "    # SNPE\n",
    "    print('SNPE')\n",
    "    filename = '../results/SNPE/maprf_100k_amortized_prior01_run_1_round1_param7_nosvi_base_res.pkl'\n",
    "    inf = io.load(filename)\n",
    "    g, prior, d = setup_sim(seed, path='..') # reset model\n",
    "    filename = '../results/toy_cells/toy_cell_' + str(idx_cell) + '.npy'\n",
    "    obs_stats, pars_true = get_data_o(filename, g, seed)\n",
    "    \n",
    "    inf.generator = g\n",
    "    inf.obs = obs_stats\n",
    "\n",
    "    #proposal = inf.predict(obs_stats)\n",
    "    #quick_plot(g, obs_stats, d, pars_true, proposal)\n",
    "\n",
    "    log, trn_data, posteriors = inf.run(n_train=n_train, \n",
    "                                        n_components=n_components,\n",
    "                                        epochs=epochs, minibatch=minibatch, \n",
    "                                        n_rounds=n_rounds, lr_decay=lr_decay)\n",
    "\n",
    "    #quick_plot(g, obs_stats, d, pars_true, posterior, log)\n",
    "    #contour_draws(posterior, g, obs_stats, d)\n",
    "\n",
    "    io.save_pkl((log, trn_data, posteriors),filename1)\n",
    "    inf.generator.model = None # model cannot be pickled atm\n",
    "    io.save_pkl((inf.generator,inf.stats_mean,inf.stats_std,\n",
    "                 inf.network,inf.kwargs,\n",
    "                 inf.loss,inf.reg_lambda),filename3)    \n",
    "    #\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
