{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import delfi.distribution as dd\n",
    "import delfi.generator as dg\n",
    "import delfi.inference as infer\n",
    "import delfi.summarystats as ds\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "from lfimodels.ricker.Ricker import Ricker\n",
    "from lfimodels.ricker.RickerStats import RickerStats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LFI for Ricker model\n",
    "\n",
    "http://www.maths.lth.se/matstat/staff/umberto/SyntheticLikelihoods_MSCproject/wood_2010.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_params = 3\n",
    "\n",
    "# problem setup\n",
    "T, burn_in = 50, 100\n",
    "thetao = np.array([3.8, 0.3, 10.])\n",
    "xo = {'data' : np.array([\n",
    "    0,   0,   4,  81,   0,  27,  52,  19, 134,   0,\n",
    "    0,  27,  84,   1, 166,   0,   1,   0,  37,  65,\n",
    "    4,  50,   4, 121,   0,   0,  38,  36,  36,  55,\n",
    "   19, 155,   0,   0,   0,  59,  18, 128,   0,   1,\n",
    "   18, 138,   0,   0,  10, 148,   0,   0,   0,  22], dtype=np.int64) }\n",
    "s = RickerStats(obs = xo['data'])\n",
    "obs_stats = s.calc([xo])\n",
    "\n",
    "# define generator init (new for every seed)\n",
    "def init_g(seed):\n",
    "    m = Ricker(dim=n_params, \n",
    "               burnIn=burn_in, \n",
    "               T=T, \n",
    "               log_r0=0, \n",
    "               seed=seed)\n",
    "    p = dd.Uniform(lower=np.array([3.0, 0.0,  4.0]), \n",
    "                   upper=np.array([5.0, 0.8, 20.0]),\n",
    "                   seed=seed)\n",
    "    return dg.Default(model=m, prior=p, summary=s)\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "x_range = np.arange(xo['data'].size).reshape(-1, 1) + 1\n",
    "plt.plot(x_range, xo['data'], 'bo')\n",
    "plt.plot(np.hstack([x_range,x_range]).T, np.hstack([np.zeros_like(x_range), xo['data'].reshape(-1,1)]).T, 'b')\n",
    "plt.title('observed data (not summary stats!)')\n",
    "plt.xlabel('time bin t')\n",
    "plt.ylabel('observed count')\n",
    "plt.axis([0, 51, 0, 180])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from delfi.utils.viz import plot_pdf\n",
    "\n",
    "rounds = 2\n",
    "n_train = [150, 350]\n",
    "algo = 'kSNPE'\n",
    "\n",
    "seeds = range(90, 93)\n",
    "\n",
    "for seed in seeds:\n",
    "    \n",
    "    trn_seed = seed\n",
    "    kwargs = {'generator': init_g(seed), \n",
    "              'reg_lambda': 0.01,\n",
    "              'n_components': 2, \n",
    "              'n_hiddens': [20], \n",
    "              'verbose' : True,\n",
    "              'obs': obs_stats.copy(),\n",
    "              'seed': trn_seed}\n",
    "\n",
    "    # setup of learning schedule\n",
    "    train = []\n",
    "    for r in range(rounds):\n",
    "        train.append(n_train[0])\n",
    "    train[-1] = n_train[-1]\n",
    "    round_cl=999\n",
    "    minibatch=50\n",
    "    n_gradients = 100000\n",
    "    epochs = [n_gradients // (n_train//minibatch) for n_train in train]\n",
    "    print('n_train :', train)\n",
    "    print('epochs :', epochs)\n",
    "\n",
    "    \n",
    "    \n",
    "    if algo == 'CDELFI':\n",
    "        inf = infer.CDELFI(**kwargs)\n",
    "        log, train_data, posteriors = inf.run(n_train=train,\n",
    "                                              minibatch=minibatch,         \n",
    "                                              n_rounds=len(train),\n",
    "                                              epochs=epochs)\n",
    "    elif algo == 'SNPE':\n",
    "        inf = infer.SNPE(**kwargs,convert_to_T=3)\n",
    "        log, train_data, posteriors = inf.run(n_train=train,\n",
    "                                              minibatch=minibatch,                                              \n",
    "                                              n_rounds=len(train),\n",
    "                                              epochs=epochs, \n",
    "                                              round_cl=round_cl)        \n",
    "    elif algo == 'kSNPE':\n",
    "        inf = infer.SNPE(**kwargs,convert_to_T=3)\n",
    "        log, train_data, posteriors = inf.run(n_train=train,\n",
    "                                              minibatch=minibatch,                                              \n",
    "                                              n_rounds=len(train),\n",
    "                                              epochs=epochs, \n",
    "                                              kernel_loss='x_kl', \n",
    "                                              round_cl=round_cl)      \n",
    "\n",
    "    for r in range(rounds):\n",
    "        w = train_data[r][2]\n",
    "        w /= w.sum()\n",
    "        \n",
    "        print('ESS', 1/np.sum(w**2))\n",
    "        \n",
    "        plot_pdf(posteriors[r],\n",
    "                 pdf2=posteriors[0],\n",
    "                 #samples=train_data[1][0][::1,:].T, \n",
    "                 gt=thetao, \n",
    "                 lims=np.array([\n",
    "                    [3, 5],\n",
    "                    [0, 0.8],\n",
    "                    [4,20]            \n",
    "                ]),\n",
    "                 resolution=100,\n",
    "                 ticks=True,\n",
    "                 figsize=(16,16));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from ctypes import CDLL, c_double, c_int, RTLD_GLOBAL\n",
    "\n",
    "path = '/home/marcel/Desktop/Projects/Biophysicality/code/lfi_models/lfimodels/ricker/'\n",
    "#load the shared object file\n",
    "ricker = CDLL(path + 'ricker.so')\n",
    "n      = (c_double * T)(*np.zeros(T))\n",
    "\n",
    "ricker.ricker(\n",
    "    n,                                           # *n   \n",
    "    (c_double * thetao.size)(*thetao.flatten()), # *theta\n",
    "    (c_double * (T+burn_in))(*e),                # *e\n",
    "    (c_int * 1)(burn_in),                        # *burn_in\n",
    "    (c_int * 1)(T),                              # *n_t\n",
    "    (c_int * 1)(1),                              # *n_reps\n",
    "    (c_double * 1)(log_r0))                      # *n0\n",
    "n = np.array(n)\n",
    "\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "acf_c  = CDLL(path + 'acf.so')\n",
    "mat_c  = CDLL(path + 'mat.so', mode=RTLD_GLOBAL)\n",
    "nlar_c = CDLL(path + 'nlar.so', mode=RTLD_GLOBAL)\n",
    "\n",
    "def afc(x, max_lag=10):\n",
    "    \"\"\"\n",
    "    `x' is a matrix containing replicate simulations in its columns.\n",
    "    sl.acf turns these into acf's    \n",
    "    \"\"\"\n",
    "    assert x.shape[1] == 1 # never tested otherwise. Do not remove without testing\n",
    "\n",
    "    vafc = np.zeros((max_lag+1, x.shape[1]))\n",
    "    vafc = (c_double * vafc.size)(*vafc.flatten())\n",
    "    NAcode = -1e70\n",
    "    \n",
    "    #oo <- .C(\"slacf\",acf=as.double(acf),x=as.double(x),as.integer(nrow(x)),as.integer(ncol(x)),\n",
    "    #        as.integer(max.lag),as.double(NAcode),correlation=as.integer(0),PACKAGE=\"sl\")\n",
    "    afc = acf_c.slacf(\n",
    "        vafc,                                               # *afc\n",
    "        (c_double * (x.shape[0]*x.shape[1]))(*x.flatten()), # *x\n",
    "        (c_int    * 1)(x.shape[0]),                         # *n\n",
    "        (c_int    * 1)(x.shape[1]),                         # *n_reps\n",
    "        (c_int    * 1)(max_lag),                            # *max_lag,\n",
    "        (c_double * 1)(NAcode),                             # *NAcode\n",
    "        (c_int    * 1)(0))                                  # correlation\n",
    "    \n",
    "    return np.array(vafc)\n",
    "\n",
    "def nlar(x, lag, power):\n",
    "    \"\"\" \n",
    "    relatively efficient polynomial autoregression for multiple reps.\n",
    "    each column of `x' is a replicate. \n",
    "    `lag[i]' is the lag for term i on rhs of autoregression\n",
    "    `power[i]' is the power for term i on rhs of autoregression \n",
    "    \"\"\"    \n",
    "    assert x.shape[1] == 1 # never tested otherwise. Do not remove without testing\n",
    "    \n",
    "    beta = np.zeros((len(lag), x.shape[1]))\n",
    "    beta = (c_double * beta.size)(*beta.flatten())\n",
    "    NAcode = -1e70\n",
    "    \n",
    "    #oo <- .C(\"slnlar\",beta = as.double(beta), x = as.double(x),\n",
    "    #        n=as.integer(nrow(x)),n.reps=as.integer(ncol(x)),n.terms=as.integer(length(lag)),\n",
    "    #        as.integer(lag),as.integer(power),as.double(NAcode),PACKAGE=\"sl\")    \n",
    "    nlar_c.slnlar(\n",
    "        beta,                                               # *beta\n",
    "        (c_double * (x.shape[0]*x.shape[1]))(*x.flatten()), # *x\n",
    "        (c_int    * 1)(x.shape[0]),                         # *n\n",
    "        (c_int    * 1)(x.shape[1]),                         # *n_reps\n",
    "        (c_int    * 1)(len(lag)),                           # *n_terms\n",
    "        (c_int    * len(lag))(*lag),                        # *lag\n",
    "        (c_int    * len(power))(*power),                    # *power\n",
    "        (c_double * 1)(NAcode)                              # *NAcode\n",
    "        )\n",
    "    \n",
    "    return np.array(beta)\n",
    "\n",
    "def order_dist(x, z, n_p=3, diff=1):\n",
    "    \"\"\"\n",
    "    Routine to obtain coefficients summarizing distribution of (differenced) columns\n",
    "    of x, by regression of sorted differenced columns of x on sorted differenced z's. \n",
    "    regression is with order `np' polynomial (no intercept as all centred). `diff'\n",
    "    is order of differencing to apply.\n",
    "    \"\"\"\n",
    "    #assert x.shape[1] == 1 # never tested otherwise. Do not remove without testing\n",
    "    assert z.ndim==1 or z.shape[1]==1\n",
    "    \n",
    "    beta = np.zeros((n_p, x.shape[1]))\n",
    "    beta = (c_double * beta.size)(*beta.flatten())\n",
    "    \n",
    "    #oo <- .C(\"order_reg\",beta=as.double(beta), as.double(x),as.double(z),n=as.integer(nrow(x)),\n",
    "    #        as.integer(ncol(x)),as.integer(np),as.integer(diff),PACKAGE=\"sl\")    \n",
    "    nlar_c.order_reg(\n",
    "        beta,                                               # *beta\n",
    "        (c_double * (x.shape[0]*x.shape[1]))(*x.flatten()), # *x\n",
    "        (c_double * (z.size))               (*z.flatten()), # *z\n",
    "        (c_int    * 1)(x.shape[0]),                         # *n\n",
    "        (c_int    * 1)(x.shape[1]),                         # *n_reps\n",
    "        (c_int    * 1)(n_p),                                # *n_p\n",
    "        (c_int    * 1)(diff)                                # *diff\n",
    "        )\n",
    "    \n",
    "    return np.array(beta)\n",
    "    \n",
    "def summary_stats(X,xo,max_lag=5, lag=[1,1], power=[1,2], n_p=3, diff=1):\n",
    "    \n",
    "    vacf = afc(X,max_lag=max_lag)\n",
    "\n",
    "    b0 = nlar(X**.3,lag=lag,power=power)\n",
    "\n",
    "    b1 = order_dist(X,xo,n_p=n_p,diff=diff)\n",
    "    \n",
    "    return np.concatenate(( vacf, b0, b1, np.mean(x, axis=1), np.mean(x==0, axis=1) ))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = m.gen_single(thetao)['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s.calc([m.gen_single(thetao)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s.obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary_stats(x.T,x.T,max_lag=5, lag=[1,1], power=[1,2], n_p=3, diff=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nlar(x.T, lag=[1,1], power=[1,2]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "afc(x.T, max_lag=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.cov(x[0,:-4],x[0,4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  acf.Y <- sl.acf(Y,max.lag=5)\n",
    "  acf.y <- sl.acf(y,max.lag=5)\n",
    "\n",
    "  b0.Y <- nlar(Y^.3,lag=c(1,1),power=c(1,2))\n",
    "  b0.y <- nlar(y^.3,lag=c(1,1),power=c(1,2))\n",
    "\n",
    "  b1.Y <- order.dist(Y,y,np=3,diff=1)\n",
    "  b1.y <- order.dist(y,y,np=3,diff=1)   \n",
    "  \n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
