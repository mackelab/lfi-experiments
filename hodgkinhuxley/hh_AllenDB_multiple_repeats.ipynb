{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference of Hodgkin-Huxley model on cell from Allen Cell Type Database with multiple repeats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import delfi.distribution as dd\n",
    "import delfi.generator as dg\n",
    "import delfi.inference as infer\n",
    "import delfi.utils.io as io\n",
    "import delfi.summarystats as ds\n",
    "import lfimodels.hodgkinhuxley.utilsMultiStep as utilsMultiStep\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from lfimodels.hodgkinhuxley.HodgkinHuxleyMultiStep import HodgkinHuxleyMultiStep\n",
    "from lfimodels.hodgkinhuxley.HodgkinHuxleyMultiStepStatsMoments import HodgkinHuxleyMultiStepStatsMoments\n",
    "from lfimodels.hodgkinhuxley.HodgkinHuxleyMultiStepStatsSpikes_mf import HodgkinHuxleyMultiStepStatsSpikes_mf\n",
    "from delfi.utils.viz import plot_pdf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_params, labels_params = utilsMultiStep.obs_params()\n",
    "\n",
    "seed = 1\n",
    "prior_uniform = True\n",
    "prior_log = False\n",
    "prior_extent = True\n",
    "n_xcorr = 0\n",
    "n_mom = 4\n",
    "cython=True\n",
    "n_summary = 8\n",
    "summary_stats = 1\n",
    "\n",
    "ephys_cell = 566517779\n",
    "sweep_number_ls=[44,56,57,58,59]\n",
    "A_soma = 0.0195/198\n",
    "junction_potential = -14\n",
    "\n",
    "num_repeats = len(sweep_number_ls)\n",
    "\n",
    "obs = utilsMultiStep.allen_obs_data(ephys_cell=ephys_cell,sweep_number_ls=sweep_number_ls,A_soma=A_soma)\n",
    "\n",
    "obs['data'] = obs['data'] + junction_potential\n",
    "\n",
    "# correct t_on and t_off\n",
    "obs['t_on'] = 205.0\n",
    "obs['t_off'] = 1204.99\n",
    "\n",
    "I = obs['I']\n",
    "dt = obs['dt']\n",
    "t_on = obs['t_on']\n",
    "t_off = obs['t_off']\n",
    "\n",
    "obs_stats = utilsMultiStep.allen_obs_stats(data=obs,ephys_cell=ephys_cell,sweep_number_ls=sweep_number_ls,\n",
    "                                           n_xcorr=n_xcorr,n_mom=n_mom,\n",
    "                                           summary_stats=summary_stats,n_summary=n_summary)\n",
    "\n",
    "# define model, prior, summary statistics and generator\n",
    "n_processes = 8\n",
    "\n",
    "def rej(x):\n",
    "    return ~np.any(np.isnan(x))\n",
    "\n",
    "if n_processes>1:\n",
    "    seeds_model = np.arange(1,n_processes+1,1)\n",
    "    m = []\n",
    "    for i in range(n_processes):\n",
    "        m.append(HodgkinHuxleyMultiStep(I, dt, V0=obs['data'][:,0], repeats=num_repeats, seed=seeds_model[i],\n",
    "                                        cython=cython,\n",
    "                                        prior_log=prior_log))\n",
    "    p = utilsMultiStep.prior(true_params=true_params,prior_uniform=prior_uniform,\n",
    "                    prior_extent=prior_extent,prior_log=prior_log, seed=seed)\n",
    "    s = HodgkinHuxleyMultiStepStatsMoments(t_on=t_on, t_off=t_off,n_xcorr=n_xcorr,n_mom=n_mom,n_summary=n_summary)\n",
    "#     s = HodgkinHuxleyMultiStepStatsSpikes_mf(t_on=t_on, t_off=t_off,n_summary=n_summary)\n",
    "#     g = dg.MPGenerator(models=m, prior=p, summary=s, rej=rej)\n",
    "    g = dg.MPGenerator(models=m, prior=p, summary=s)\n",
    "else:\n",
    "    seed = None\n",
    "    m = HodgkinHuxleyMultiStep(I, dt, V0=obs['data'][:,0], repeats=num_repeats, seed=seed,\n",
    "                               cython=cython,prior_log=prior_log)\n",
    "    p = utilsMultiStep.prior(true_params=true_params,prior_uniform=prior_uniform,\n",
    "                    prior_extent=prior_extent,prior_log=prior_log, seed=seed)\n",
    "    s = HodgkinHuxleyMultiStepStatsMoments(t_on=t_on, t_off=t_off,n_xcorr=n_xcorr,n_mom=n_mom,n_summary=n_summary)\n",
    "#     s = HodgkinHuxleyMultiStepStatsSpikes_mf(t_on=t_on, t_off=t_off,n_summary=n_summary)\n",
    "    g = dg.RejKernel(model=m, prior=p, summary=s, rej=rej)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,8))\n",
    "for i in range(num_repeats):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.plot(obs['time'],obs['data'][i],lw=2)\n",
    "    plt.xlabel('time (ms)')\n",
    "    plt.ylabel('voltage (mV)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t_on)\n",
    "print(t_off)\n",
    "print(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SNPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "svi = False\n",
    "impute_missing = False\n",
    "pilot_samples = 1000\n",
    "n_sims = 125000\n",
    "n_rounds = 2\n",
    "n_components = 1\n",
    "n_hiddens = [100]*2\n",
    "kernel_loss='x_kl'\n",
    "res = infer.SNPE(g, obs=obs_stats, pilot_samples=pilot_samples, n_hiddens=n_hiddens, seed=seed, prior_norm=True,\n",
    "                 n_components=n_components, svi=svi, impute_missing=impute_missing)\n",
    "\n",
    "# run with N samples\n",
    "log, train_data, posterior = res.run(n_sims, n_rounds=n_rounds, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if svi:\n",
    "    svi_flag = '_svi'\n",
    "else:\n",
    "    svi_flag = '_nosvi'\n",
    "\n",
    "filename1 = './results/allen_'+str(ephys_cell)+'_'+str(num_repeats)+\\\n",
    "'repeats_run_1_round2_prior0013_param8'+svi_flag+'_ncomp'+str(n_components)+\\\n",
    "'_nsims'+str(n_sims*n_rounds)+'_snpe.pkl'\n",
    "filename2 = './results/allen_'+str(ephys_cell)+'_'+str(num_repeats)+\\\n",
    "'repeats_run_1_round2_prior0013_param8'+svi_flag+'_ncomp'+str(n_components)+\\\n",
    "'_nsims'+str(n_sims*n_rounds)+'_snpe_res.pkl'\n",
    "io.save_pkl((log, train_data, posterior),filename1)\n",
    "io.save(res, filename2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_sims = 50000\n",
    "# n_rounds = 2\n",
    "filename1 = './results/allen_'+str(ephys_cell)+'_'+str(num_repeats)+\\\n",
    "'repeats_run_1_round2_prior0013_param8'+svi_flag+'_ncomp'+str(n_components)+\\\n",
    "'_nsims'+str(n_sims*n_rounds)+'_snpe.pkl'\n",
    "filename2 = './results/allen_'+str(ephys_cell)+'_'+str(num_repeats)+\\\n",
    "'repeats_run_1_round2_prior0013_param8'+svi_flag+'_ncomp'+str(n_components)+\\\n",
    "'_nsims'+str(n_sims*n_rounds)+'_snpe_res.pkl'\n",
    "log, train_data, posterior = io.load_pkl(filename1)\n",
    "res = io.load(filename2)\n",
    "# posterior = res.predict(obs_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res.network.n_components)\n",
    "print(res.network.n_hiddens)\n",
    "print(np.shape(train_data[0][0]))\n",
    "print(np.shape(train_data[0][1]))\n",
    "print(np.shape(train_data[1][0]))\n",
    "print(np.shape(train_data[1][1]))\n",
    "print(res.round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputation_values = log[-1]['imputation_values'][-1]*res.stats_std+res.stats_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(imputation_values,label='imputation values')\n",
    "# plt.plot(obs_stats[0],label='observed features')\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use samples from first round to re-learn network with different configurations\n",
    "\n",
    "# # set network\n",
    "# import theano\n",
    "# import theano.tensor as tt\n",
    "\n",
    "# from delfi.neuralnet.NeuralNet import NeuralNet\n",
    "\n",
    "# dtype = theano.config.floatX\n",
    "\n",
    "# # n_hiddens=[1000,1000]\n",
    "# n_hiddens=[200]*3\n",
    "# n_components=1\n",
    "# svi = False\n",
    "# impute_missing = True\n",
    "# res.network = NeuralNet(n_inputs=train_data[0][1].shape[1],\n",
    "#                         n_outputs = train_data[0][0].shape[1],\n",
    "#                         n_hiddens=n_hiddens, n_components=n_components, svi=svi, impute_missing=impute_missing)\n",
    "# res.network.iws = tt.vector('iws', dtype=dtype)\n",
    "\n",
    "# from delfi.neuralnet.Trainer import Trainer\n",
    "\n",
    "# def train_net(res=res, epochs=100, minibatch=50, round_cl=1, stop_on_nan=False, monitor=None, **kwargs):\n",
    "#     \"\"\"Run algorithm\"\"\"\n",
    "\n",
    "#     # load training data (z-transformed params and stats)\n",
    "#     _, trn_data, _ = io.load_pkl(filename1)\n",
    "#     trn_data = trn_data[0]\n",
    "#     n_train_round = trn_data[0].shape[0]\n",
    "\n",
    "#     # precompute importance weights\n",
    "#     iws = np.ones((n_train_round,))\n",
    "\n",
    "#     # normalize weights\n",
    "#     iws = (iws/np.sum(iws))*n_train_round\n",
    "\n",
    "#     trn_data = (trn_data[0], trn_data[1], iws)\n",
    "#     trn_inputs = [res.network.params, res.network.stats,\n",
    "#                   res.network.iws]\n",
    "\n",
    "#     t = Trainer(res.network,\n",
    "#                 res.loss(N=n_train_round, round_cl=round_cl),\n",
    "#                 trn_data=trn_data, trn_inputs=trn_inputs,\n",
    "#                 seed=res.gen_newseed(),\n",
    "#                 monitor=res.monitor_dict_from_names(monitor),\n",
    "#                 **kwargs)\n",
    "#     log = t.train(epochs=epochs, minibatch=minibatch,\n",
    "#                         verbose=res.verbose, stop_on_nan=stop_on_nan)\n",
    "\n",
    "#     posterior = res.predict(res.obs)\n",
    "\n",
    "#     return log, posterior\n",
    "\n",
    "# epochs=100\n",
    "# minibatch=50\n",
    "# log, posterior = train_net(epochs=epochs, minibatch=minibatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_transform(prior_log, x):\n",
    "    if prior_log:\n",
    "        return np.log(x)\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def param_invtransform(prior_log, x):\n",
    "    if prior_log:\n",
    "        return np.exp(x)\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if prior_uniform:\n",
    "    prior_min = res.generator.prior.lower\n",
    "    prior_max = res.generator.prior.upper\n",
    "else:\n",
    "    prior_min = param_transform(prior_log,np.array([.5,1e-4,1e-4,1e-4,50.,40.,1e-4,35.]))\n",
    "    prior_max = param_transform(prior_log,np.array([80.,15.,.6,.6,3000.,90.,.15,100.]))\n",
    "\n",
    "prior_lims = np.concatenate((prior_min.reshape(-1,1),\n",
    "                                 prior_max.reshape(-1,1)),\n",
    "                                axis=1)\n",
    "\n",
    "for i in range(res.round):\n",
    "    fig = plt.figure(figsize=(15,15))\n",
    "    plot_pdf(posterior[i], lims=prior_lims, samples=None,figsize=(15,15))\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior=posterior[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot best solution of genetic algorithm\n",
    "# _, halloffame, _, _ = io.load_pkl('allen_'+str(ephys_cell)+'_run_3_offspr100_max_gen100_ibea.pkl')\n",
    "\n",
    "if prior_uniform:\n",
    "    prior_min = res.generator.prior.lower\n",
    "    prior_max = res.generator.prior.upper\n",
    "else:\n",
    "    prior_min = param_transform(prior_log,np.array([.5,1e-4,1e-4,1e-4,50.,40.,1e-4,35.]))\n",
    "    prior_max = param_transform(prior_log,np.array([80.,15.,.6,.6,3000.,90.,.15,100.]))\n",
    "\n",
    "prior_lims = np.concatenate((prior_min.reshape(-1,1),\n",
    "                             prior_max.reshape(-1,1)),\n",
    "                            axis=1)\n",
    "\n",
    "# plot_pdf(posterior, lims=prior_lims, samples=None, figsize=(15,15),\n",
    "#          gt=halloffame[0], labels_params=labels_params, ticks=True);\n",
    "plot_pdf(posterior, lims=prior_lims, samples=None, figsize=(15,15), labels_params=labels_params, ticks=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "\n",
    "col_min = 1\n",
    "num_colors = 2+col_min\n",
    "cm1 = mpl.cm.Blues\n",
    "col1 = [cm1(1.*i/num_colors) for i in range(col_min,num_colors)]\n",
    "\n",
    "for i in range(2):\n",
    "    plt.subplot(2,1,i+1)\n",
    "    plt.plot(log[i]['loss'], color=col1[i], lw=2)\n",
    "    plt.xlabel('iteration')\n",
    "    plt.ylabel('loss')\n",
    "    plt.title('round'+str(i+1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sim = len(train_data[0][0][:,0])\n",
    "ess = np.zeros(res.round)\n",
    "for i in range(res.round):\n",
    "    ess[i] = 1/np.sum((train_data[i][2]/n_sim)**2)\n",
    "ess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.round = len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.sqrt(np.diag(posterior.xs[np.argmax(posterior.a)].S))/mn_post,'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "# mn_post, S = posterior.calc_mean_and_cov()\n",
    "mn_post = posterior.xs[np.argmax(posterior.a)].m\n",
    "# S = posterior.xs[np.argmax(posterior.a)].S\n",
    "n_params = len(mn_post)\n",
    "y_obs = obs['data']\n",
    "t = obs['time']\n",
    "duration = np.max(t)\n",
    "\n",
    "COL = {}\n",
    "COL['GT']   = (35/255,86/255,167/255)\n",
    "COL['SNPE'] = (0, 174/255,239/255)\n",
    "\n",
    "# # parameter set from training data with minimum distance to observed data\n",
    "# train_data_unzscored = train_data[res.round-1][1]*res.stats_std+res.stats_mean\n",
    "# # param_min_arg = np.argmin(np.linalg.norm(train_data_unzscored-obs_stats[0],axis=1))\n",
    "# param_min_arg = np.argmin(np.linalg.norm((train_data_unzscored-obs_stats[0])/obs_stats[0],axis=1))\n",
    "# param_min = train_data[res.round-1][0][param_min_arg,:]*res.params_std + res.params_mean\n",
    "# param_min_stats = train_data[res.round-1][1][param_min_arg,:]*res.stats_std + res.stats_mean\n",
    "\n",
    "num_samp = 3\n",
    "\n",
    "# # sampling at contour of 1 covariance away from mean (if samples from outside the prior box, contour is at prior box)\n",
    "# x_samp = np.random.randn(n_params,num_samp)\n",
    "# x_samp = np.divide(x_samp,np.linalg.norm(x_samp,axis=0))\n",
    "# x_samp = (np.dot(S,x_samp)).T+mn_post\n",
    "\n",
    "# sample from posterior\n",
    "x_samp = posterior.gen(n_samples=num_samp)\n",
    "\n",
    "# reject samples outside the prior box\n",
    "ind = (x_samp > prior_min) & (x_samp < prior_max)\n",
    "x_samp = x_samp[np.prod(ind,axis=1)==1]\n",
    "\n",
    "num_samp = len(x_samp[:,0])\n",
    "num_colors = num_samp+1\n",
    "cm1 = mpl.cm.Oranges\n",
    "col1 = [cm1(1.*i/num_colors) for i in range(num_colors)]\n",
    "\n",
    "# params = param_invtransform(prior_log,np.concatenate((np.array([param_min]),np.array([mn_post]),x_samp)))\n",
    "params = param_invtransform(prior_log,np.concatenate((np.array([mn_post]),x_samp)))\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "V = np.zeros((num_repeats,len(t),1+num_samp))\n",
    "for i in range(1+num_samp):\n",
    "    m = HodgkinHuxleyMultiStep(I=I, dt=dt, V0=obs['data'][0], repeats=num_repeats,\n",
    "                               seed=230+i, cython=True, prior_log=prior_log)\n",
    "    x = m.gen_single(param_transform(prior_log,params[i,:]))\n",
    "    V[:,:,i] = x['data']\n",
    "    if i>0:\n",
    "        for j in range(num_repeats):\n",
    "            plt.subplot(2,3,j+1)\n",
    "            plt.plot(t, V[j, :, i], color = col1[i-1], lw=2, label='sample '+str(num_samp-i+1))\n",
    "\n",
    "# plotting simulation\n",
    "# plt.plot(t, V[:, 0], color='r', lw=2, label='min sample')\n",
    "for j in range(num_repeats):\n",
    "    plt.subplot(2,3,j+1)\n",
    "    plt.plot(t, V[j, :, 0], color=COL['SNPE'], lw=2, label='mode')\n",
    "    plt.plot(t, y_obs[j], color=COL['GT'], lw=2, label='observation')\n",
    "\n",
    "\n",
    "# # average parameter set between the two modes (if two components considered)\n",
    "# if res.network.n_components == 2:\n",
    "#     param_av = (posterior.xs[0].m + posterior.xs[1].m)/2\n",
    "#     m = HodgkinHuxley(I=I, dt=dt, V0=obs['data'][0], seed=231+i, cython=True, prior_log=prior_log)\n",
    "#     x = m.gen_single(param_transform(prior_log,param_av))\n",
    "# #     plt.plot(t, x['data'], color='r', lw=2, label='modes average')\n",
    "    \n",
    "#     mn_post_small = posterior.xs[np.argmin(posterior.a)].m\n",
    "#     m = HodgkinHuxley(I=I, dt=dt, V0=obs['data'][0], seed=232+i, cython=True, prior_log=prior_log)\n",
    "#     x = m.gen_single(param_transform(prior_log,mn_post_small))\n",
    "# #     plt.plot(t, x['data'], color='g', lw=2, label='smallest mode')\n",
    "# else:\n",
    "#     param_av = posterior.xs[np.argmax(posterior.a)].m\n",
    "\n",
    "\n",
    "plt.xlabel('time (ms)')\n",
    "plt.ylabel('voltage (mV)')\n",
    "\n",
    "ax = plt.gca()\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles[::-1], labels[::-1], bbox_to_anchor=(1.3, 1), loc='upper right')\n",
    "\n",
    "ax.set_xticks([0, duration/2, duration])\n",
    "ax.set_yticks([-80, -20, 40]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "# plotting simulation\n",
    "for j in range(num_repeats):\n",
    "    plt.subplot(2,3,j+1)\n",
    "    # plt.plot(t, V[:, 0], color='r', lw=2, label='min sample')\n",
    "    plt.plot(t, V[j, :, 0], color=COL['SNPE'], lw=2, label='mode')\n",
    "    plt.xlabel('time (ms)')\n",
    "    plt.ylabel('voltage (mV)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels_sum_stats = ['sp_t','ISI_mn','ISI_std','c0','c1','c2','c3','c4','c5','c6','c7','c8','c9',\n",
    "#                     'r_pot','mn','m2','m3','m4','m5','m6','m7','m8']\n",
    "# labels_sum_stats = ['sp_t','c0','c1','c2','c3','c4',\n",
    "#                     'r_pot','r_pot_std','m1','m2','m3','m4','m5']\n",
    "# labels_sum_stats = ['sp_t','c0','c1','r_pot','r_pot_std','m1','m2','m3','m4']\n",
    "labels_sum_stats = ['sp_t','r_pot','r_pot_std','m1','m2','m3','m4','mn_sp_t']\n",
    "# labels_sum_stats = ['f_rate','AP_lat','AP_oversh','r_pot','r_pot_std','AHD','A_ind','spike_w','ISI_mn','ISI_std']\n",
    "# labels_sum_stats = ['f_rate','AP_lat','AP_oversh','r_pot','r_pot_std','AHD','A_ind','spike_w']\n",
    "\n",
    "n_summary_stats = len(labels_sum_stats)\n",
    "\n",
    "sum_stats_post = res.generator.summary.calc([m.gen_single(mn_post)])[0]\n",
    "# sum_stats_post_small = res.generator.summary.calc([m.gen_single(param_transform(prior_log,mn_post_small))])[0]\n",
    "# sum_stats_param_av = res.generator.summary.calc([m.gen_single(param_transform(prior_log,param_av))])[0]\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(20,5))\n",
    "ax = plt.subplot(1,2,1)\n",
    "plt.plot(res.obs[0], color=COL['GT'], lw=2, label='observation')\n",
    "plt.plot(sum_stats_post, color=COL['SNPE'], lw=2, label='mode')\n",
    "# plt.plot(imputation_values, color='r', lw=2, label='imputation values')\n",
    "# plt.plot(sum_stats_post_small, color='g', lw=2, label='smallest mode')\n",
    "# plt.plot(sum_stats_param_av, color='r', lw=2, label='modes average')\n",
    "ax.set_xticks(np.linspace(0,n_summary_stats-1,n_summary_stats))\n",
    "ax.set_xticklabels(labels_sum_stats)\n",
    "plt.ylabel('feature value')\n",
    "ax = plt.gca()\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles[::-1], labels[::-1], bbox_to_anchor=(1.2, 1), loc='upper right')\n",
    "\n",
    "ax = plt.subplot(1,2,2)\n",
    "plt.semilogy(np.abs(res.obs[0]),color=COL['GT'],linestyle='--', lw=2, label='observation')\n",
    "plt.semilogy(np.abs(sum_stats_post-res.obs[0]),color=COL['SNPE'], lw=2, label='mode')\n",
    "# plt.plot(imputation_values-obs_stats[0], color='r', lw=2, label='imputation values')\n",
    "# plt.plot(sum_stats_post_small-obs_stats[0], color='g', lw=2, label='smallest mode')\n",
    "# plt.plot(sum_stats_param_av-obs_stats[0], color='r', lw=2, label='modes average')\n",
    "ax.set_xticks(np.linspace(0,n_summary_stats-1,n_summary_stats))\n",
    "ax.set_xticklabels(labels_sum_stats);\n",
    "plt.ylabel(r'$f^*$ - f');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rejection ABC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round_num = 0\n",
    "obs_stats_zscored = (obs_stats[0]-res.stats_mean)/res.stats_std\n",
    "dist_train_data = np.linalg.norm((train_data[round_num][1]-obs_stats_zscored),axis=1)\n",
    "dist_argsort = np.argsort(dist_train_data)\n",
    "percent_accept = .1\n",
    "percent_criterion = int(len(dist_train_data)*percent_accept/100)\n",
    "train_data_accept = train_data[round_num][0][dist_argsort[0:percent_criterion],:]*res.params_std + res.params_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(train_data_accept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(dist_train_data[~np.isnan(dist_train_data)]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(dist_train_data[dist_argsort[0:percent_criterion]]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pdf(posterior, lims=prior_lims, samples=train_data_accept.T, figsize=(15,15),\n",
    "         labels_params=labels_params, ticks=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## summary statistics for samples from the prior and posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = HodgkinHuxley(I=I, dt=dt, V0=obs['data'][0], seed=230+i, cython=True, prior_log=prior_log)\n",
    "\n",
    "#############################################################################\n",
    "# samples from the prior\n",
    "num_samp = 100\n",
    "params = param_invtransform(prior_log,p.gen(num_samp))\n",
    "\n",
    "sum_stats_prior = []\n",
    "for i in range(num_samp):\n",
    "    x = m.gen_single(param_transform(prior_log,params[i,:]))\n",
    "    sum_stats1 = s.calc([x])\n",
    "    sum_stats_prior.append(sum_stats1)\n",
    "\n",
    "mn_sum_stats_prior = np.nanmean(sum_stats_prior,axis=0)\n",
    "std_sum_stats_prior = np.nanstd(sum_stats_prior,axis=0)\n",
    "\n",
    "sum_stats_prior_mat = np.asarray(sum_stats_prior)\n",
    "\n",
    "#############################################################################\n",
    "# samples from the posterior\n",
    "num_samp1 = 100\n",
    "params = param_invtransform(prior_log,posterior.gen(num_samp1))\n",
    "\n",
    "# reject samples outside the prior box\n",
    "ind = (params > prior_min) & (params < prior_max)\n",
    "params = params[np.prod(ind,axis=1)==1]\n",
    "\n",
    "num_samp = len(params[:,0])\n",
    "\n",
    "sum_stats = []\n",
    "for i in range(num_samp):\n",
    "    x = m.gen_single(param_transform(prior_log,params[i,:]))\n",
    "    sum_stats1 = s.calc([x])\n",
    "    sum_stats.append(sum_stats1)\n",
    "\n",
    "mn_sum_stats = np.nanmean(sum_stats,axis=0)\n",
    "std_sum_stats = np.nanstd(sum_stats,axis=0)\n",
    "\n",
    "sum_stats_mat = np.asarray(sum_stats)\n",
    "\n",
    "sum_stats_mat1 = np.ma.array(sum_stats_mat, mask=np.isnan(sum_stats_mat))\n",
    "# cov_sum_stats = np.cov(sum_stats_mat[:,0,:], rowvar=False)\n",
    "cov_sum_stats = np.ma.cov(sum_stats_mat1[:,0,:], rowvar=False)\n",
    "\n",
    "sum_stats_min = np.min(mn_sum_stats,axis=0).reshape(-1,1)\n",
    "sum_stats_max = np.max(std_sum_stats,axis=0).reshape(-1,1)\n",
    "sum_stats_lims = np.concatenate((sum_stats_min,sum_stats_max),axis=1)\n",
    "\n",
    "\n",
    "n_summary_stats = len(mn_sum_stats[0,:])\n",
    "\n",
    "labels_sum_stats = ['sp_t','c0','c1','c2','c3','c4',\n",
    "                    'r_pot','r_pot_std','mn','m2','m3','m4','m5']\n",
    "# labels_sum_stats = ['f_rate','ISI_mn','ISI_std','AP_lat','AP_oversh','r_pot','r_pot_std','AHD','A_ind','spike_w']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "width = 0.3\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = plt.subplot()\n",
    "plt.bar(np.linspace(0,n_summary_stats-1,n_summary_stats),mn_sum_stats_prior[0,:],width,\n",
    "       yerr=std_sum_stats_prior[0,:],label='prior stats')\n",
    "plt.bar(np.linspace(0,n_summary_stats-1,n_summary_stats)+width,mn_sum_stats[0,:],width,\n",
    "       yerr=std_sum_stats[0,:],label='posterior stats')\n",
    "plt.bar(np.linspace(0,n_summary_stats-1,n_summary_stats)+2*width,obs_stats[0,:],width,label='obs stats')\n",
    "ax.set_xlim(-1.5*width,n_summary_stats+width/2)\n",
    "ax.set_xticks(np.linspace(0,n_summary_stats-1,n_summary_stats)+width/2)\n",
    "ax.set_xticklabels(labels_sum_stats)\n",
    "plt.legend(bbox_to_anchor=(1.2, 1), loc='upper right')\n",
    "plt.title('summary statistics');\n",
    "\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,16))\n",
    "for i in range(n_summary_stats):\n",
    "    plt.subplot(4,4,i+1)\n",
    "    plt.hist(sum_stats_prior_mat[~np.isnan(sum_stats_prior_mat[:,0,i]),0,i], label='prior stat')\n",
    "    plt.hist(sum_stats_mat[~np.isnan(sum_stats_mat[:,0,i]),0,i], label='posterior stat')\n",
    "    plt.plot(obs_stats[0,i],1,'o',markersize=10, label='obs stat')\n",
    "    plt.title(labels_sum_stats[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(sum_stats_mat[~np.isnan(sum_stats_mat[:,0,9]),0,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reject samples with NaNs\n",
    "# sum_stats_mat2 = sum_stats_mat[:,0,:]\n",
    "# ind = ~np.isnan(sum_stats_mat2)\n",
    "# sum_stats_mat2 = sum_stats_mat2[np.prod(ind,axis=1)==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # summary statistics from posterior\n",
    "\n",
    "# pdf1 = dd.Gaussian(m=mn_sum_stats[0], S=cov_sum_stats)\n",
    "# # pdf1 = dd.Gaussian(m=mn_sum_stats[0], S=np.diag(np.ones(n_summary_stats)))\n",
    "# plot_pdf(pdf1, lims=sum_stats_lims, samples=sum_stats_mat2.T, gt=res.obs[0],figsize=(20,20));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
