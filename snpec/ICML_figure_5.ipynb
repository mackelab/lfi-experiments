{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "base_seed = 1300\n",
    "n_seeds = 10\n",
    "\n",
    "model_id = 'lv'\n",
    "save_path = '/home/david/code/lfi-experiments/snpec/results/' + model_id\n",
    "\n",
    "use_maf = False\n",
    "\n",
    "noise_sd = 50.0  # compare to log(noise_sd) = 2.3 in Owen et al. 2014, Likelihood free inference for Makov Processes: a comparison\n",
    "\n",
    "include_initial_state = True\n",
    "\n",
    "# simulation setup\n",
    "setup_opts = {        \n",
    "    'n_hiddens': [50, 50],\n",
    "    'reg_lambda': 0.01,\n",
    "    'pilot_samples': 1000,\n",
    "    'verbose': True,\n",
    "    'prior_norm': False,    \n",
    "    'svi': False,\n",
    "    'n_rnn': 100,\n",
    "    'n_inputs_rnn': 2\n",
    "}\n",
    "\n",
    "run_opts = {\n",
    "    'n_train': 1000,\n",
    "    'n_rounds': 10,\n",
    "    'minibatch': 100,\n",
    "    'epochs': 2000,\n",
    "    'moo': 'resample',\n",
    "    'proposal': 'gaussian',\n",
    "    'n_null': None,\n",
    "    'train_on_all': True,\n",
    "    'max_norm': 0.1,\n",
    "    'val_frac': 0.1,\n",
    "    'silent_fail': False,\n",
    "    'reuse_prior_samples': True,\n",
    "}\n",
    "  \n",
    "if run_opts['train_on_all']:\n",
    "    run_opts['epochs'] = [run_opts['epochs'] // (r+1) for r in range(run_opts['n_rounds'])]\n",
    "\n",
    "if use_maf:\n",
    "    # control MAF seed\n",
    "    rng_maf = np.random\n",
    "    \n",
    "    setup_opts.update({\n",
    "        'mode': 'random',\n",
    "        'n_mades': 5,\n",
    "        'rng': rng_maf,\n",
    "        'act_fun': 'tanh',\n",
    "        'batch_norm': False\n",
    "    })\n",
    "\n",
    "pars_true = np.array([-4.60517019, -0.69314718,  0.        , -4.60517019])  # from SNL paper\n",
    "#x0 was generated by simulation using the true parameters from the SNL paper, initial state not removed, dt=0.2\n",
    "raw_data = np.array([50., 100., 59., 104.,  66., 117.,  81., 133.,  97., 131., 109., 135., 127.,\n",
    "       132., 148., 135., 163., 125., 188., 108., 217.,  95., 239.,  75.,\n",
    "       236.,  60., 235.,  46., 228.,  34., 217.,  28., 211.,  18., 193.,\n",
    "        12., 175.,   8., 171.,   9., 162.,   5., 151.,   5., 136.,   6.,\n",
    "       128.,   6., 111.,   8., 110.,   8.,  96.,   8.,  95.,   9.,  93.,\n",
    "         9.,  81.,  10.,  80.,  11.,  78.,  17.,  74.,  17.,  72.,  19.,\n",
    "        66.,  20.,  67.,  25.,  64.,  29.,  54.,  30.,  55.,  45.,  54.,\n",
    "        45.,  53.,  48.,  48.,  50.,  54.,  65.,  61.,  75.,  64.,  77.,\n",
    "        65.,  95.,  73., 106.,  85., 107.,  88., 114., 104., 113., 130.,\n",
    "       114., 159., 110., 173.,  95., 196.,  77., 220.,  72., 219.,  49.,\n",
    "       212.,  33., 209.,  24., 196.,  18., 188.,  18., 176.,  17., 166.,\n",
    "        15., 158.,  14., 154.,  10., 138.,  13., 128.,  11., 119.,  11.,\n",
    "       107.,   9.,  99.,   8.,  94.,  11.,  86.,  11.,  81.,  12.,  78.,\n",
    "        15.,  67.,  19.,  63.,  16.,  58.,  20.,  58.,  28.,  57.,  36.,\n",
    "        53.,  39.,  55.,  44.,  53.,  44.,  55.,  44.,  54.,  49.,  54.,\n",
    "        66.,  54.,  77.,  53.,  93.,  64.,  98.,  76., 100.,  94., 110.,\n",
    "       116., 112., 136., 102., 149., 105., 173., 103., 200.,  95., 208.,\n",
    "        69., 224.,  54., 232.,  47., 217.,  40., 206.,  29., 202.,  24.,\n",
    "       196.,  24., 181.,  23., 167.,  13., 158.,  14., 147.,   9., 135.,\n",
    "         8., 121.,   9., 111.,   8.,  95.,  10.,  84.,  10.,  73.,  11.,\n",
    "        68.,  14.,  61.,  16.,  57.,  20.,  50.,  19.,  46.,  25.,  43.,\n",
    "        33.,  41.,  38.,  42.,  40.,  45.,  50.,  48.,  57.,  48.,  60.,\n",
    "        47.,  63.,  49.,  68.,  48.,  66.,  42.,  71.,  43.,  84.,  46.,\n",
    "        81.,  40.,  89.,  45., 121.,  55., 134.,  67., 136.,  83., 135.,\n",
    "       100., 142., 129., 135., 148., 134., 163., 130., 182., 111., 195.,\n",
    "       106., 206.,  93., 216.,  67., 224.,  47., 207.,  33., 202.,  24.,\n",
    "       193.,  20., 182.,  14., 174.,   8., 161.,   8., 152.,   4., 140.,\n",
    "         6., 131.,   5.])\n",
    "raw_data += np.random.randn(*raw_data.shape) * noise_sd\n",
    "obs = raw_data if include_initial_state else raw_data[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import timeit\n",
    "from copy import deepcopy\n",
    "from delfi.utils.progress import no_tqdm, progressbar\n",
    "\n",
    "from delfi.utils.viz import plot_pdf\n",
    "import delfi.inference as infer\n",
    "import delfi.distribution as dd\n",
    "import delfi.generator\n",
    "from delfi.summarystats import Identity\n",
    "\n",
    "from lfimodels.snl_exps.util import save_results, load_results, StubbornGenerator, stubborn_defaultrej\n",
    "from lfimodels.snl_exps.util import  save_results_byname, load_results_byname\n",
    "from lfimodels.snl_exps.util import init_g_lv as init_g\n",
    "from lfimodels.snl_exps.util import load_setup_lv as load_setup\n",
    "from lfimodels.snl_exps.util import load_gt_lv as load_gt\n",
    "from lfimodels.snl_exps.util import calc_all_lprob_errs\n",
    "from lfimodels.snl_exps.LotkaVolterra import LotkaVolterra, LotkaVolterraStats\n",
    "import snl.simulators.lotka_volterra as sim_lv\n",
    "from snl.util.plot import plot_hist_marginals\n",
    "\n",
    "print('pars_true : ', pars_true)\n",
    "\n",
    "dt = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gaussian_sequence(x, ps, **kwargs):\n",
    "    m = np.array([p.xs[0].m[k] for p in ps])\n",
    "    s = np.array([np.sqrt(p.xs[0].S[k, k]) for p in ps])\n",
    "    return plt.fill_between(x, m - s, m + s, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare rnn and stats with and without no noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "exp_ids_rnn_nonoise = [d for d in os.listdir(save_path) if d.startswith('rnn_nonoise_seed23')]\n",
    "prnn_nonoise = []\n",
    "for exp_id in exp_ids_rnn_nonoise:\n",
    "    try:\n",
    "        pstats, Vstats = load_results_byname(exp_id=exp_id, path=save_path)\n",
    "    except:\n",
    "        continue\n",
    "    del Vstats\n",
    "    if type(pstats[0]) is list:        \n",
    "        #assert len(pstats) == 1\n",
    "        pstats = pstats[-1]\n",
    "    prnn_nonoise.append(pstats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_ids_stats_nonoise = [d for d in os.listdir(save_path) if d.startswith('stats_fc_nonoise_seed23')]\n",
    "pstats_nonoise = []\n",
    "for exp_id in exp_ids_stats_nonoise:\n",
    "    try:\n",
    "        pstats, Vstats = load_results_byname(exp_id=exp_id, path=save_path)\n",
    "    except:\n",
    "        continue\n",
    "    del Vstats\n",
    "    if type(pstats[0]) is list:\n",
    "        #assert len(pstats) == 1\n",
    "        pstats = pstats[-1]\n",
    "    pstats_nonoise.append(pstats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_ids_rnn_noise = [d for d in os.listdir(save_path) if d.startswith('rnn_noise_seed13')]\n",
    "prnn_noise = []\n",
    "for exp_id in exp_ids_rnn_noise:\n",
    "    try:\n",
    "        pstats, Vstats = load_results_byname(exp_id=exp_id, path=save_path)\n",
    "    except:\n",
    "        continue\n",
    "    del Vstats\n",
    "    if type(pstats[0]) is list:\n",
    "        #assert len(pstats) == 1\n",
    "        pstats = pstats[-1]\n",
    "    prnn_noise.append(pstats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_ids_stats_noise = [d for d in os.listdir(save_path) if d.startswith('stats_fc_noise_seed13')]\n",
    "pstats_noise = []\n",
    "for exp_id in exp_ids_stats_noise:\n",
    "    try:\n",
    "        pstats, Vstats = load_results_byname(exp_id=exp_id, path=save_path)\n",
    "    except:\n",
    "        continue\n",
    "    del Vstats\n",
    "    if type(pstats[0]) is list:\n",
    "        assert len(pstats) == 1\n",
    "        pstats = pstats[0]\n",
    "    pstats_noise.append(pstats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "rnn_color = 'teal'\n",
    "stats_color = 'violet'\n",
    "\n",
    "dim_param = pars_true.size\n",
    "figh = plt.figure(figsize=(16,6))\n",
    "for k in range(dim_param):\n",
    "    ax = plt.subplot(2, dim_param, k+1)    \n",
    "    for i, pps in enumerate(pstats_nonoise):\n",
    "        nsamples = run_opts['n_train'] * (1.0 + np.arange(len(pps)))\n",
    "        hstats = plot_gaussian_sequence(nsamples, pps, color=stats_color, alpha=alpha)#, label='stats')\n",
    "        plt.plot(nsamples, [p.xs[0].mean[k] for p in pps], color=stats_color)\n",
    "    for i, pps in enumerate(prnn_nonoise):\n",
    "        nsamples = run_opts['n_train'] * (1.0 + np.arange(len(pps)))\n",
    "        hrnn = plot_gaussian_sequence(nsamples, pps, color=rnn_color, alpha=alpha)#, label='rnn')\n",
    "        plt.plot(nsamples, [p.xs[0].mean[k] for p in pps], color=rnn_color)\n",
    "    plt.plot(plt.xlim(), np.ones(2) * pars_true[k],'k')\n",
    "    plt.ylim(pars_true[k] + np.array([-1., 1.]) * .5)\n",
    "    plt.xlim([0, 10000])\n",
    "    plt.xlabel('Simulations')\n",
    "    plt.ylabel('$\\\\theta_{0}$'.format(k))\n",
    "    ax.set_aspect(10000.)\n",
    "    if k == 0:\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.title('Observationn noise $\\\\sigma = 0$')\n",
    "\n",
    "    ax = plt.subplot(2, dim_param, k+1 + dim_param)    \n",
    "    for i, pps in enumerate(pstats_noise):\n",
    "        nsamples = run_opts['n_train'] * (1.0 + np.arange(len(pps)))\n",
    "        hstats = plot_gaussian_sequence(nsamples, pps, color=stats_color, alpha=alpha)#, label='stats')\n",
    "        plt.plot(nsamples, [p.xs[0].mean[k] for p in pps], color=stats_color)\n",
    "    for i, pps in enumerate(prnn_noise):\n",
    "        nsamples = run_opts['n_train'] * (1.0 + np.arange(len(pps)))\n",
    "        hrnn = plot_gaussian_sequence(nsamples, pps, color=rnn_color, alpha=alpha)#, label='rnn')\n",
    "        plt.plot(nsamples, [p.xs[0].mean[k] for p in pps], color=rnn_color)\n",
    "    plt.plot(plt.xlim(), np.ones(2) * pars_true[k],'k')\n",
    "    plt.ylim(pars_true[k] + np.array([-1., 1.]) * 5)\n",
    "    plt.xlim([0, 10000])\n",
    "    plt.xlabel('Simulations')\n",
    "    plt.ylabel('$\\\\theta_{0}$'.format(k))\n",
    "    ax.set_aspect(1000.)\n",
    "    if k == 0:\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.title('Observationn noise $\\\\sigma = 50$')\n",
    "figh.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for ii in range(10):\n",
    "\n",
    "    print('\\n')\n",
    "    print(str(ii))\n",
    "    print('\\n')\n",
    "    \n",
    "    round_to_plot = 10\n",
    "    g=g_rnn\n",
    "\n",
    "    g2 = deepcopy(g)\n",
    "    g2.proposal = prnn_nonoise[ii][round_to_plot - 1]\n",
    "    samples_rnn= np.array(g2.draw_params(5000)) \n",
    "\n",
    "    fig = plot_hist_marginals(samples_rnn,\n",
    "                            gt=pars_true.flatten(),\n",
    "                            lims=[[-5,2],[-5,2],[-5,2],[-5,2]])\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "    g2 = deepcopy(g)\n",
    "    g2.proposal = pstats_nonoise[ii][round_to_plot - 1]\n",
    "    samples_ss =  np.array(g2.draw_params(5000)) \n",
    "\n",
    "    fig = plot_hist_marginals(samples_ss,\n",
    "                            gt=pars_true.flatten(),\n",
    "                            lims=[[-5,2],[-5,2],[-5,2],[-5,2]])\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "g2 = deepcopy(g)\n",
    "g2.proposal = prnn_noise[ii][round_to_plot - 1]\n",
    "samples_noise = np.array(g2.draw_params(5000)) \n",
    "\n",
    "_ = plot_hist_marginals(samples_noise,\n",
    "                        gt=pars_true.flatten(),\n",
    "                        lims=[[-5,2],[-5,2],[-5,2],[-5,2]])\n",
    "fig.show()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "figh = plt.figure(figsize=(16,6))\n",
    "\n",
    "round_plot = 10\n",
    "for k in range(dim_param):\n",
    "    xx = pars_true[k] + np.linspace(-1., 1., 5000) * 2\n",
    "    \n",
    "    plt.subplot(2, 4, k + 1)\n",
    "    for p in pstats_nonoise: \n",
    "        m = p[round_plot - 1].xs[0].m[k]\n",
    "        V = p[round_plot - 1].xs[0].S[k,k]\n",
    "        y = scipy.stats.norm.pdf(xx, m, np.sqrt(V))\n",
    "        plt.plot(xx, y, color=stats_color)\n",
    "    plt.xlabel('$\\\\theta_{0}$'.format(k))\n",
    "    if k == 0:\n",
    "        #plt.ylabel('$q_{F(x,\\\\phi)}(\\\\theta)$')\n",
    "        plt.ylabel('$\\\\sigma = 0$')\n",
    "        \n",
    "    for p in prnn_nonoise: \n",
    "        m = p[round_plot - 1].xs[0].m[k]\n",
    "        V = p[round_plot - 1].xs[0].S[k,k]\n",
    "        y = scipy.stats.norm.pdf(xx, m, np.sqrt(V))\n",
    "        plt.plot(xx, y, color=rnn_color)\n",
    "        \n",
    "    plt.subplot(2, 4, 4 + k + 1)\n",
    "    for p in pstats_noise: \n",
    "        m = p[round_plot - 1].xs[0].m[k]\n",
    "        V = p[round_plot - 1].xs[0].S[k,k]\n",
    "        y = scipy.stats.norm.pdf(xx, m, np.sqrt(V))\n",
    "        plt.plot(xx, y, color=stats_color)\n",
    "    plt.xlabel('$\\\\theta_{0}$'.format(k))\n",
    "    if k == 0:\n",
    "        #plt.ylabel('$q_{F(x,\\\\phi)}(\\\\theta)$')\n",
    "        plt.ylabel('$\\\\sigma = 50$')\n",
    "\n",
    "        \n",
    "    for p in prnn_noise: \n",
    "        m = p[round_plot - 1].xs[0].m[k]\n",
    "        V = p[round_plot - 1].xs[0].S[k,k]\n",
    "        y = scipy.stats.norm.pdf(xx, m, np.sqrt(V))\n",
    "        plt.plot(xx, y, color=rnn_color)\n",
    "        \n",
    "for k in range(dim_param):\n",
    "    plt.subplot(2, 4, k + 1)\n",
    "    YL = plt.ylim()\n",
    "    plt.plot(pars_true[k] * np.ones(2), YL, 'r')\n",
    "    plt.ylim(YL)\n",
    "    plt.subplot(2, 4, 4 + k + 1)\n",
    "    plt.plot(pars_true[k] * np.ones(2), plt.ylim(), 'r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_alpha = 0.2\n",
    "\n",
    "max_rounds = 10\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "y = np.hstack([np.array([-pp.eval(pars_true.reshape(1, -1), log=True) for pp in ps])[:max_rounds] for ps in prnn_nonoise])\n",
    "m_rnn_nonoise = y.mean(axis=1)\n",
    "s_rnn_nonoise = y.std(axis=1)\n",
    "y = np.hstack([np.array([-pp.eval(pars_true.reshape(1, -1), log=True) for pp in ps])[:max_rounds] for ps in prnn_noise])\n",
    "m_rnn_noise = y.mean(axis=1)\n",
    "s_rnn_noise = y.std(axis=1)\n",
    "y = np.hstack([np.array([-pp.eval(pars_true.reshape(1, -1), log=True) for pp in ps])[:max_rounds] for ps in pstats_nonoise])\n",
    "m_stats_nonoise = y.mean(axis=1)\n",
    "s_stats_nonoise = y.std(axis=1)\n",
    "y = np.hstack([np.array([-pp.eval(pars_true.reshape(1, -1), log=True) for pp in ps])[:max_rounds] for ps in pstats_noise])\n",
    "m_stats_noise = y.mean(axis=1)\n",
    "s_stats_noise = y.std(axis=1)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "m, s, c = m_stats_nonoise, s_stats_nonoise, stats_color\n",
    "plt.fill_between(nsamples, m-s, m + s, color=c, alpha=fill_alpha)\n",
    "\n",
    "m, s, c = m_rnn_nonoise, s_rnn_nonoise, rnn_color\n",
    "plt.fill_between(nsamples, m-s, m + s, color=c, alpha=fill_alpha)\n",
    "\n",
    "plt.plot(nsamples, m_stats_nonoise, color=stats_color, marker='.')\n",
    "plt.plot(nsamples, m_rnn_nonoise, color=rnn_color,marker='.')\n",
    "\n",
    "plt.xlabel('samples')\n",
    "plt.ylabel('-log p(true params)')\n",
    "plt.title('noise 0')\n",
    "plt.xlim([0, 10000])\n",
    "plt.ylim([-5, 40])\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "m, s, c = m_stats_noise, s_stats_noise, stats_color\n",
    "plt.fill_between(nsamples, m-s, m + s, color=c, alpha=fill_alpha)\n",
    "\n",
    "m, s, c = m_rnn_noise, s_rnn_noise, rnn_color\n",
    "plt.fill_between(nsamples, m-s, m + s, color=c, alpha=fill_alpha)\n",
    "\n",
    "plt.plot(nsamples, m_stats_noise, color=stats_color,marker='.')\n",
    "plt.plot(nsamples, m_rnn_noise, color=rnn_color, marker='.')\n",
    "\n",
    "plt.xlabel('samples')\n",
    "plt.ylabel('-log p(true params)')\n",
    "plt.title('noise 50')\n",
    "plt.xlim([0, 10000])\n",
    "plt.ylim([-5, 40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for i, ps in enumerate(prnn_nonoise):\n",
    "    nsamples = run_opts['n_train'] * (1.0 + np.arange(len(ps)))\n",
    "    plt.plot(nsamples, [-pp.eval(pars_true.reshape(1, -1), log=True) for pp in ps], color=rnn_color)\n",
    "for i, ps in enumerate(pstats_nonoise):\n",
    "    nsamples = run_opts['n_train'] * (1.0 + np.arange(len(ps)))\n",
    "    plt.plot(nsamples, [-pp.eval(pars_true.reshape(1, -1), log=True) for pp in ps], color=stats_color)    \n",
    "plt.title('noise 0')\n",
    "plt.xlim([0, 10000])\n",
    "plt.ylim([-5, 20])\n",
    "\n",
    "plt.figure()\n",
    "for i, ps in enumerate(prnn_noise):\n",
    "    nsamples = run_opts['n_train'] * (1.0 + np.arange(len(ps)))\n",
    "    plt.plot(nsamples, [-pp.eval(pars_true.reshape(1, -1), log=True) for pp in ps], color=rnn_color)\n",
    "for i, ps in enumerate(pstats_noise):\n",
    "    nsamples = run_opts['n_train'] * (1.0 + np.arange(len(ps)))\n",
    "    plt.plot(nsamples, [-pp.eval(pars_true.reshape(1, -1), log=True) for pp in ps], color=stats_color)    \n",
    "plt.title('noise 50')\n",
    "plt.xlim([0, 10000])\n",
    "plt.ylim([-5, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=42\n",
    "\n",
    "n_steps_used=(raw_data.shape[0] - 2)// 2\n",
    "assert (n_steps_used + int(include_initial_state)) * 2 == obs.shape[0]\n",
    "model = LotkaVolterra(dt=dt, duration=dt * n_steps_used, seed=seed, max_n_steps=50000, noise_sd=noise_sd)\n",
    "prior = dd.Uniform(lower= [-5,-5,-5,-5], upper = [2,2,2,2], seed=seed)\n",
    "summary = Identity(seed=seed)\n",
    "g_rnn = StubbornGenerator(model=model, prior=prior, summary=summary, seed=seed)\n",
    "\n",
    "n_steps_used=(raw_data.shape[0] - 2)// 2\n",
    "assert (n_steps_used + int(include_initial_state)) * 2 == obs.shape[0]\n",
    "model = LotkaVolterra(dt=dt, duration=dt * n_steps_used, seed=seed, max_n_steps=50000, noise_sd=noise_sd)\n",
    "prior = dd.Uniform(lower= [-5,-5,-5,-5], upper = [2,2,2,2], seed=seed)\n",
    "summary = LotkaVolterraStats(seed=seed)\n",
    "g_stats = StubbornGenerator(model=model, prior=prior, summary=summary, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit\n",
    "import os\n",
    "\n",
    "import delfi.distribution as dd\n",
    "import delfi.inference as infer\n",
    "import delfi.generator as dg\n",
    "\n",
    "from delfi.simulator import TwoMoons\n",
    "import delfi.summarystats as ds\n",
    "from delfi.utils.viz import plot_pdf, probs2contours\n",
    "\n",
    "from lfimodels.snl_exps.util import save_results, load_results\n",
    "from lfimodels.snl_exps.util import draw_sample_uniform_prior_52, load_gt_lv, init_g_lv\n",
    "from snl.util.plot import plot_hist_marginals\n",
    "\n",
    "from inspect import getmembers, isclass\n",
    "\n",
    "fig_path = 'results/figs/'\n",
    "fontsize = 16\n",
    "\n",
    "def rasterize_and_save(fname, rasterize_list=None, fig=None, dpi=None,\n",
    "                       savefig_kw={}):\n",
    "    \"\"\"Save a figure with raster and vector components\n",
    "    This function lets you specify which objects to rasterize at the export\n",
    "    stage, rather than within each plotting call. Rasterizing certain\n",
    "    components of a complex figure can significantly reduce file size.\n",
    "    Inputs\n",
    "    ------\n",
    "    fname : str\n",
    "        Output filename with extension\n",
    "    rasterize_list : list (or object)\n",
    "        List of objects to rasterize (or a single object to rasterize)\n",
    "    fig : matplotlib figure object\n",
    "        Defaults to current figure\n",
    "    dpi : int\n",
    "        Resolution (dots per inch) for rasterizing\n",
    "    savefig_kw : dict\n",
    "        Extra keywords to pass to matplotlib.pyplot.savefig\n",
    "    If rasterize_list is not specified, then all contour, pcolor, and\n",
    "    collects objects (e.g., ``scatter, fill_between`` etc) will be\n",
    "    rasterized\n",
    "    Note: does not work correctly with round=True in Basemap\n",
    "    Example\n",
    "    -------\n",
    "    Rasterize the contour, pcolor, and scatter plots, but not the line\n",
    "    >>> import matplotlib.pyplot as plt\n",
    "    >>> from numpy.random import random\n",
    "    >>> X, Y, Z = random((9, 9)), random((9, 9)), random((9, 9))\n",
    "    >>> fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(ncols=2, nrows=2)\n",
    "    >>> cax1 = ax1.contourf(Z)\n",
    "    >>> cax2 = ax2.scatter(X, Y, s=Z)\n",
    "    >>> cax3 = ax3.pcolormesh(Z)\n",
    "    >>> cax4 = ax4.plot(Z[:, 0])\n",
    "    >>> rasterize_list = [cax1, cax2, cax3]\n",
    "    >>> rasterize_and_save('out.svg', rasterize_list, fig=fig, dpi=300)\n",
    "    \"\"\"\n",
    "\n",
    "    # Behave like pyplot and act on current figure if no figure is specified\n",
    "    fig = plt.gcf() if fig is None else fig\n",
    "\n",
    "    # Need to set_rasterization_zorder in order for rasterizing to work\n",
    "    zorder = -5  # Somewhat arbitrary, just ensuring less than 0\n",
    "\n",
    "    if rasterize_list is None:\n",
    "        # Have a guess at stuff that should be rasterised\n",
    "        types_to_raster = ['QuadMesh', 'Contour', 'collections']\n",
    "        rasterize_list = []\n",
    "\n",
    "        print(\"\"\"\n",
    "        No rasterize_list specified, so the following objects will\n",
    "        be rasterized: \"\"\")\n",
    "        # Get all axes, and then get objects within axes\n",
    "        for ax in fig.get_axes():\n",
    "            for item in ax.get_children():\n",
    "                if any(x in str(item) for x in types_to_raster):\n",
    "                    rasterize_list.append(item)\n",
    "        print('\\n'.join([str(x) for x in rasterize_list]))\n",
    "    else:\n",
    "        # Allow rasterize_list to be input as an object to rasterize\n",
    "        if type(rasterize_list) != list:\n",
    "            rasterize_list = [rasterize_list]\n",
    "\n",
    "    for item in rasterize_list:\n",
    "\n",
    "        # Whether or not plot is a contour plot is important\n",
    "        is_contour = (isinstance(item, matplotlib.contour.QuadContourSet) or\n",
    "                      isinstance(item, matplotlib.tri.TriContourSet))\n",
    "\n",
    "        # Whether or not collection of lines\n",
    "        # This is commented as we seldom want to rasterize lines\n",
    "        # is_lines = isinstance(item, matplotlib.collections.LineCollection)\n",
    "\n",
    "        # Whether or not current item is list of patches\n",
    "        all_patch_types = tuple(\n",
    "            x[1] for x in getmembers(matplotlib.patches, isclass))\n",
    "        try:\n",
    "            is_patch_list = isinstance(item[0], all_patch_types)\n",
    "        except TypeError:\n",
    "            is_patch_list = False\n",
    "\n",
    "        # Convert to rasterized mode and then change zorder properties\n",
    "        if is_contour:\n",
    "            curr_ax = item.ax.axes\n",
    "            curr_ax.set_rasterization_zorder(zorder)\n",
    "            # For contour plots, need to set each part of the contour\n",
    "            # collection individually\n",
    "            for contour_level in item.collections:\n",
    "                contour_level.set_zorder(zorder - 1)\n",
    "                contour_level.set_rasterized(True)\n",
    "        elif is_patch_list:\n",
    "            # For list of patches, need to set zorder for each patch\n",
    "            for patch in item:\n",
    "                curr_ax = patch.axes\n",
    "                curr_ax.set_rasterization_zorder(zorder)\n",
    "                patch.set_zorder(zorder - 1)\n",
    "                patch.set_rasterized(True)\n",
    "        else:\n",
    "            # For all other objects, we can just do it all at once\n",
    "            curr_ax = item.axes\n",
    "            curr_ax.set_rasterization_zorder(zorder)\n",
    "            item.set_rasterized(True)\n",
    "            item.set_zorder(zorder - 1)\n",
    "\n",
    "    # dpi is a savefig keyword argument, but treat it as special since it is\n",
    "    # important to this function\n",
    "    if dpi is not None:\n",
    "        savefig_kw['dpi'] = dpi\n",
    "\n",
    "    # Save resulting figure\n",
    "    fig.savefig(fname, **savefig_kw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'results/lv_validationset/'\n",
    "\n",
    "plot_seed = 42\n",
    "exp_id = 'seed' + str(plot_seed)\n",
    "pars_true, obs_stats = load_gt_lv(init_g_lv(seed=plot_seed))\n",
    "pnl_a = plot_hist_marginals(samples_rnn, gt=pars_true.flatten(), lims=[-5,2])\n",
    "pnl_a.set_figwidth(5)\n",
    "pnl_a.set_figheight(5)\n",
    "for ax in pnl_a.axes:\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "#    ax.axis('off')\n",
    "    \n",
    "pnl_a.axes[-4].set_xlabel(r'$\\theta_1$', fontsize=fontsize)\n",
    "pnl_a.axes[-3].set_xlabel(r'$\\theta_2$', fontsize=fontsize)\n",
    "pnl_a.axes[-2].set_xlabel(r'$\\theta_3$', fontsize=fontsize)    \n",
    "pnl_a.axes[-1].set_xlabel(r'$\\theta_4$', fontsize=fontsize)        \n",
    "    \n",
    "PANEL_5A = fig_path +'fig5_a.svg'\n",
    "\n",
    "savefig_kw = {\n",
    "'facecolor' : plt.gcf().get_facecolor(), \n",
    "'transparent' : True,\n",
    "'bbox_inches' : 'tight' \n",
    "}\n",
    "rasterize_and_save(PANEL_5A, rasterize_list=[pnl_a.axes[i] for i in [1,3,4,6,7,8]], fig=pnl_a, dpi=600, savefig_kw=savefig_kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'results/lv_validationset/'\n",
    "\n",
    "plot_seed = 42\n",
    "exp_id = 'seed' + str(plot_seed)\n",
    "pars_true, obs_stats = load_gt_lv(init_g_lv(seed=plot_seed))\n",
    "pnl_c = plot_hist_marginals(samples_ss, gt=pars_true.flatten(), lims=[-5,2], upper=True)\n",
    "pnl_c.set_figwidth(5)\n",
    "pnl_c.set_figheight(5)\n",
    "for ax in pnl_c.axes:\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "#    ax.axis('off')\n",
    "    \n",
    "pnl_c.axes[0].set_xlabel(r'$\\theta_1$', fontsize=fontsize)\n",
    "pnl_c.axes[4].set_xlabel(r'$\\theta_2$', fontsize=fontsize)\n",
    "pnl_c.axes[7].set_xlabel(r'$\\theta_3$', fontsize=fontsize)    \n",
    "pnl_c.axes[-1].set_xlabel(r'$\\theta_4$', fontsize=fontsize)        \n",
    "    \n",
    "PANEL_5C = fig_path +'fig5_c.svg'\n",
    "\n",
    "savefig_kw = {\n",
    "'facecolor' : plt.gcf().get_facecolor(), \n",
    "'transparent' : True,\n",
    "'bbox_inches' : 'tight' \n",
    "}\n",
    "rasterize_and_save(PANEL_5C, rasterize_list=[pnl_c.axes[i] for i in [1,2,3,5,6,8]], fig=pnl_c, dpi=600, savefig_kw=savefig_kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "figh = plt.figure(figsize=(8,5))\n",
    "\n",
    "round_plot = 10\n",
    "for k in range(dim_param):\n",
    "    xx = np.linspace(-5,2,5000) #pars_true[k] + np.linspace(-1., 1., 5000) * 2\n",
    "    \n",
    "    ax = plt.subplot(2, 4, k + 1)\n",
    "    for p in pstats_nonoise: \n",
    "        m = p[round_plot - 1].xs[0].m[k]\n",
    "        V = p[round_plot - 1].xs[0].S[k,k]\n",
    "        y = scipy.stats.norm.pdf(xx, m, np.sqrt(V))\n",
    "        plt.plot(xx, y, color=stats_color, linewidth=1.5)\n",
    "        plt.xticks([])\n",
    "        \n",
    "    #plt.xlabel('$\\\\theta_{0}$'.format(k))\n",
    "    if k == 0:\n",
    "        #plt.ylabel('$q_{F(x,\\\\phi)}(\\\\theta)$')\n",
    "        plt.ylabel('$\\\\sigma = 0$', fontsize=13)\n",
    "        plt.ylim([-0.05, 5])\n",
    "    plt.yticks([])\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.xaxis.set_ticks_position('bottom') \n",
    "\n",
    "    for p in prnn_nonoise: \n",
    "        m = p[round_plot - 1].xs[0].m[k]\n",
    "        V = p[round_plot - 1].xs[0].S[k,k]\n",
    "        y = scipy.stats.norm.pdf(xx, m, np.sqrt(V))\n",
    "        plt.plot(xx, y, color=rnn_color, linewidth=1.5)\n",
    "        plt.ylim([-0.05, 5])\n",
    "        \n",
    "    ax=plt.subplot(2, 4, 4 + k + 1)\n",
    "    for p in pstats_noise: \n",
    "        m = p[round_plot - 1].xs[0].m[k]\n",
    "        V = p[round_plot - 1].xs[0].S[k,k]\n",
    "        y = scipy.stats.norm.pdf(xx, m, np.sqrt(V))\n",
    "        plt.plot(xx, y, color=stats_color, linewidth=1.5)\n",
    "    plt.xlabel('$\\\\theta_{0}$'.format(k), fontsize=13)\n",
    "    if k == 0:\n",
    "        #plt.ylabel('$q_{F(x,\\\\phi)}(\\\\theta)$')\n",
    "        plt.ylabel('$\\\\sigma = 50$', fontsize=13)\n",
    "        plt.ylim([-0.05, 5])\n",
    "    plt.yticks([])\n",
    "    #plt.box('off')\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.xaxis.set_ticks_position('bottom')    \n",
    "    plt.xticks([-5, 2], fontsize=12)\n",
    "\n",
    "\n",
    "        \n",
    "    for p in prnn_noise: \n",
    "        m = p[round_plot - 1].xs[0].m[k]\n",
    "        V = p[round_plot - 1].xs[0].S[k,k]\n",
    "        y = scipy.stats.norm.pdf(xx, m, np.sqrt(V))\n",
    "        plt.plot(xx, y, color=rnn_color, linewidth=1.5)\n",
    "        plt.ylim([-0.05, 3])\n",
    "        \n",
    "for k in range(dim_param):\n",
    "    plt.subplot(2, 4, k + 1)\n",
    "    YL = plt.ylim()\n",
    "    plt.plot(pars_true[k] * np.ones(2), YL, 'r')\n",
    "    plt.ylim(YL)\n",
    "    plt.subplot(2, 4, 4 + k + 1)\n",
    "    plt.plot(pars_true[k] * np.ones(2), plt.ylim(), 'r')\n",
    "\n",
    "PANEL_5B = fig_path +'fig5_b.svg'\n",
    "figh.savefig(PANEL_5B, facecolor=plt.gcf().get_facecolor(), transparent=True, bbox_inches='tight')\n",
    "figh.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ./common.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIGURE and GRID\n",
    "FIG_HEIGHT_MM = 104\n",
    "FIG_WIDTH_MM = 80  # set in NIPS2017 notebook to a default value for all figures\n",
    "\n",
    "FIG_N_ROWS = 2\n",
    "ROW_1_NCOLS = 2\n",
    "ROW_1_HEIGHT_MM =      1.2 * (FIG_HEIGHT_MM / FIG_N_ROWS )\n",
    "ROW_1_WIDTH_COL_1_MM =  1.5* (FIG_WIDTH_MM / ROW_1_NCOLS)\n",
    "\n",
    "ROW_2_NCOLS = 2\n",
    "ROW_2_HEIGHT_MM = 0.8 * FIG_HEIGHT_MM / FIG_N_ROWS\n",
    "ROW_2_WIDTH_COL_1_MM = FIG_WIDTH_MM / ROW_2_NCOLS\n",
    "ROW_2_WIDTH_COL_2_MM = FIG_WIDTH_MM / ROW_2_NCOLS\n",
    "\n",
    "\n",
    "fig = create_fig(FIG_WIDTH_MM, FIG_HEIGHT_MM)\n",
    "\n",
    "\n",
    "fig = add_svg(fig, PANEL_5A, \n",
    "              3, \n",
    "              0)\n",
    "fig = add_label(fig, \n",
    "                'a)', \n",
    "                0, \n",
    "                3.5)\n",
    "\n",
    "fig = add_svg(fig, PANEL_5C, \n",
    "              31, \n",
    "              0)\n",
    "fig = add_label(fig, \n",
    "                'b)', \n",
    "                28, \n",
    "                3.5)\n",
    "\n",
    "\n",
    "fig = add_svg(fig, PANEL_5B, \n",
    "              0,\n",
    "              50) \n",
    "fig = add_label(fig, \n",
    "                'c)', \n",
    "                0, \n",
    "                53.5)\n",
    "fig = add_label(fig, \n",
    "                'd)', \n",
    "                0, \n",
    "                78)\n",
    "\n",
    "\n",
    "\n",
    "PATH_SVG = PATH_DROPBOX_FIGS + 'fig5.svg'\n",
    "fig.save(PATH_SVG)\n",
    "svg(PATH_SVG)\n",
    "!$INKSCAPE --export-pdf $PATH_DROPBOX_FIGS/fig5.pdf $PATH_SVG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
