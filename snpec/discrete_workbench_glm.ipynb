{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLM\n",
    "\n",
    "\n",
    "- GLM example as simple multivariate posterior estimation problem with available ground-truth (MCMC)\n",
    "- setup and code from NIPS 2017 paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import delfi.distribution as dd\n",
    "import delfi.generator as dg\n",
    "import delfi.inference as infer\n",
    "import delfi.utils.io as io\n",
    "import delfi.summarystats as ds\n",
    "import lfimodels.glm.utils as utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from lfimodels.glm.GLM import GLM\n",
    "from lfimodels.glm.GLMStats import GLMStats\n",
    "from delfi.utils.viz import plot_pdf\n",
    "\n",
    "import sys\n",
    "import timeit\n",
    "\n",
    "import snl.inference.mcmc as mcmc\n",
    "from lfimodels.snl_exps.util import calc_all_mmds\n",
    "\n",
    "import snl.inference.diagnostics.two_sample as two_sample\n",
    "from snl.util import math\n",
    "\n",
    "import snl.inference.nde as nde\n",
    "from snl.ml.models.mafs import ConditionalMaskedAutoregressiveFlow\n",
    "from delfi.utils.delfi2snl import SNLprior, SNLmodel\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# load setup from NIPS 2017 paper\n",
    "\n",
    "len_filter = 9 # number of GLM filter parameters (= dim. of parameters)\n",
    "duration = 100 # simulation length (longer = tighter posteriors)\n",
    "\n",
    "true_params, labels_params = utils.obs_params(len_filter)\n",
    "\n",
    "# basic approach to controlling generator seeds\n",
    "def init_g(seed):\n",
    "    m = GLM(seed=seed, duration=duration, len_filter=len_filter)\n",
    "    #m.I = I\n",
    "    #p = dd.Uniform(lower=[-3,-3,-3,-3,-3,-3,-3,-3,-3,-3], upper=[3,3,3,3,3,3,3,3,3,3])\n",
    "    p = utils.smoothing_prior(n_params=m.n_params, seed=seed)\n",
    "    s = GLMStats(n_summary=m.n_params)\n",
    "    return dg.Default(model=m, prior=p, summary=s)\n",
    "\n",
    "# SNPE parameters\n",
    "\n",
    "# training schedule\n",
    "n_train=5000\n",
    "n_rounds=5\n",
    "\n",
    "# fitting setup\n",
    "minibatch=100\n",
    "epochs=1000\n",
    "\n",
    "# network setup\n",
    "n_hiddens=[50,50]\n",
    "reg_lambda=0.01\n",
    "\n",
    "# convenience\n",
    "pilot_samples=1000\n",
    "svi=False\n",
    "verbose=True\n",
    "prior_norm=False\n",
    "val_frac = 0.1\n",
    "\n",
    "# MAF parameters\n",
    "mode='random' # ordering of variables for MADEs\n",
    "n_mades = 5 # number of MADES\n",
    "act_fun = 'tanh'\n",
    "batch_norm = False # batch-normalization currently not supported\n",
    "train_on_all = True # now supported feature\n",
    "\n",
    "# MDN parameters\n",
    "n_components = 8\n",
    "\n",
    "# number of samples for MMD computation\n",
    "N = 5000\n",
    "\n",
    "def calc_all_mmds_snl(samples_true, samples_snl):\n",
    "    \"\"\" only called for 'Gaussian' simulator \"\"\"\n",
    "\n",
    "    all_mmds = []\n",
    "    ct = 0\n",
    "    for samples in samples_snl:\n",
    "        \n",
    "        ct += 1\n",
    "        \n",
    "        print('\\n round #' + str(ct) + '/' + str(len(samples_snl)))\n",
    "        \n",
    "        if np.any(np.isnan(samples)): # fail to sample n_sample times\n",
    "            all_mmds.append(np.inf)\n",
    "        else:            \n",
    "            print('- computing MMD')\n",
    "            scale = math.median_distance(samples_true)\n",
    "            mmd = two_sample.sq_maximum_mean_discrepancy(samples, samples_true, scale=scale)\n",
    "            if isinstance(mmd, np.ndarray):\n",
    "                mmd = mmd.flatten()[0]\n",
    "            all_mmds.append(mmd)\n",
    "            \n",
    "    return np.array(all_mmds).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "for seed in range(42, 52):\n",
    "    \n",
    "    \n",
    "    observation_seed = seed # draw own xo for each seed (same ground-truth parameters though)\n",
    "    obs = utils.obs_data(true_params, seed=observation_seed, duration=duration)\n",
    "    obs_stats = utils.obs_stats(true_params, seed=observation_seed)\n",
    "\n",
    "    # MCMC samples for comparison\n",
    "    sam = np.load('results/glm/seed' + str(seed) + '/sam_' + str(seed) + '.npz')['arr_0']\n",
    "\n",
    "\n",
    "    ##########\n",
    "    # SNPE-A #\n",
    "    ##########\n",
    "\n",
    "    g = init_g(seed=seed)\n",
    "\n",
    "    res = infer.CDELFI(g, \n",
    "                     obs=obs_stats, \n",
    "                     n_hiddens=n_hiddens, \n",
    "                     seed=seed, \n",
    "                     reg_lambda=reg_lambda,\n",
    "                     pilot_samples=pilot_samples,\n",
    "                     svi=svi,\n",
    "                     n_components=n_components,\n",
    "                     verbose=verbose,\n",
    "                     prior_norm=prior_norm)\n",
    "\n",
    "    t = timeit.time.time()\n",
    "\n",
    "    logs_A, tds_A, posteriors_A = res.run(n_train=n_train, \n",
    "                        n_rounds=5, \n",
    "                        minibatch=minibatch, \n",
    "                        epochs=epochs)\n",
    "\n",
    "    print(timeit.time.time() -  t)\n",
    "\n",
    "    #samples_true = np.load(os.path.join('results/' + model_id, 'seed42', 'samples.npy'))\n",
    "    all_mmds_A = calc_all_mmds(sam[:,3000:13000:2].T, \n",
    "                             n_samples=N, \n",
    "                             posteriors=posteriors_A, \n",
    "                             init_g=init_g,\n",
    "                             rej=True)\n",
    "\n",
    "    print('all_mmds', all_mmds_A)\n",
    "\n",
    "\n",
    "\n",
    "    ##########\n",
    "    # SNPE-B #\n",
    "    ##########\n",
    "\n",
    "\n",
    "    g = init_g(seed=seed)\n",
    "\n",
    "    res_B = infer.SNPE(g, \n",
    "                     obs=obs_stats, \n",
    "                     n_hiddens=n_hiddens, \n",
    "                     seed=seed, \n",
    "                     reg_lambda=reg_lambda,\n",
    "                     pilot_samples=pilot_samples,\n",
    "                     svi=svi,\n",
    "                     n_components=n_components,\n",
    "                     verbose=verbose,\n",
    "                     prior_norm=prior_norm)\n",
    "\n",
    "    t = timeit.time.time()\n",
    "\n",
    "    logs_B, tds_B, posteriors_B = res_B.run(n_train=n_train, \n",
    "                        n_rounds=5, \n",
    "                        minibatch=minibatch, \n",
    "                        epochs=epochs)\n",
    "\n",
    "    print(timeit.time.time() -  t)\n",
    "\n",
    "    #samples_true = np.load(os.path.join('results/' + model_id, 'seed42', 'samples.npy'))\n",
    "    all_mmds_B = calc_all_mmds(sam[:,3000:13000:2].T, \n",
    "                             n_samples=N, \n",
    "                             posteriors=posteriors_B, \n",
    "                             init_g=init_g,\n",
    "                             rej=True)\n",
    "\n",
    "    print('all_mmds', all_mmds_B)\n",
    "\n",
    "\n",
    "\n",
    "    #######\n",
    "    # APT #\n",
    "    #######\n",
    "\n",
    "\n",
    "\n",
    "    if train_on_all:\n",
    "        epochs = [epochs//(r+1) for r in range(n_rounds)]\n",
    "\n",
    "    # control MAF seed\n",
    "    rng = np.random\n",
    "    rng.seed(seed)\n",
    "\n",
    "    # generator\n",
    "    g = init_g(seed=seed)\n",
    "\n",
    "    # inference object\n",
    "    res_C = infer.SNPEC(g,\n",
    "                     obs=obs_stats,\n",
    "                     n_hiddens=n_hiddens,\n",
    "                     seed=seed,\n",
    "                     reg_lambda=reg_lambda,\n",
    "                     pilot_samples=pilot_samples,\n",
    "                     svi=svi,\n",
    "                     n_mades=n_mades, # providing this argument triggers usage of MAFs (vs. MDNs)\n",
    "                     act_fun=act_fun,\n",
    "                     mode=mode,\n",
    "                     rng=rng,\n",
    "                     batch_norm=batch_norm,\n",
    "                     verbose=verbose,\n",
    "                     prior_norm=prior_norm)\n",
    "\n",
    "    # train\n",
    "    t = timeit.time.time()\n",
    "\n",
    "    logs_C, tds_C, posteriors_C = res_C.run(\n",
    "                        n_train=n_train,\n",
    "                        proposal='discrete',\n",
    "                        moo='resample',\n",
    "                        n_null = minibatch-1,\n",
    "                        n_rounds=n_rounds,\n",
    "                        train_on_all=train_on_all,\n",
    "                        minibatch=minibatch,\n",
    "                        epochs=epochs,\n",
    "                        val_frac=val_frac,\n",
    "                        silent_fail=True,\n",
    "                        stop_on_nan=True)\n",
    "\n",
    "    print(timeit.time.time() - t)\n",
    "\n",
    "    #samples_true = np.load(os.path.join('results/' + model_id, 'seed42', 'samples.npy'))\n",
    "    all_mmds_C = calc_all_mmds(sam[:,3000:13000:2].T, \n",
    "                             n_samples=N, \n",
    "                             posteriors=posteriors_C, \n",
    "                             init_g=init_g,\n",
    "                             rej=True)\n",
    "\n",
    "    print('all_mmds', all_mmds_C)\n",
    "\n",
    "\n",
    "    #######\n",
    "    # SNL #\n",
    "    #######\n",
    "\n",
    "\n",
    "    # control MAF seed\n",
    "    rng = np.random\n",
    "    rng.seed(seed)\n",
    "\n",
    "    # explicit call to MAF constructor\n",
    "    theta, x = g.gen(1)\n",
    "    n_inputs, n_outputs  = x.size, theta.size\n",
    "    model = ConditionalMaskedAutoregressiveFlow(\n",
    "                    n_inputs=n_inputs,\n",
    "                    n_outputs=n_outputs,\n",
    "                    n_hiddens=n_hiddens,\n",
    "                    act_fun=act_fun,\n",
    "                    n_mades=n_mades,\n",
    "                    mode=mode,\n",
    "                    rng=rng)\n",
    "\n",
    "\n",
    "    # generator\n",
    "    g = init_g(seed=seed)\n",
    "\n",
    "    # inference object\n",
    "    inf = nde.SequentialNeuralLikelihood(SNLprior(g.prior),               # method to draw parameters  \n",
    "                                         SNLmodel(g.model, g.summary).gen # method to draw summary stats\n",
    "                                        )\n",
    "\n",
    "    # train\n",
    "    t = timeit.time.time()\n",
    "\n",
    "    rng = np.random # control  \n",
    "    rng.seed(seed)  # MCMC seed\n",
    "    model = inf.learn_likelihood(obs_stats.flatten(), \n",
    "                                 model, \n",
    "                                 n_samples=n_train, \n",
    "                                 n_rounds=n_rounds, \n",
    "                                 train_on_all=True, \n",
    "                                 thin=10, \n",
    "                                 save_models=True, \n",
    "                                 logger=sys.stdout, \n",
    "                                 rng=rng)\n",
    "\n",
    "    print(timeit.time.time() - t)\n",
    "\n",
    "    network = inf.all_models[-1]\n",
    "    prior = SNLprior(init_g(seed=seed).prior)\n",
    "    init_pars = true_params\n",
    "\n",
    "    log_post = lambda t: network.eval([t, obs_stats.flatten()]) + prior.eval(t)\n",
    "    sampler = mcmc.SliceSampler(init_pars, log_post, thin=10)\n",
    "    sampler.gen(100, rng=rng)  # burn in\n",
    "    samples = sampler.gen(N, rng=rng)\n",
    "\n",
    "\n",
    "    #samples_true = np.load(os.path.join('results/' + model_id, 'seed42', 'samples.npy'))\n",
    "    all_mmds_L = calc_all_mmds_snl(sam[:,3000:13000:2].T, \n",
    "                             samples_snl=inf.all_ps[1:] + [samples])\n",
    "\n",
    "    print('all_mmds', all_mmds_L)\n",
    "\n",
    "\n",
    "\n",
    "    # save and plot\n",
    "\n",
    "    np.save('results/glm/seed' + str(seed) + '/all_mmds_v2', \n",
    "             {'all_mmds_A' : all_mmds_A, \n",
    "              'all_mmds_B' : all_mmds_B, \n",
    "              'all_mmds_C' : all_mmds_C, \n",
    "              'all_mmds_L' : all_mmds_L          \n",
    "             })\n",
    "\n",
    "    plt.figure(figsize=(9,6))\n",
    "    plt.plot(np.sqrt(all_mmds_A), '>:', color='c', label='SNPE-A')\n",
    "    plt.plot(np.sqrt(all_mmds_B), 'p:', color='g', label='SNPE-B')\n",
    "    plt.plot(np.sqrt(all_mmds_L), 'o:', color='r', label='SNL')\n",
    "    plt.plot(np.sqrt(all_mmds_C), 'd-', color='k', label='APT')\n",
    "\n",
    "    plt.xlabel('N')\n",
    "    plt.ylabel('maximum mean discrepancy')\n",
    "    plt.xticks([0,2,4], [5000, 10000, 25000])\n",
    "    plt.title('GLM (10-dim, 5 rounds with N=5k each)')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower=init_g(seed).prior.m-1*np.diag(init_g(seed).prior.S)\n",
    "upper=init_g(seed).prior.m+1*np.diag(init_g(seed).prior.S)\n",
    "\n",
    "fig, _ = plot_pdf(pdf1=posteriors_A[-1],\n",
    "         pdf2=posteriors_B[-1],\n",
    "         samples=sam,\n",
    "         lims= [\n",
    "          [lower[i], upper[i]] for i in range(10)            \n",
    "         ],\n",
    "         figsize=(16,16))\n",
    "fig.suptitle('SNPE-A & SNPE-B vs. MCMC')\n",
    "\n",
    "fig, _ = plot_pdf(pdf1=posteriors_A[-1],\n",
    "         samples=posteriors_C[-1].gen(10000).T,\n",
    "         lims= [\n",
    "          [lower[i], upper[i]] for i in range(10)            \n",
    "         ],\n",
    "         figsize=(16,16))\n",
    "fig.suptitle('SNPE-A vs. APT')\n",
    "\n",
    "fig, _ = plot_pdf(pdf1=posteriors_A[-1],\n",
    "         samples=inf.all_ps[-1].T,\n",
    "         lims= [\n",
    "          [lower[i], upper[i]] for i in range(10)            \n",
    "         ],                  \n",
    "         figsize=(16,16))\n",
    "fig.suptitle('SNPE-A vs. SNL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "mmd_snpea = np.array([0.16374293, 0.01935329, 0.0042091,  0.00060067, 0.0029527])\n",
    "mmd_snpeb = np.array([0.16689721, 0.09796158, 0.09905345, 0.10139064, 0.09843219])\n",
    "mmd_snl = np.array([0.0519698,  0.06865336, 0.06759704, 0.04965283, 0.04916893])\n",
    "mmd_snpec = np.array([0.13863246, 0.01514593, 0.00414106, 0.00475852, 0.00567665])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.plot(np.sqrt(mmd_snpea), '>:', color='c', label='SNPE-A')\n",
    "plt.plot(np.sqrt(mmd_snpeb), 'p:', color='g', label='SNPE-B')\n",
    "plt.plot(np.sqrt(mmd_snl), 'o:', color='r', label='SNL')\n",
    "plt.plot(np.sqrt(mmd_snpec), 'd-', color='k', label='APT')\n",
    "\n",
    "plt.xlabel('N')\n",
    "plt.ylabel('maximum mean discrepancy')\n",
    "plt.xticks([0,2,4], [5000, 10000, 25000])\n",
    "plt.title('GLM (10-dim, 5 rounds with N=5k each)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
