{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLM\n",
    "\n",
    "\n",
    "- GLM example as simple multivariate posterior estimation problem with available ground-truth (MCMC)\n",
    "- setup and code from NIPS 2017 paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import delfi.distribution as dd\n",
    "import delfi.generator as dg\n",
    "import delfi.inference as infer\n",
    "import delfi.utils.io as io\n",
    "import delfi.summarystats as ds\n",
    "import lfimodels.glm.utils as utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from lfimodels.glm.GLM import GLM\n",
    "from lfimodels.glm.GLMStats import GLMStats\n",
    "from delfi.utils.viz import plot_pdf\n",
    "\n",
    "import timeit\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "seed = 42\n",
    "\n",
    "\n",
    "# load setup from NIPS 2017 paper\n",
    "\n",
    "len_filter = 9 # number of GLM filter parameters (= dim. of parameters)\n",
    "duration = 100 # simulation length (longer = tighter posteriors)\n",
    "\n",
    "true_params, labels_params = utils.obs_params(len_filter)\n",
    "obs = utils.obs_data(true_params, seed=seed, duration=duration)\n",
    "obs_stats = utils.obs_stats(true_params, seed=seed)\n",
    "\n",
    "# basic approach to controlling generator seeds\n",
    "def init_g(seed):\n",
    "    m = GLM(seed=seed, duration=duration, len_filter=len_filter)\n",
    "    p = utils.smoothing_prior(n_params=m.n_params, seed=seed)\n",
    "    s = GLMStats(n_summary=m.n_params)\n",
    "    return dg.Default(model=m, prior=p, summary=s)\n",
    "\n",
    "# MCMC comparison (this might take a while the first time !)\n",
    "rerun = False  # if False, will try loading file from disk\n",
    "try:\n",
    "    assert rerun == False, 'rerun requested'\n",
    "    sam = np.load('sam.npz')['arr_0']\n",
    "except:\n",
    "    sam = utils.pg_mcmc(true_params, obs)\n",
    "    np.savez('sam.npz', sam)\n",
    "    \n",
    "\n",
    "# SNPE parameters\n",
    "    \n",
    "# training schedule\n",
    "n_train=3000\n",
    "n_rounds=5\n",
    "\n",
    "# fitting setup\n",
    "minibatch=100\n",
    "epochs=50\n",
    "\n",
    "# network setup\n",
    "n_hiddens=[50]\n",
    "reg_lambda=0.01\n",
    "\n",
    "# convenience\n",
    "pilot_samples=0\n",
    "svi=False\n",
    "verbose=True\n",
    "prior_norm=False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## baseline: SNPE-A\n",
    "\n",
    "- SNPE-A hard to beat on this problem with Gaussian prior and Gaussian $q^*$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = init_g(seed=seed)\n",
    "\n",
    "res = infer.CDELFI(g, \n",
    "                 obs=obs_stats, \n",
    "                 n_hiddens=n_hiddens, \n",
    "                 seed=seed, \n",
    "                 reg_lambda=reg_lambda,\n",
    "                 pilot_samples=pilot_samples,\n",
    "                 svi=svi,\n",
    "                 verbose=verbose,\n",
    "                 prior_norm=prior_norm)\n",
    "\n",
    "t = timeit.time.time()\n",
    "\n",
    "logs_A, tds_A, posteriors_A = res.run(n_train=n_train, \n",
    "                    n_rounds=n_rounds, \n",
    "                    minibatch=minibatch, \n",
    "                    epochs=epochs)\n",
    "\n",
    "print(timeit.time.time() -  t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# quick look at problem setup, posterior vs. prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,_ = plot_pdf(posteriors_A[-1], \n",
    "         pdf2=g.prior,\n",
    "         samples=sam, \n",
    "         gt=true_params, \n",
    "         resolution=100,\n",
    "         figsize=(16,16));\n",
    "fig.suptitle('final posterior estimate vs MCMC samples and prior', fontsize=14)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SNPE-C\n",
    "\n",
    "- version with rounds: first round is SNPE-A, then \n",
    "\n",
    "    - after every round, set $\\tilde{p}(\\theta) = q^*(\\theta|x_0)$\n",
    "    \n",
    "    - sample synthetic data set $\\mathcal{D} = \\{(\\theta_n,x_n)\\}_{n=1}^N$  for this round, with $(\\theta_n, x_n) \\sim p(x|\\theta)\\tilde{p}(\\theta)$\n",
    "    \n",
    "    - for every gradient step, sample alternatives $\\theta'_{nj}, j = 1 \\ldots, n_{null}$ from $\\theta'_{nj}$ depending on chosen rule: \n",
    "        - moo='resample' : $\\ \\theta'_{nj}\\sim Unif[\\{\\theta_m\\}_{n\\neq{}m}]$, i.e. $\\theta'_{nj}$ are resampled (without replacement) from the $\\theta_n\\sim \\tilde{p}(\\theta)$ in the same minibatch. \n",
    "        - moo='prior' : $\\ \\theta'_{nj}\\sim p(\\theta)$ \n",
    "        - moo='p_tilda' : $\\ \\theta'_{nj}\\sim \\tilde{p}(\\theta)$ with _fixed_ $\\tilde{p}(\\theta) = q^*(\\theta|x_0)$  (default)\n",
    "        - moo='q_phi_xo': $\\ \\theta'_{nj}\\sim q^*(\\theta | x_o)$ with _current_ $q^*$\n",
    "        - moo='q_phi_x' : $\\ \\theta'_{nj}\\sim q^*(\\theta | x_n)$ with _current_ $q^*$\n",
    "        - note that the two 'q_phi' rules violate the view of drawing $\\theta_n, \\theta'_{nj}$ iid ! atm it is not perfectly clear what they implement (prbly some form of VI).\n",
    "    \n",
    "    - construct uniform discrete proposals over $\\{\\theta_n\\} \\cup \\{\\theta'_{nj}\\}_{j=1}^{n_{null}}$ and compute SNPE-C loss and gradients\n",
    "    \n",
    "    - do SGD with minibatches over $minibatch$ many $(\\theta_n, x_n)$\n",
    "    \n",
    "    \n",
    "- takes longer than SNPE-A because \n",
    "\n",
    "    - for every batch, need to sample $minibath * n_{null}$ many $\\theta'_{nj}$ from $minibatch$ many different MoGs $q^*(\\theta|x_n)$ !\n",
    "    - for every batch, need to evaluate $minibath * n_{null}$ many terms $q^*(\\theta'_{nj} | x_n)$ (versus $minibatch$ many for SNPE-A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_null = minibatch-1 # number of alternative parameters theta_ni for each data pair (theta_n, x_n)\n",
    "\n",
    "g = init_g(seed=seed)\n",
    "res = infer.SNPEC(g,\n",
    "                 obs=obs_stats,\n",
    "                 n_hiddens=n_hiddens,\n",
    "                 seed=seed,\n",
    "                 reg_lambda=reg_lambda,\n",
    "                 pilot_samples=pilot_samples,\n",
    "                 svi=svi,\n",
    "                 verbose=verbose,\n",
    "                 prior_norm=prior_norm)\n",
    "\n",
    "t = timeit.time.time()\n",
    "\n",
    "logs_C, tds_C, posteriors_C = res.run(n_train=n_train,\n",
    "                    n_rounds=n_rounds,\n",
    "                    minibatch=minibatch,\n",
    "                    epochs=epochs,\n",
    "                    n_null=n_null,\n",
    "                    proposal='discrete',\n",
    "                    moo='resample'\n",
    "                    )\n",
    "\n",
    "print(timeit.time.time() -  t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# round-by-round comparison of posterior estimates\n",
    "- on the first round, SNPE-C = SNPE-A ! (want samples from $q^*_{F(\\phi,x_0)}( \\cdot{} | x_O)$ to not be much worse than samples from prior, which they are for initial $\\phi$ !) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for r in range(len(logs_C)):\n",
    "    \n",
    "    posterior_A = posteriors_A[r]\n",
    "    posterior_C = posteriors_C[r]\n",
    "    \n",
    "    fig,_=plot_pdf(posterior_C, \n",
    "                   pdf2=posterior_A,\n",
    "                   samples=sam, \n",
    "                   gt=true_params, \n",
    "                   resolution=100,\n",
    "                   figsize=(16,16));\n",
    "    \n",
    "    fig.suptitle('SNPE-C (upper triangle) vs SNPE-A (lower triangle), round r = '+str(r+1), fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
