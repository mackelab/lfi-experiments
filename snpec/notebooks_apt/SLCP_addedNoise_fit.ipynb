{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLCP model with added noise dimensions (fig 3)\n",
    "\n",
    "- fitting APT and SNL for figure 3 of APT paper\n",
    "- for evaluation of fits, see APT_eval.ipynb and SNL_eval.ipynb \n",
    "- for plotting, see ICML_figure3.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import timeit\n",
    "\n",
    "from delfi.utils.viz import plot_pdf\n",
    "import delfi.inference as infer\n",
    "import delfi.distribution as dd\n",
    "from delfi.summarystats.BaseSummaryStats import BaseSummaryStats\n",
    "\n",
    "from lfimodels.snl_exps.util import save_results, load_results\n",
    "from lfimodels.snl_exps.util import init_g_gauss as init_g\n",
    "from lfimodels.snl_exps.util import load_setup_gauss as load_setup\n",
    "from lfimodels.snl_exps.util import load_gt_gauss as load_gt\n",
    "from lfimodels.snl_exps.util import calc_all_lprob_errs\n",
    "\n",
    "import snl.simulators.gaussian as sim_gauss\n",
    "from snl.inference.nde import SequentialNeuralLikelihood\n",
    "from snl.ml.models.mafs import ConditionalMaskedAutoregressiveFlow\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "model_id = 'gauss'\n",
    "save_path = 'results/' + model_id + '_noisedims_v3'\n",
    "\n",
    "noise_dim = 52\n",
    "n_noise_comps = 20\n",
    "\n",
    "scale = 3.\n",
    "\n",
    "\"\"\"\n",
    "STABILITY ISSUES WITH NOISE GENERATION FOR LARGE noise_dim VALUES! \n",
    "ADDING scale * np.eye(noise_dim) TO COVARIANCE MATRICES, WITH SCALE DEPENDING ON noise_dim !\n",
    "scales manually mapped out: \n",
    "noise_dim = 92 : scale = 7.\n",
    "noise_dim = 52 : scale = 3.\n",
    "noise_dim = 32 : scale = 3.\n",
    "noise_dim = 12 : scale = 1.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Version numbers (savepath suffix):  \n",
    "noise_dim = 92 : _v2.\n",
    "noise_dim = 52 : _v3.\n",
    "noise_dim = 32 : _v4.\n",
    "noise_dim = 12 : _v1.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "class NoiseStats(BaseSummaryStats):\n",
    "\n",
    "        \n",
    "    def __init__(self, noise_source, n_signal = None, seed=None):\n",
    "\n",
    "        rng = np.random\n",
    "        rng.seed(seed)\n",
    "                \n",
    "        self.noise_source = noise_source\n",
    "        \n",
    "        self.n_signal = n_signal\n",
    "        self.n_noise = self.noise_source.ndim\n",
    "\n",
    "        super().__init__(seed=seed)\n",
    "        \n",
    "        self.n_summary = n_signal + self.n_noise\n",
    "        \n",
    "\n",
    "        self.idx = np.arange(self.n_summary)\n",
    "        self.idx = rng.permutation(self.n_summary)\n",
    "        \n",
    "    def calc(self, repetition_list):\n",
    "                \n",
    "        # get the number of samples contained\n",
    "        n_reps = len(repetition_list)\n",
    "\n",
    "        # get the size of the data inside a sample\n",
    "        assert self.n_summary == repetition_list[0].size + self.n_noise\n",
    "\n",
    "        # build a matrix of n_reps x n_summary\n",
    "        data_matrix = np.zeros((n_reps, self.n_summary))\n",
    "        noise_matrix = self.noise_source.gen(n_reps)\n",
    "        for rep_idx, rep_val in enumerate(repetition_list):\n",
    "            data_matrix[rep_idx, :] =  np.hstack( (rep_val, noise_matrix[rep_idx,:]) )\n",
    "\n",
    "        return data_matrix if self.idx is None else data_matrix[:, self.idx]\n",
    "\n",
    "\n",
    "def init_noise_g(seed, obs_stats):\n",
    "\n",
    "    rng = np.random\n",
    "    rng.seed(seed)    \n",
    "    \n",
    "    noise_means_prior = dd.Gaussian(m = np.zeros(noise_dim), S=np.eye(noise_dim), seed=seed+1)\n",
    "    noise_ms = [noise_means_prior.gen(1).reshape(-1) for i in range(n_noise_comps)]\n",
    "\n",
    "    cholesky_factors = [np.tril(rng.normal(size=(noise_dim, noise_dim))) + np.diag(np.exp(rng.normal(size=noise_dim)))\n",
    "                        + scale * np.eye(noise_dim) for i in range(n_noise_comps) ]\n",
    "    noise_Ss = [3 * np.dot(ch, ch.T) / noise_dim for ch in cholesky_factors]\n",
    "    noise_ms = [15 * rng.normal(size=noise_dim) for i in range(n_noise_comps)]\n",
    "    noise_dofs = [2 for i in range(n_noise_comps)]\n",
    "\n",
    "    noise_distribution = dd.MoT(a=np.ones(n_noise_comps) / n_noise_comps, ms=noise_ms, Ss=noise_Ss, dofs=noise_dofs, seed=seed)\n",
    "    noise_distribution.ndim = noise_dim\n",
    "\n",
    "    # generator\n",
    "    g = init_g(seed=seed)\n",
    "    g.summary = NoiseStats(noise_source=noise_distribution, n_signal=8, seed=seed)\n",
    "    g.model.dim_param = 5\n",
    "\n",
    "    obs_stats = np.hstack((obs_stats, noise_distribution.gen(1).reshape(1,-1)))[0,g.summary.idx]\n",
    "    assert obs_stats.size ==  g.summary.n_summary\n",
    "\n",
    "    print('permutation indices', g.summary.idx)    \n",
    "    \n",
    "    return g, obs_stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fit SNL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seeds = np.arange(52,62)\n",
    "\n",
    "for seed in seeds:\n",
    "\n",
    "    \n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    print('seed #' + str(seed))\n",
    "    print('\\n')\n",
    "    \n",
    "    setup_dict = load_setup()    \n",
    "    pars_true, obs_stats = load_gt(generator=init_g(seed=seed))\n",
    "    print('pars_true : ', pars_true)\n",
    "    print('obs_stats : ', obs_stats)    \n",
    "    \n",
    "    # fit SNPE\n",
    "            \n",
    "    exp_id = 'seed'+str(seed)\n",
    "    \n",
    "    g, obs_stats_noise = init_noise_g(seed, obs_stats)\n",
    "\n",
    "    if setup_dict['train_on_all']:\n",
    "        epochs=[setup_dict['epochs']//(r+1) for r in range(setup_dict['n_rounds'])]\n",
    "    else:\n",
    "        epochs=setup_dict['epochs']\n",
    "\n",
    "    # control MAF seed\n",
    "    rng = np.random\n",
    "    rng.seed(seed)\n",
    "\n",
    "    obs_stats_noise_snpe = obs_stats_noise.copy()\n",
    "\n",
    "    \n",
    "    # fit SNL\n",
    "\n",
    "\n",
    "    g, obs_stats_noise = init_noise_g(seed, obs_stats)\n",
    "    \n",
    "    model = sim_gauss.Model()\n",
    "    prior = sim_gauss.Prior()\n",
    "    stats = NoiseStats(noise_source=g.summary.noise_source, n_signal=8, seed=seed)\n",
    "    stats.idx = g.summary.idx\n",
    "\n",
    "    print('permutation indices', stats.idx)\n",
    "\n",
    "    # control model seed seed\n",
    "    rng = np.random\n",
    "    rng.seed(seed)\n",
    "    \n",
    "    sim_model = lambda ps, rng: stats.calc(model.sim(ps, rng=rng)) \n",
    "    # to run without summary stats: sim_model = model.sim !\n",
    "\n",
    "    obs_stats_noise_snl = obs_stats_noise.copy()\n",
    "        \n",
    "    inf = SequentialNeuralLikelihood(prior=prior, sim_model=sim_model)\n",
    "\n",
    "    # control MAF seed\n",
    "    rng = np.random\n",
    "    rng.seed(seed)\n",
    "\n",
    "    maf = ConditionalMaskedAutoregressiveFlow(n_inputs=prior.n_dims, \n",
    "                                              n_outputs=obs_stats_noise.size, \n",
    "                                              n_hiddens=setup_dict['n_hiddens'], \n",
    "                                              act_fun=setup_dict['act_fun'], \n",
    "                                              n_mades=setup_dict['n_mades'], \n",
    "\n",
    "                                              batch_norm=False,           # these differ for \n",
    "                                              output_order='sequential', # the usage of our \n",
    "                                              mode=setup_dict['mode'],         # MAFs...\n",
    "\n",
    "                                              input=None, \n",
    "                                              output=None, rng=rng)\n",
    "\n",
    "\n",
    "    # control sampler seed\n",
    "    rng = np.random\n",
    "    rng.seed(seed+1)\n",
    "\n",
    "    t = timeit.time.time()\n",
    "\n",
    "    learned_model = inf.learn_likelihood(obs_xs=obs_stats_noise.flatten(), \n",
    "                           model=maf, \n",
    "                           n_samples=setup_dict['n_train'], \n",
    "                           n_rounds=setup_dict['n_rounds'],\n",
    "                           train_on_all=setup_dict['train_on_all'],\n",
    "                           thin=10, \n",
    "                           save_models=True, \n",
    "                           logger=sys.stdout, \n",
    "                           rng=rng)\n",
    "\n",
    "    print(timeit.time.time() -  t)    \n",
    "    \n",
    "    dir = os.path.join(save_path, exp_id)\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "\n",
    "    file = os.path.join(save_path, exp_id, 'SNL_MAF')\n",
    "    with open(file + '.pkl', 'wb') as f:\n",
    "        pickle.dump(learned_model, f)\n",
    "        \n",
    "    file = os.path.join(save_path, exp_id, 'SNL_posteriors')\n",
    "    with open(file + '.pkl', 'wb') as f:\n",
    "        pickle.dump(inf.all_models, f)               \n",
    "\n",
    "    file = os.path.join(save_path, exp_id, 'SNL_posteriors')\n",
    "    with open(file + '.pkl', 'wb') as f:\n",
    "        pickle.dump(inf.all_models, f)        \n",
    "        \n",
    "    vars = {\n",
    "        'ps' : inf.all_ps,\n",
    "        'xs' : inf.all_xs\n",
    "    }\n",
    "\n",
    "    for varname in vars.keys():\n",
    "        fn = os.path.join(save_path, exp_id, varname)\n",
    "        np.save(fn, vars[varname])    \n",
    "            \n",
    "    fn = os.path.join(save_path, exp_id, 'obs_stats_noise')\n",
    "    np.save(fn, obs_stats_noise)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fit APT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "seeds = np.arange(52,62)\n",
    "\n",
    "for seed in seeds:\n",
    "\n",
    "    \n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    print('seed #' + str(seed))\n",
    "    print('\\n')\n",
    "    \n",
    "    setup_dict = load_setup()    \n",
    "    pars_true, obs_stats = load_gt(generator=init_g(seed=seed))\n",
    "    print('pars_true : ', pars_true)\n",
    "    print('obs_stats : ', obs_stats)    \n",
    "    \n",
    "    # fit SNPE\n",
    "            \n",
    "    exp_id = 'seed'+str(seed)\n",
    "    \n",
    "    g, obs_stats_noise = init_noise_g(seed, obs_stats)\n",
    "\n",
    "    if setup_dict['train_on_all']:\n",
    "        epochs=[setup_dict['epochs']//(r+1) for r in range(setup_dict['n_rounds'])]\n",
    "    else:\n",
    "        epochs=setup_dict['epochs']\n",
    "\n",
    "    # control MAF seed\n",
    "    rng = np.random\n",
    "    rng.seed(seed)\n",
    "\n",
    "    obs_stats_noise_snpe = obs_stats_noise.copy()\n",
    "    \n",
    "\n",
    "    res_C = infer.SNPEC(g,\n",
    "                        obs=obs_stats_noise,\n",
    "                        n_hiddens=setup_dict['n_hiddens'],\n",
    "                        seed=seed,\n",
    "                        reg_lambda=setup_dict['reg_lambda'],\n",
    "                        pilot_samples=setup_dict['pilot_samples'],\n",
    "                        svi=setup_dict['svi'],\n",
    "                        n_mades=setup_dict['n_mades'],\n",
    "                        act_fun=setup_dict['act_fun'],\n",
    "                        mode=setup_dict['mode'],\n",
    "                        rng=rng,\n",
    "                        batch_norm=setup_dict['batch_norm'],\n",
    "                        verbose=setup_dict['verbose'],\n",
    "                        #upper=setup_dict['upper'], # box-constraints \n",
    "                        #lower=setup_dict['lower'], # for MAF support\n",
    "                        prior_norm=setup_dict['prior_norm'])\n",
    "\n",
    "\n",
    "    \n",
    "    # train\n",
    "    t = timeit.time.time()\n",
    "\n",
    "    print('fitting model with SNPC-C')\n",
    "    logs_C, tds_C, posteriors_C = res_C.run(\n",
    "                        n_train=setup_dict['n_train'],\n",
    "                        proposal=setup_dict['proposal'],\n",
    "                        moo=setup_dict['moo'],\n",
    "                        n_null = setup_dict['n_null'],\n",
    "                        n_rounds=setup_dict['n_rounds'],\n",
    "                        train_on_all=setup_dict['train_on_all'],\n",
    "                        minibatch=setup_dict['minibatch'],\n",
    "                        epochs=epochs, \n",
    "                        verbose=False,\n",
    "                        val_frac=0.1,\n",
    "                        silent_fail=True,\n",
    "                        stop_on_nan=True)\n",
    "\n",
    "    print('fitting time : ', timeit.time.time() - t)\n",
    "\n",
    "    save_results(logs=logs_C, tds=[], posteriors=posteriors_C, \n",
    "                 setup_dict=setup_dict, exp_id=exp_id, path=save_path)\n",
    "\n",
    "    fn = os.path.join(save_path, exp_id, 'obs_stats_noise')\n",
    "    np.save(fn, obs_stats_noise)    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fits SNPE-B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = np.arange(52,62)\n",
    "\n",
    "for seed in seeds:\n",
    "\n",
    "    try:\n",
    "        \n",
    "        print('\\n')\n",
    "        print('\\n')\n",
    "        print('seed #' + str(seed))\n",
    "        print('\\n')\n",
    "\n",
    "        setup_dict = load_setup()    \n",
    "        pars_true, obs_stats = load_gt(generator=init_g(seed=seed))\n",
    "        print('pars_true : ', pars_true)\n",
    "        print('obs_stats : ', obs_stats)    \n",
    "\n",
    "        # fit SNPE\n",
    "\n",
    "        exp_id = 'seed'+str(seed) + '_SNPEB'\n",
    "\n",
    "        g, obs_stats_noise = init_noise_g(seed, obs_stats)\n",
    "\n",
    "        # control MAF seed\n",
    "        rng = np.random\n",
    "        rng.seed(seed)\n",
    "\n",
    "        obs_stats_noise_snpe = obs_stats_noise.copy()\n",
    "\n",
    "        # SNPE-B settings\n",
    "        setup_dict['n_components'] = 8\n",
    "        setup_dict['svi'] = True\n",
    "        setup_dict['epochs'] = 500 # SNPE-B gradient descent becomes unstable after ~700 epochs ! (-> NaN weights)\n",
    "\n",
    "\n",
    "        res_B = infer.SNPE(g,\n",
    "                            obs=obs_stats_noise.reshape(1,-1),\n",
    "                            n_hiddens=setup_dict['n_hiddens'],\n",
    "                            seed=seed,\n",
    "                            reg_lambda=setup_dict['reg_lambda'],\n",
    "                            pilot_samples=setup_dict['pilot_samples'],\n",
    "                            svi=setup_dict['svi'],\n",
    "                            n_components=setup_dict['n_components'],\n",
    "                            prior_norm=setup_dict['prior_norm'])\n",
    "\n",
    "\n",
    "\n",
    "        # train\n",
    "        t = timeit.time.time()\n",
    "\n",
    "        print('fitting model with SNPC-B')\n",
    "        logs_B, tds_B, posteriors_B = res_B.run(\n",
    "                            n_train=setup_dict['n_train'],\n",
    "                            n_rounds=setup_dict['n_rounds'],\n",
    "                            minibatch=setup_dict['minibatch'],\n",
    "                            epochs=setup_dict['epochs'],\n",
    "                            stop_on_nan=True\n",
    "                            #verbose=True,\n",
    "                            #val_frac=0.1,\n",
    "                            #silent_fail=True,\n",
    "                            )\n",
    "\n",
    "        print('fitting time : ', timeit.time.time() - t)\n",
    "\n",
    "        save_results(logs=logs_B, tds=[], posteriors=posteriors_B, \n",
    "                     setup_dict=setup_dict, exp_id=exp_id, path=save_path)\n",
    "\n",
    "        fn = os.path.join(save_path, exp_id, 'obs_stats_noise')\n",
    "        np.save(fn, obs_stats_noise)    \n",
    "        \n",
    "    except:\n",
    "        \n",
    "        print('\\n')\n",
    "        print('\\n')\n",
    "        print('\\n')\n",
    "        print('SEED FAILED !')\n",
    "        print('\\n')\n",
    "        print('\\n')\n",
    "        print('\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fit SNPE-A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = np.arange(52,62)\n",
    "\n",
    "for seed in seeds:\n",
    "\n",
    "    \n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    print('seed #' + str(seed))\n",
    "    print('\\n')\n",
    "    \n",
    "    setup_dict = load_setup()    \n",
    "    pars_true, obs_stats = load_gt(generator=init_g(seed=seed))\n",
    "    print('pars_true : ', pars_true)\n",
    "    print('obs_stats : ', obs_stats)    \n",
    "    \n",
    "    # fit SNPE\n",
    "            \n",
    "    exp_id = 'seed'+str(seed) + '_SNPEA'\n",
    "    \n",
    "    g, obs_stats_noise = init_noise_g(seed, obs_stats)\n",
    "\n",
    "    # control MAF seed\n",
    "    rng = np.random\n",
    "    rng.seed(seed)\n",
    "\n",
    "    obs_stats_noise_snpe = obs_stats_noise.copy()\n",
    "    \n",
    "    # SNPE-A settings\n",
    "    setup_dict['n_components'] = 8\n",
    "    setup_dict['svi'] = True\n",
    "    setup_dict['epochs'] = 1000\n",
    "    \n",
    "    \n",
    "    res_A = infer.CDELFI(g,\n",
    "                        obs=obs_stats_noise.reshape(1,-1),\n",
    "                        n_hiddens=setup_dict['n_hiddens'],\n",
    "                        seed=seed,\n",
    "                        reg_lambda=setup_dict['reg_lambda'],\n",
    "                        pilot_samples=setup_dict['pilot_samples'],\n",
    "                        svi=setup_dict['svi'],\n",
    "                        n_components=setup_dict['n_components'],\n",
    "                        prior_norm=setup_dict['prior_norm'])\n",
    "\n",
    "\n",
    "    \n",
    "    # train\n",
    "    t = timeit.time.time()\n",
    "\n",
    "    print('fitting model with SNPC-A')\n",
    "    logs_A, tds_A, posteriors_A = res_A.run(\n",
    "                        n_train=setup_dict['n_train'],\n",
    "                        n_rounds=setup_dict['n_rounds'],\n",
    "                        minibatch=setup_dict['minibatch'],\n",
    "                        epochs=setup_dict['epochs']\n",
    "                        #verbose=True,\n",
    "                        #val_frac=0.1,\n",
    "                        #silent_fail=True,\n",
    "                        )\n",
    "\n",
    "    print('fitting time : ', timeit.time.time() - t)\n",
    "\n",
    "    save_results(logs=logs_A, tds=[], posteriors=posteriors_A, \n",
    "                 setup_dict=setup_dict, exp_id=exp_id, path=save_path)\n",
    "\n",
    "    fn = os.path.join(save_path, exp_id, 'obs_stats_noise')\n",
    "    np.save(fn, obs_stats_noise)    \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
