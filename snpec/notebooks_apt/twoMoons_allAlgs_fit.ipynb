{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# two Moons model (figs 1, 6)\n",
    "- fits various algorithms (SNPE-A,SNPE-B,APT-MDN, APT-MAF, SNL) to two moons example\n",
    "- originally used only for the multi-seed runs of figure 6 (fig 1 was run from a 'playground' version of this, i.e. with only one fixed seed)\n",
    "- this notebook was written in haste (day before submission) and never fully uploaded. Local copies on different machines with cells for different algorithms\n",
    "- for evaluation (i.e. computation of MMDs), see twoMoons_allAlgs_eval.ipynb\n",
    "- for plotting, see ICML_figure_1.ipynb and ICML_figure_supp.ipynb\n",
    "\n",
    "\n",
    "- toDo: recover cells for algorithms SNPE-A, APT-MDN, APT-MAF from local notebook copies on different machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "import snl.inference.nde as nde\n",
    "from snl.ml.models.mafs import ConditionalMaskedAutoregressiveFlow\n",
    "from delfi.utils.delfi2snl import SNLprior, SNLmodel\n",
    "\n",
    "import delfi.distribution as dd\n",
    "import delfi.inference as infer\n",
    "import delfi.generator as dg\n",
    "\n",
    "from delfi.simulator import TwoMoons\n",
    "import delfi.summarystats as ds\n",
    "from delfi.utils.viz import plot_pdf, probs2contours\n",
    "\n",
    "from lfimodels.snl_exps.util import save_results, load_results\n",
    "\n",
    "# very basic approach to controlling generator seeds\n",
    "def init_g(seed):\n",
    "    m = TwoMoons(mean_radius=0.1, sd_radius=0.01, baseoffset=0.25,\n",
    "                 #angle= np.pi/4.0,  # rotation angle in radians\n",
    "                 #mapfunc=lambda theta, p: p + theta,  # transforms noise dist.\n",
    "                 seed=seed)\n",
    "    p = dd.Uniform(lower=[-1,-1], upper=[1,1], seed=seed)\n",
    "    s = ds.Identity()\n",
    "    return dg.Default(model=m, prior=p, summary=s)\n",
    "\n",
    "seed=42\n",
    "g = init_g(seed=seed)\n",
    "\n",
    "obs_stats = np.array([[0., 0.]])\n",
    "\n",
    "verbose =True\n",
    "        \n",
    "setup_dict = {}\n",
    "setup_dict['seed'] = seed\n",
    "setup_dict['obs_stats'] = obs_stats\n",
    "\n",
    "# training schedule\n",
    "setup_dict['n_rounds'] = 10\n",
    "setup_dict['n_train'] = 1000\n",
    "\n",
    "# fitting setup\n",
    "setup_dict['minibatch'] = 100\n",
    "setup_dict['reg_lambda'] = 0.001\n",
    "setup_dict['pilot_samples'] = 0\n",
    "setup_dict['prior_norm'] = False\n",
    "setup_dict['init_norm'] = False\n",
    "\n",
    "exp_id = 'seed' + str(setup_dict['seed'])\n",
    "save_path = 'results/two_moons_runs/'    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNPE-B fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = np.arange(42,52)\n",
    "    \n",
    "for seed in seeds:\n",
    "\n",
    "    \n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    print('seed #' + str(seed))\n",
    "    print('\\n')\n",
    "    \n",
    "    # fit SNPE\n",
    "            \n",
    "    exp_id = 'seed'+str(seed)\n",
    "    \n",
    "    setup_dict_ = setup_dict.copy()\n",
    "    setup_dict_['n_components'] = 20\n",
    "    setup_dict_['n_hiddens'] = [50,50]\n",
    "    setup_dict_['svi'] = True\n",
    "    setup_dict_['epochs'] = 500\n",
    "    setup_dict_['round_cl'] = 1\n",
    "\n",
    "    # generator\n",
    "    g = init_g(seed=seed)\n",
    "\n",
    "    # inference object\n",
    "    res_B = infer.SNPE(g, \n",
    "                     obs=obs_stats, \n",
    "                     n_hiddens=setup_dict_['n_hiddens'], \n",
    "                     n_components=setup_dict_['n_components'],\n",
    "                     seed=seed, \n",
    "                     reg_lambda=setup_dict_['reg_lambda'],\n",
    "                     pilot_samples=setup_dict_['pilot_samples'],\n",
    "                     svi=setup_dict_['svi'],\n",
    "                     verbose=verbose,\n",
    "                     init_norm=setup_dict_['init_norm'],\n",
    "                     prior_norm=setup_dict_['prior_norm'])\n",
    "\n",
    "    # train\n",
    "    t = timeit.time.time()\n",
    "\n",
    "    logs_B, tds_B, posteriors_B = res_B.run(\n",
    "                        n_train=setup_dict_['n_train'], \n",
    "                        n_rounds=setup_dict_['n_rounds'], \n",
    "                        minibatch=setup_dict_['minibatch'], \n",
    "                        round_cl=setup_dict_['round_cl'], \n",
    "                        epochs=setup_dict_['epochs'])\n",
    "\n",
    "    print(timeit.time.time() -  t)\n",
    "\n",
    "    try:\n",
    "        save_results(logs=logs_B, tds=tds_B, posteriors=posteriors_B, \n",
    "                     setup_dict=setup_dict_, exp_id=exp_id, path=save_path + '_MDN_SNPEB')\n",
    "    except:\n",
    "        save_results(logs=logs_B, tds=[], posteriors=posteriors_B, \n",
    "                     setup_dict=setup_dict_, exp_id=exp_id, path=save_path + '_MDN_SNPEB')\n",
    "        print('could not save datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNL fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "seeds = np.arange(42,52)\n",
    "    \n",
    "for seed in seeds:\n",
    "\n",
    "    \n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    print('seed #' + str(seed))\n",
    "    print('\\n')\n",
    "    \n",
    "    # fit SNPE\n",
    "            \n",
    "    exp_id = 'seed'+str(seed)\n",
    "\n",
    "    # MAF parameters\n",
    "    setup_dict_  = setup_dict.copy()\n",
    "    setup_dict_['mode'] = 'random'\n",
    "    setup_dict_['n_hiddens'] = [50,50]\n",
    "    setup_dict_['n_mades'] = 5\n",
    "    setup_dict_['act_fun'] = 'tanh'\n",
    "    setup_dict_['batch_norm'] = False # batch-normalization currently not supported\n",
    "    setup_dict_['train_on_all'] = True\n",
    "    setup_dict_['thin'] = 10\n",
    "    # control MAF seed\n",
    "    rng = np.random\n",
    "    rng.seed(seed)\n",
    "\n",
    "    # explicit call to MAF constructor\n",
    "    theta, x = g.gen(1)\n",
    "    n_inputs, n_outputs  = x.size, theta.size\n",
    "    model = ConditionalMaskedAutoregressiveFlow(\n",
    "                    n_inputs=n_inputs,\n",
    "                    n_outputs=n_outputs,\n",
    "                    n_hiddens=setup_dict_['n_hiddens'],\n",
    "                    act_fun=setup_dict_['act_fun'],\n",
    "                    n_mades=setup_dict_['n_mades'],\n",
    "                    mode=setup_dict_['mode'],\n",
    "                    rng=rng)\n",
    "\n",
    "    # generator\n",
    "    g = init_g(seed=seed)\n",
    "\n",
    "    # inference object\n",
    "    inf = nde.SequentialNeuralLikelihood(SNLprior(g.prior),               # method to draw parameters  \n",
    "                                         SNLmodel(g.model, g.summary).gen # method to draw summary stats\n",
    "                                        )\n",
    "\n",
    "    # train\n",
    "    t = timeit.time.time()\n",
    "\n",
    "    rng = np.random # control  \n",
    "    rng.seed(seed)  # MCMC seed\n",
    "    model = inf.learn_likelihood(obs_stats.flatten(), model, n_samples=setup_dict_['n_train'], \n",
    "                                 n_rounds=setup_dict_['n_rounds'], \n",
    "                                 train_on_all=setup_dict_['train_on_all'], thin=setup_dict_['thin'], save_models=True, \n",
    "                                 logger=sys.stdout, rng=rng)\n",
    "\n",
    "    print(timeit.time.time() -  t)\n",
    "\n",
    "    tds = (inf.all_ps, inf.all_xs)\n",
    "\n",
    "    #save_results(logs=[], tds=tds, posteriors=[model], \n",
    "    #             setup_dict=setup_dict_, exp_id=exp_id, path=save_path + '_MAF_SNL')\n",
    "\n",
    "    print(timeit.time.time() -  t)    \n",
    "    \n",
    "    dir = os.path.join(save_path, exp_id)\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "\n",
    "    file = os.path.join(save_path, exp_id, 'SNL_MAF')\n",
    "    with open(file + '.pkl', 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "        \n",
    "    file = os.path.join(save_path, exp_id, 'SNL_posteriors')\n",
    "    with open(file + '.pkl', 'wb') as f:\n",
    "        pickle.dump(inf.all_models, f)               \n",
    "\n",
    "    file = os.path.join(save_path, exp_id, 'SNL_posteriors')\n",
    "    with open(file + '.pkl', 'wb') as f:\n",
    "        pickle.dump(inf.all_models, f)        \n",
    "        \n",
    "    vars = {\n",
    "        'ps' : inf.all_ps,\n",
    "        'xs' : inf.all_xs\n",
    "    }\n",
    "\n",
    "    for varname in vars.keys():\n",
    "        fn = os.path.join(save_path, exp_id, varname)\n",
    "        np.save(fn, vars[varname])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
