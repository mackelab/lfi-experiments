{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M/G/1 model\n",
    "\n",
    "- simulator taken from https://github.com/mackelab/SNL_py3port, which contains the original https://github.com/gpapamak/snl after 2to3 conversion with minimal edits (deactivating generator-internal summary stats normalization).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import timeit\n",
    "\n",
    "import snl\n",
    "import snl.simulators.mg1 as sim\n",
    "\n",
    "import delfi.generator as dg\n",
    "import delfi.distribution as dd\n",
    "from delfi.utils.viz import plot_pdf\n",
    "import delfi.inference as infer\n",
    "\n",
    "seed = 42\n",
    "\n",
    "# SNPE parameters\n",
    "\n",
    "# training schedule\n",
    "n_train=1000\n",
    "n_rounds=20\n",
    "\n",
    "# fitting setup\n",
    "minibatch=100\n",
    "epochs=500\n",
    "\n",
    "# network setup\n",
    "n_hiddens=[50,50]\n",
    "reg_lambda=0.01\n",
    "\n",
    "# convenience\n",
    "pilot_samples=1000\n",
    "svi=False\n",
    "verbose=True\n",
    "prior_norm=False\n",
    "\n",
    "# SNPE-C parameters\n",
    "n_null = 10\n",
    "\n",
    "# MAF parameters\n",
    "mode='random' # ordering of variables for MADEs\n",
    "n_mades = 5 # number of MADES\n",
    "act_fun = 'tanh'\n",
    "batch_norm = False # batch-normalization currently not supported\n",
    "train_on_all = True # now supported feature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# implement prior in DELFI\n",
    "- Papamakarios' prior for this experiment is uniform within a non-rectangular region\n",
    "- since the MAF has in principle infinite support, we need to reject samples drawn from proposals in later rounds that fall outside the prior support\n",
    "- DELFI implements rejection through the generator object, but it is hardcoded for uniform (rectangular-support) priors, so we inherit from dd.Uniform and slightly adapt the generator \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShiftedUniform(dd.Uniform):\n",
    "    \n",
    "    def __init__(self, lower=0., upper=1., seed=None):\n",
    "        \"\"\"Shifted uniform distribution from SNL paper, M/G/1 model\n",
    "        theta1 ~ Unif[0,10]\n",
    "        theta2-theta1 ~ Unif[0,10]\n",
    "        theta3 ~ Unif[0,1/3]\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        lower : list, or np.array, 1d\n",
    "            Lower bound(s)\n",
    "        upper : list, or np.array, 1d\n",
    "            Upper bound(s)\n",
    "        seed : int or None\n",
    "            If provided, random number generator will be seeded\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(lower=lower, upper=upper, seed=seed)\n",
    "        assert self.ndim == 3\n",
    "        \n",
    "\n",
    "    def gen(self, n_samples=1):\n",
    "        params = super().gen(n_samples=n_samples)\n",
    "        params[:,1] += params[:,0]\n",
    "        return params\n",
    "    \n",
    "    def eval(self, x, ii=None, log=True):\n",
    "        \n",
    "        x = x.copy()\n",
    "        x[:,1] -= x[:,0]\n",
    "        return super().eval(x=x, ii=ii,log=log)\n",
    "        \n",
    "        \n",
    "prior = ShiftedUniform(lower=[ 0, 0,  0  ], \n",
    "                       upper=[10,10,1./3.])\n",
    "params = prior.gen(10000)\n",
    "\n",
    "plt.plot(params[:,0], params[:,1], '.')\n",
    "plt.show()\n",
    "\n",
    "plt.hist( params[:,1] - params[:,0], normed=True)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(prior.eval(params, log=True))\n",
    "plt.show()\n",
    "\n",
    "print('isinstance(prior, dd.Uniform)', isinstance(prior, dd.Uniform))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### overwrite generator to properly reject proposal draws outside prior bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from delfi.generator.Default import Default\n",
    "\n",
    "\n",
    "class GenMG1(Default):\n",
    "    \n",
    "    @copy_ancestor_docstring\n",
    "    def _feedback_proposed_param(self, param):\n",
    "        # See BaseGenerator for docstring\n",
    "\n",
    "        #print(param.shape)\n",
    "        assert param.size == 3\n",
    "        assert isinstance(self.prior, ShiftedUniform)\n",
    "        \n",
    "        param_ = param.copy()\n",
    "        param_[0,1] -= param_[0,0]\n",
    "        \n",
    "        if np.any(param_ < self.prior.lower) or \\\n",
    "           np.any(param_ > self.prior.upper):\n",
    "            return 'resample'\n",
    "\n",
    "        return 'accept'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### control seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from delfi.simulator import BaseSimulator\n",
    "\n",
    "\n",
    "def init_g(seed):\n",
    "    # prior \n",
    "\n",
    "    #prior = sim.Prior() # proposal will happily sample from outside the prior unless it's dd.Uniform !\n",
    "    prior = ShiftedUniform(lower=[ 0, 0,  0  ], \n",
    "                           upper=[10,10,1./3.], \n",
    "                           seed=seed)\n",
    "\n",
    "    # model \n",
    "    model_snl = sim.Model()\n",
    "    class MG1(BaseSimulator):\n",
    "        \"\"\"M/G/1 simulator\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        dim : int\n",
    "            Number of dimensions of parameters\n",
    "        seed : int or None\n",
    "            If set, randomness is seeded\n",
    "        \"\"\"        \n",
    "\n",
    "        def gen_single(self, params):\n",
    "            \"\"\" params = (lower bound of server processing time,\n",
    "                          upper bound of server processing time,\n",
    "                          rate customer arrivals )\n",
    "\n",
    "            \"\"\"\n",
    "            return model_snl.sim(params, rng=self.rng)\n",
    "\n",
    "    model = MG1(dim_param=3, seed=seed)\n",
    "\n",
    "    # summary statistics\n",
    "    summary = sim.Stats()\n",
    "\n",
    "    # generator\n",
    "    g = GenMG1(prior=prior, model=model, summary=summary, seed=seed+41)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = init_g(seed=seed)\n",
    "\n",
    "#pars_true = np.array([1, 5, 0.2])  # taken from SNL paper\n",
    "#obs = g.model.gen_single(pars_true)  # should also recover\n",
    "#obs_stats = g.summary.calc([obs])    # xo from SNL paper !\n",
    "\n",
    "# load ground-truth xo and true parameter values theta* from disc\n",
    "gt = np.load('/home/marcel/Desktop/Projects/Biophysicality/code/snl_snpec/gt_mg1.npy', encoding='latin1')[()]\n",
    "whiten_params = np.load('/home/marcel/Desktop/Projects/Biophysicality/code/snl_snpec/whiten_params_mg1.npy', encoding='latin1')[()]\n",
    "pars_true, obs_stats = np.array(gt['true_ps']), np.array(gt['obs_xs']).reshape(1,-1)\n",
    "\n",
    "# un-whiten xo with retrieved whitening params (SNPE-C will apply its own z-scoring, but xo needs to match the x_n)\n",
    "obs_stats = (obs_stats.flatten() / whiten_params['istds']).dot(whiten_params['U'].T) + whiten_params['means']\n",
    "obs_stats = obs_stats.reshape(1,-1)\n",
    "\n",
    "pars_true, obs_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fit SNPE-C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "if train_on_all:\n",
    "    epochs = [epochs//(r+1) for r in range(n_rounds)]\n",
    "\n",
    "# control MAF seed\n",
    "rng = np.random\n",
    "rng.seed(seed)\n",
    "\n",
    "# generator\n",
    "g = init_g(seed=seed)\n",
    "\n",
    "# inference object\n",
    "res_C = infer.SNPEC(g,\n",
    "                 obs=obs_stats,\n",
    "                 n_hiddens=n_hiddens,\n",
    "                 seed=seed,\n",
    "                 reg_lambda=reg_lambda,\n",
    "                 pilot_samples=pilot_samples,\n",
    "                 svi=svi,\n",
    "                 n_mades=n_mades, # providing this argument triggers usage of MAFs (vs. MDNs)\n",
    "                 act_fun=act_fun,\n",
    "                 mode=mode,\n",
    "                 rng=rng,\n",
    "                 batch_norm=batch_norm,\n",
    "                 verbose=verbose,\n",
    "                 prior_norm=prior_norm)\n",
    "\n",
    "# train\n",
    "t = timeit.time.time()\n",
    "\n",
    "logs_C, tds_C, posteriors_C = res_C.run(\n",
    "                    n_train=n_train,\n",
    "                    proposal='discrete',\n",
    "                    moo='resample',\n",
    "                    n_null = n_null,\n",
    "                    n_rounds=n_rounds,\n",
    "                    train_on_all=train_on_all,\n",
    "                    minibatch=minibatch,\n",
    "                    epochs=epochs)\n",
    "\n",
    "print(timeit.time.time() - t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training losses across rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for r in range(n_rounds):\n",
    "    plt.plot(logs_C[r]['loss'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# posterior estimates across rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for r in range(len(logs_C)):\n",
    "    \n",
    "    posterior_C = posteriors_C[r]\n",
    "    #posterior_C.ndim = posterior_A.ndim\n",
    "    \n",
    "    g = init_g(seed=42)\n",
    "    g.proposal = posterior_C\n",
    "    samples = np.array(g.draw_params(1000)) \n",
    "    \n",
    "    fig,_ = plot_pdf(dd.Gaussian(m=0.00000123*np.ones(pars_true.size), S=1e-30*np.eye(pars_true.size)), \n",
    "                   samples=samples.T,\n",
    "                   gt=pars_true, \n",
    "                   lims=[[0,10],[0,20],[0., 1./3.]],\n",
    "                   #lims=[0,10],\n",
    "                   resolution=100,\n",
    "                   ticks=True,\n",
    "                   figsize=(16,16));\n",
    "    \n",
    "    fig.suptitle('SNPE-C posterior estimates, round r = '+str(r+1), fontsize=14)\n",
    "    print('negative log-probability of ground-truth pars \\n', -posterior_C.eval(pars_true, log=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# marginal over summary statistics (plus best-fitting Gaussian approx.)\n",
    "- note that plot_pdf automatically chooses the axes limits according to the provided samples, i.e. by the outliers\n",
    "- hence large empty regions indicate that the simulator sometimes produces extreme outliers that may negatively affect the de-facto standard z-scoring done by SNPE and SNL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = tds_C[0][1]\n",
    "fig,_ = plot_pdf(dd.Gaussian(m=stats.mean(axis=0), S=np.cov(stats.T)), \n",
    "                   samples=stats.T,\n",
    "                   gt=((obs_stats-res_C.stats_mean)/res_C.stats_std).flatten(), \n",
    "                   ticks=True,\n",
    "                   resolution=100,\n",
    "                   figsize=(16,16));\n",
    "fig.suptitle('(pair-wise) marginal(s) over summary statistics from Gaussian model (already z-scored!)')\n",
    "#fig.savefig('/home/marcel/Desktop/mg1_summary_stats_marginals.pdf')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# results evaluation\n",
    "- copy-paste from SNL code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snl.pdfs as pdfs\n",
    "\n",
    "# for mcmc\n",
    "thin = 10\n",
    "n_mcmc_samples = 5000\n",
    "burnin = 100\n",
    "\n",
    "def calc_err(true_ps, samples, weights=None):\n",
    "    \"\"\"\n",
    "    Calculates error (neg log prob of truth) for a set of possibly weighted samples.\n",
    "    \"\"\"\n",
    "\n",
    "    std = n_mcmc_samples ** (-1.0 / (len(true_ps) + 4))\n",
    "\n",
    "    return -pdfs.gaussian_kde(samples, weights, std).eval(true_ps)\n",
    "\n",
    "std = n_mcmc_samples ** (-1.0 / (len(pars_true) + 4))\n",
    "\n",
    "all_prop_errs = []\n",
    "\n",
    "for proposal in posteriors_C[:-1]:\n",
    "    g = init_g(seed=42)\n",
    "    g.proposal = proposal\n",
    "    samples = np.array(g.draw_params(n_mcmc_samples))\n",
    "    prop_err = calc_err(pars_true, samples)\n",
    "    all_prop_errs.append(prop_err)\n",
    "\n",
    "g = init_g(seed=42)\n",
    "g.proposal = posteriors_C[-1]    \n",
    "samples = np.array(g.draw_params(n_mcmc_samples))\n",
    "post_err = calc_err(pars_true, samples)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.semilogx(np.arange(1, n_rounds+1) * n_train, np.array(all_prop_errs + [post_err]), 'kd:')\n",
    "plt.axis([600, 22000, -1, 5])\n",
    "plt.xlabel('Number of simulations (log scale)')\n",
    "plt.ylabel('- log probability of true parameters')\n",
    "plt.savefig('/home/marcel/Desktop/mg1_snpec_maf_n_null_10__v0.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_prop_errs_raw = []\n",
    "\n",
    "for proposal in posteriors_C[:-1]:\n",
    "    samples = proposal.gen(n_mcmc_samples)\n",
    "    prop_err = calc_err(pars_true, samples)\n",
    "    all_prop_errs_raw.append(prop_err)\n",
    "\n",
    "samples = posteriors_C[-1].gen(n_mcmc_samples)\n",
    "post_err_raw = calc_err(pars_true, samples)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.semilogx(np.arange(1, n_rounds+1) * n_train, np.array(all_prop_errs + [post_err]), 'bd:')\n",
    "plt.semilogx(np.arange(1, n_rounds+1) * n_train, np.array(all_prop_errs_raw + [post_err_raw]), 'kd:')\n",
    "plt.legend(['rej. sampling', 'naive sampling'])\n",
    "plt.axis([600, 22000, -1, 0.8])\n",
    "plt.xlabel('Number of simulations (log scale)')\n",
    "plt.ylabel('- log probability of true parameters')\n",
    "plt.title('effects of truncation on MAF')\n",
    "plt.savefig('/home/marcel/Desktop/mg1_snpec_maf_n_null_10_N5000_MAF_truncation.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
