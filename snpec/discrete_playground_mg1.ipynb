{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M/G/1 model\n",
    "\n",
    "- simulator taken from https://github.com/mackelab/SNL_py3port, which contains the original https://github.com/gpapamak/snl after 2to3 conversion with minimal edits (deactivating generator-internal summary stats normalization).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import timeit\n",
    "\n",
    "from delfi.utils.viz import plot_pdf\n",
    "import delfi.inference as infer\n",
    "\n",
    "from lfimodels.snl_exps.util import init_g_mg1 as init_g\n",
    "\n",
    "seed = 42\n",
    "\n",
    "# SNPE parameters\n",
    "\n",
    "# training schedule\n",
    "n_train=1000\n",
    "n_rounds=20\n",
    "\n",
    "# fitting setup\n",
    "minibatch=100\n",
    "epochs=500\n",
    "\n",
    "# network setup\n",
    "n_hiddens=[50,50]\n",
    "reg_lambda=0.01\n",
    "\n",
    "# convenience\n",
    "pilot_samples=1000\n",
    "svi=False\n",
    "verbose=True\n",
    "prior_norm=False\n",
    "\n",
    "# SNPE-C parameters\n",
    "n_null = 10\n",
    "\n",
    "# MAF parameters\n",
    "mode='random' # ordering of variables for MADEs\n",
    "n_mades = 5 # number of MADES\n",
    "act_fun = 'tanh'\n",
    "batch_norm = False # batch-normalization currently not supported\n",
    "train_on_all = True # now supported feature\n",
    "\n",
    "# simulation setup\n",
    "g = init_g(seed=seed)\n",
    "\n",
    "try: \n",
    "    # load ground-truth xo and true parameter values theta* from disc\n",
    "    gt = np.load('/home/marcel/Desktop/Projects/Biophysicality/code/snl_snpec/gt_mg1.npy', encoding='latin1')[()]\n",
    "    whiten_params = np.load('/home/marcel/Desktop/Projects/Biophysicality/code/snl_snpec/whiten_params_mg1.npy', encoding='latin1')[()]\n",
    "    pars_true, obs_stats = np.array(gt['true_ps']), np.array(gt['obs_xs']).reshape(1,-1)\n",
    "\n",
    "    # un-whiten xo with retrieved whitening params (SNPE-C will apply its own z-scoring, but xo needs to match the x_n)\n",
    "    obs_stats = (obs_stats.flatten() / whiten_params['istds']).dot(whiten_params['U'].T) + whiten_params['means']\n",
    "    obs_stats = obs_stats.reshape(1,-1)\n",
    "\n",
    "except:\n",
    "    pars_true = np.array([1, 5, 0.2])  # taken from SNL paper\n",
    "    obs = g.model.gen_single(pars_true)  # should also recover\n",
    "    obs_stats = g.summary.calc([obs])    # xo from SNL paper !\n",
    "    \n",
    "    print('\\n WARNING: could not load ground-truth data and parameters from disk! \\n Sampling xo instead !')\n",
    "\n",
    "print('pars_true : ', pars_true)\n",
    "print('obs_stats : ', obs_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fit SNPE-C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "if train_on_all:\n",
    "    epochs = [epochs//(r+1) for r in range(n_rounds)]\n",
    "\n",
    "# control MAF seed\n",
    "rng = np.random\n",
    "rng.seed(seed)\n",
    "\n",
    "# generator\n",
    "g = init_g(seed=seed)\n",
    "\n",
    "# inference object\n",
    "res_C = infer.SNPEC(g,\n",
    "                 obs=obs_stats,\n",
    "                 n_hiddens=n_hiddens,\n",
    "                 seed=seed,\n",
    "                 reg_lambda=reg_lambda,\n",
    "                 pilot_samples=pilot_samples,\n",
    "                 svi=svi,\n",
    "                 n_mades=n_mades, # providing this argument triggers usage of MAFs (vs. MDNs)\n",
    "                 act_fun=act_fun,\n",
    "                 mode=mode,\n",
    "                 rng=rng,\n",
    "                 batch_norm=batch_norm,\n",
    "                 verbose=verbose,\n",
    "                 prior_norm=prior_norm)\n",
    "\n",
    "# train\n",
    "t = timeit.time.time()\n",
    "\n",
    "logs_C, tds_C, posteriors_C = res_C.run(\n",
    "                    n_train=n_train,\n",
    "                    proposal='discrete',\n",
    "                    moo='resample',\n",
    "                    n_null = n_null,\n",
    "                    n_rounds=n_rounds,\n",
    "                    train_on_all=train_on_all,\n",
    "                    minibatch=minibatch,\n",
    "                    epochs=epochs)\n",
    "\n",
    "print('fitting time : ', timeit.time.time() - t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inspect results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for r in range(n_rounds):\n",
    "    plt.plot(logs_C[r]['loss'])\n",
    "    plt.show()\n",
    "\n",
    "for r in range(len(logs_C)):\n",
    "    \n",
    "    posterior_C = posteriors_C[r]\n",
    "    #posterior_C.ndim = posterior_A.ndim\n",
    "    \n",
    "    g = init_g(seed=42)\n",
    "    g.proposal = posterior_C\n",
    "    samples = np.array(g.draw_params(1000)) \n",
    "    \n",
    "    fig,_ = plot_pdf(dd.Gaussian(m=0.00000123*np.ones(pars_true.size), S=1e-30*np.eye(pars_true.size)), \n",
    "                   samples=samples.T,\n",
    "                   gt=pars_true, \n",
    "                   lims=[[0,10],[0,20],[0., 1./3.]],\n",
    "                   #lims=[0,10],\n",
    "                   resolution=100,\n",
    "                   ticks=True,\n",
    "                   figsize=(16,16));\n",
    "    \n",
    "    fig.suptitle('SNPE-C posterior estimates, round r = '+str(r+1), fontsize=14)\n",
    "    print('negative log-probability of ground-truth pars \\n', -posterior_C.eval(pars_true, log=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# marginal over summary statistics (plus best-fitting Gaussian approx.)\n",
    "- note that plot_pdf automatically chooses the axes limits according to the provided samples, i.e. by the outliers\n",
    "- hence large empty regions indicate that the simulator sometimes produces extreme outliers that may negatively affect the de-facto standard z-scoring done by SNPE and SNL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = tds_C[0][1]\n",
    "fig,_ = plot_pdf(dd.Gaussian(m=stats.mean(axis=0), S=np.cov(stats.T)), \n",
    "                   samples=stats.T,\n",
    "                   gt=((obs_stats-res_C.stats_mean)/res_C.stats_std).flatten(), \n",
    "                   ticks=True,\n",
    "                   resolution=100,\n",
    "                   figsize=(16,16));\n",
    "fig.suptitle('(pair-wise) marginal(s) over summary statistics from Gaussian model (already z-scored!)')\n",
    "#fig.savefig('/home/marcel/Desktop/mg1_summary_stats_marginals.pdf')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# results evaluation\n",
    "- copy-paste from SNL code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_prop_errs = calc_all_lprob_errs(pars_true, \n",
    "                                    n_samples=5000, \n",
    "                                    posteriors=posteriors_C, \n",
    "                                    init_g=init_g,\n",
    "                                    rej=True)\n",
    "\n",
    "all_prop_errs_raw = calc_all_lprob_errs(pars_true, \n",
    "                                    n_samples=5000, \n",
    "                                    posteriors=posteriors_C, \n",
    "                                    init_g=init_g,\n",
    "                                    rej=False)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.semilogx(np.arange(1, n_rounds+1) * n_train, np.array(all_prop_errs + [post_err]), 'bd:')\n",
    "plt.semilogx(np.arange(1, n_rounds+1) * n_train, np.array(all_prop_errs_raw + [post_err_raw]), 'kd:')\n",
    "plt.legend(['rej. sampling', 'naive sampling'])\n",
    "plt.axis([600, 22000, -1, 2])\n",
    "plt.xlabel('Number of simulations (log scale)')\n",
    "plt.ylabel('- log probability of true parameters')\n",
    "plt.title('effects of truncation on MAF')\n",
    "#plt.savefig('/home/marcel/Desktop/mg1_snpec_maf_n_null_10_N5000_MAF_truncation.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
