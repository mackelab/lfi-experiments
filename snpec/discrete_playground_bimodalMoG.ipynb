{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit\n",
    "\n",
    "import delfi.distribution as dd\n",
    "import delfi.inference as infer\n",
    "import delfi.generator as dg\n",
    "\n",
    "from delfi.simulator import GaussMixture\n",
    "import delfi.summarystats as ds\n",
    "from delfi.utils.viz import plot_pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# problem setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=42\n",
    "return_abs = False\n",
    "\n",
    "# analytic target posterior for plotting (y-axis flipped for overlay with imshow figures !)\n",
    "p_true = dd.MoG(a=[0.5, 0.5], \n",
    "                ms=[np.asarray([.5, -.5]), np.asarray([-.5, .5])], \n",
    "                Ss=[0.01*np.eye(2), 0.01*np.eye(2)])\n",
    "p_true.ndim=2\n",
    "\n",
    "\n",
    "# very basic approach to controlling generator seeds\n",
    "def init_g(seed):\n",
    "    m = GaussMixture(dim=2, bimodal=True, return_abs=return_abs, noise_cov=[0.01, 0.01], seed=seed)\n",
    "    p = dd.Uniform(lower=[-1,-1], upper=[1,1], seed=seed)\n",
    "    s = ds.Identity()\n",
    "    return dg.Default(model=m, prior=p, summary=s)\n",
    "\n",
    "g = init_g(seed=seed)\n",
    "\n",
    "obs_stats = np.array([[.5, -.5]])\n",
    "\n",
    "trn_data = g.gen(1000)\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(trn_data[1], trn_data[0], '.')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('theta(1) resp. theta(2)')\n",
    "plt.title('marginals p(theta_i, x)')\n",
    "plt.show()\n",
    "        \n",
    "# training schedule\n",
    "n_train=500\n",
    "n_rounds=10\n",
    "\n",
    "# fitting setup\n",
    "minibatch=100\n",
    "epochs=[500//(r+1) for r in range(n_rounds)]\n",
    "\n",
    "# network setup\n",
    "n_hiddens=[50,50]\n",
    "reg_lambda=0.01\n",
    "\n",
    "# convenience\n",
    "pilot_samples=0\n",
    "svi=False\n",
    "verbose=True\n",
    "prior_norm=False\n",
    "init_norm=False\n",
    "\n",
    "# SNPE-C parameters\n",
    "n_null = 1\n",
    "\n",
    "# MAF parameters\n",
    "mode='random' # ordering of variables for MADEs\n",
    "n_mades = 5 # number of MADES\n",
    "act_fun = 'tanh'\n",
    "batch_norm = False # batch-normalization currently not supported\n",
    "train_on_all = False\n",
    "\n",
    "# MDN parameters\n",
    "n_components = 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# discrete-proposal SNPE-C (MAF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# control MAF seed\n",
    "rng = np.random\n",
    "rng.seed(seed)\n",
    "\n",
    "# generator\n",
    "g = init_g(seed=seed)\n",
    "\n",
    "# inference object\n",
    "res = infer.SNPEC(g, \n",
    "                 obs=obs_stats, \n",
    "                 n_hiddens=n_hiddens, \n",
    "                 seed=seed, \n",
    "                 reg_lambda=reg_lambda,\n",
    "                 pilot_samples=pilot_samples,\n",
    "                 svi=svi,\n",
    "                 n_mades=n_mades, # providing this argument triggers usage of MAFs (vs. MDNs)\n",
    "                 act_fun=act_fun,\n",
    "                 mode=mode, \n",
    "                 rng=rng, \n",
    "                 batch_norm=batch_norm, \n",
    "                 verbose=verbose,\n",
    "                 prior_norm=prior_norm)\n",
    "\n",
    "# train\n",
    "\n",
    "t = timeit.time.time()\n",
    "\n",
    "logs, tds, posteriors = res.run(n_train=n_train, \n",
    "                    proposal='discrete',\n",
    "                    moo='q_phi_x',\n",
    "                    n_null = n_null,\n",
    "                    n_rounds=n_rounds,\n",
    "                    train_on_all=train_on_all,\n",
    "                    minibatch=minibatch, \n",
    "                    epochs=epochs)\n",
    "\n",
    "print(timeit.time.time() -  t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from delfi.utils.viz import probs2contours\n",
    "\n",
    "# plot loss curves\n",
    "plt.figure(figsize=(12, 8))\n",
    "for r in range(n_rounds):\n",
    "    plt.subplot(np.ceil(n_rounds/3), 3, r+1)\n",
    "    plt.plot(logs[r]['loss'])\n",
    "    plt.title('loss for round r=' + str(r+1))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# plot posterior estimates (overlaid with ground-truth)\n",
    "xo = 1.*obs_stats.flatten()\n",
    "lims = np.array([[-1,1], [-1,1]])\n",
    "i,j,resolution = 0,1,100\n",
    "xx = np.linspace(lims[i, 0], lims[i, 1], resolution)\n",
    "yy = np.linspace(lims[j, 0], lims[j, 1], resolution)\n",
    "X, Y = np.meshgrid(xx, yy)\n",
    "xy = np.concatenate(\n",
    "    [X.reshape([-1, 1]), Y.reshape([-1, 1])], axis=1)\n",
    "plt.figure(figsize=(16, 16))\n",
    "plt.subplot(np.ceil(n_rounds/3), 3, 1)\n",
    "pp = g.prior.eval(xy, log=False).reshape(list(X.shape))\n",
    "plt.imshow(0*pp.T, origin='lower',\n",
    "               extent=[lims[j, 0], lims[j, 1], lims[i, 0], lims[i, 1]],\n",
    "               aspect='auto', interpolation='none')\n",
    "pp = p_true.eval(xy, log=False).reshape(list(X.shape))\n",
    "plt.contour(Y, X, probs2contours(pp, levels=(0.68, 0.95)), levels=(0.68, 0.95), colors=('w', 'y'))\n",
    "plt.title('prior (real posterior overlaid)')\n",
    "for r in range(n_rounds):\n",
    "    plt.subplot(np.ceil(n_rounds/3), 3, r + 2)\n",
    "    posterior = posteriors[r] \n",
    "    pp = posterior.eval(xy, log=False).reshape(list(X.shape))\n",
    "    plt.imshow(pp.T, origin='lower',\n",
    "               extent=[lims[j, 0], lims[j, 1], lims[i, 0], lims[i, 1]],\n",
    "               aspect='auto', interpolation='none')\n",
    "    pp = p_true.eval(xy, log=False).reshape(list(X.shape))\n",
    "    plt.contour(Y, X, probs2contours(pp, levels=(0.68, 0.95)), levels=(0.68, 0.95), colors=('w', 'y'))\n",
    "    plt.title('posterior estimate after round r='+str(r+1))\n",
    "    #plt.savefig('/home/mackelab/Desktop/SNPE_10rounds_posterior_est.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# control MAF seed\n",
    "rng = np.random\n",
    "rng.seed(seed)\n",
    "\n",
    "# generator\n",
    "g = init_g(seed=seed)\n",
    "\n",
    "# inference object\n",
    "res = infer.SNPEC(g, \n",
    "                 obs=obs_stats, \n",
    "                 n_hiddens=n_hiddens, \n",
    "                 seed=seed, \n",
    "                 reg_lambda=reg_lambda,\n",
    "                 pilot_samples=pilot_samples,\n",
    "                 svi=svi,\n",
    "                 n_mades=n_mades, # providing this argument triggers usage of MAFs (vs. MDNs)\n",
    "                 act_fun=act_fun,\n",
    "                 mode=mode, \n",
    "                 rng=rng, \n",
    "                 batch_norm=batch_norm, \n",
    "                 verbose=verbose,\n",
    "                 prior_norm=prior_norm)\n",
    "\n",
    "# train\n",
    "\n",
    "t = timeit.time.time()\n",
    "\n",
    "logs, tds, posteriors = res.run(n_train=n_train, \n",
    "                    proposal='discrete',\n",
    "                    moo='p_tilda',\n",
    "                    n_null = n_null,\n",
    "                    n_rounds=n_rounds,\n",
    "                    train_on_all=train_on_all,\n",
    "                    minibatch=minibatch, \n",
    "                    epochs=epochs)\n",
    "\n",
    "print(timeit.time.time() -  t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from delfi.utils.viz import probs2contours\n",
    "\n",
    "# plot loss curves\n",
    "plt.figure(figsize=(12, 8))\n",
    "for r in range(n_rounds):\n",
    "    plt.subplot(np.ceil(n_rounds/3), 3, r+1)\n",
    "    plt.plot(logs[r]['loss'])\n",
    "    plt.title('loss for round r=' + str(r+1))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# plot posterior estimates (overlaid with ground-truth)\n",
    "xo = 1.*obs_stats.flatten()\n",
    "lims = np.array([[-1,1], [-1,1]])\n",
    "i,j,resolution = 0,1,100\n",
    "xx = np.linspace(lims[i, 0], lims[i, 1], resolution)\n",
    "yy = np.linspace(lims[j, 0], lims[j, 1], resolution)\n",
    "X, Y = np.meshgrid(xx, yy)\n",
    "xy = np.concatenate(\n",
    "    [X.reshape([-1, 1]), Y.reshape([-1, 1])], axis=1)\n",
    "plt.figure(figsize=(16, 16))\n",
    "plt.subplot(np.ceil(n_rounds/3), 3, 1)\n",
    "pp = g.prior.eval(xy, log=False).reshape(list(X.shape))\n",
    "plt.imshow(0*pp.T, origin='lower',\n",
    "               extent=[lims[j, 0], lims[j, 1], lims[i, 0], lims[i, 1]],\n",
    "               aspect='auto', interpolation='none')\n",
    "pp = p_true.eval(xy, log=False).reshape(list(X.shape))\n",
    "plt.contour(Y, X, probs2contours(pp, levels=(0.68, 0.95)), levels=(0.68, 0.95), colors=('w', 'y'))\n",
    "plt.title('prior (real posterior overlaid)')\n",
    "for r in range(n_rounds):\n",
    "    plt.subplot(np.ceil(n_rounds/3), 3, r + 2)\n",
    "    posterior = posteriors[r] \n",
    "    pp = posterior.eval(xy, log=False).reshape(list(X.shape))\n",
    "    plt.imshow(pp.T, origin='lower',\n",
    "               extent=[lims[j, 0], lims[j, 1], lims[i, 0], lims[i, 1]],\n",
    "               aspect='auto', interpolation='none')\n",
    "    pp = p_true.eval(xy, log=False).reshape(list(X.shape))\n",
    "    plt.contour(Y, X, probs2contours(pp, levels=(0.68, 0.95)), levels=(0.68, 0.95), colors=('w', 'y'))\n",
    "    plt.title('posterior estimate after round r='+str(r+1))\n",
    "    #plt.savefig('/home/mackelab/Desktop/SNPE_10rounds_posterior_est.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNL (MAF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import snl.inference.nde as nde\n",
    "from snl.ml.models.mafs import ConditionalMaskedAutoregressiveFlow\n",
    "from delfi.utils.delfi2snl import SNLprior, SNLmodel\n",
    "\n",
    "\n",
    "# control MAF seed\n",
    "rng = np.random\n",
    "rng.seed(seed)\n",
    "\n",
    "# explicit call to MAF constructor\n",
    "theta, x = g.gen(1)\n",
    "n_inputs, n_outputs  = x.size, theta.size\n",
    "model = ConditionalMaskedAutoregressiveFlow(\n",
    "                n_inputs=n_inputs,\n",
    "                n_outputs=n_outputs,\n",
    "                n_hiddens=n_hiddens,\n",
    "                act_fun=act_fun,\n",
    "                n_mades=n_mades,\n",
    "                mode=mode,\n",
    "                rng=rng)\n",
    "\n",
    "\n",
    "# generator\n",
    "g = init_g(seed=seed)\n",
    "\n",
    "# inference object\n",
    "inf = nde.SequentialNeuralLikelihood(SNLprior(g.prior),               # method to draw parameters  \n",
    "                                     SNLmodel(g.model, g.summary).gen # method to draw summary stats\n",
    "                                    )\n",
    "\n",
    "# train\n",
    "t = timeit.time.time()\n",
    "\n",
    "rng = np.random # control  \n",
    "rng.seed(seed)  # MCMC seed\n",
    "model = inf.learn_likelihood(obs_stats.flatten(), model, n_samples=n_train, n_rounds=n_rounds, \n",
    "                             train_on_all=True, thin=10, save_models=False, \n",
    "                             logger=sys.stdout, rng=rng)\n",
    "\n",
    "print(timeit.time.time() -  t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize learned likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snl.inference.mcmc as mcmc\n",
    "log_posterior = lambda t: model.eval([t, obs_stats.flatten()]) + inf.prior.eval(t)\n",
    "sampler = mcmc.SliceSampler(x=inf.all_ps[-1][-1], lp_f=log_posterior, thin=100)\n",
    "ps = sampler.gen(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xo = 1.*obs_stats.flatten()\n",
    "\n",
    "lims = np.array([[-1,1], [-1,1]])\n",
    "i,j,resolution = 0,1, 100\n",
    "        \n",
    "xx = np.linspace(lims[i, 0], lims[i, 1], resolution)\n",
    "yy = np.linspace(lims[j, 0], lims[j, 1], resolution)\n",
    "X, Y = np.meshgrid(xx, yy)\n",
    "xy = np.concatenate(\n",
    "    [X.reshape([-1, 1]), Y.reshape([-1, 1])], axis=1)\n",
    "pp = model.eval((xo, xy), log=False).reshape(list(X.shape))\n",
    "\n",
    "plt.imshow(pp.T, origin='lower',\n",
    "           extent=[lims[j, 0], lims[j, 1], lims[i, 0], lims[i, 1]],\n",
    "           aspect='auto', interpolation='none')\n",
    "#plt.savefig('/home/mackelab/Desktop/SNL_5rounds_final_likelihood_tightll.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,11))\n",
    "for r in range(n_rounds):\n",
    "    plt.subplot(np.ceil(n_rounds/3), 3, r + 1)\n",
    "    plt.plot(inf.all_ps[r][:,0],\n",
    "             inf.all_ps[r][:,1], 'k.')\n",
    "    plt.axis([-1,1,-1,1])\n",
    "    plt.xlabel('theta1')\n",
    "    plt.xlabel('theta2')\n",
    "    plt.title('round r='+str(r))\n",
    "\n",
    "plt.subplot(np.ceil(n_rounds/3), 3, n_rounds+1)\n",
    "plt.plot(ps[:,0],\n",
    "         ps[:,1], 'k.')\n",
    "plt.axis([-1,1,-1,1])\n",
    "plt.xlabel('theta1')\n",
    "plt.xlabel('theta2')\n",
    "plt.title('round r='+str(n_rounds))\n",
    "#plt.savefig('/home/mackelab/Desktop/posteriors_per_round_tightll.pdf')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNPE A (always MDN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# generator\n",
    "g = init_g(seed=seed)\n",
    "\n",
    "# inference object\n",
    "res_A = infer.CDELFI(g, \n",
    "                 obs=obs_stats, \n",
    "                 n_hiddens=n_hiddens, \n",
    "                 n_components=n_components,\n",
    "                 seed=seed, \n",
    "                 reg_lambda=reg_lambda,\n",
    "                 pilot_samples=pilot_samples,\n",
    "                 svi=svi,\n",
    "                 verbose=verbose,\n",
    "                 init_norm=init_norm,\n",
    "                 prior_norm=prior_norm)\n",
    "\n",
    "# train\n",
    "t = timeit.time.time()\n",
    "\n",
    "logs_A, tds_A, posteriors_A = res_A.run(n_train=n_train, \n",
    "                    n_rounds=n_rounds, \n",
    "                    minibatch=minibatch, \n",
    "                    epochs=np.max(epochs))\n",
    "\n",
    "print(timeit.time.time() -  t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# discrete-proposal SNPE C (MDN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator\n",
    "g = init_g(seed=seed)\n",
    "\n",
    "# inference object\n",
    "res_C = infer.SNPEC(g, \n",
    "                 obs=obs_stats, \n",
    "                 n_hiddens=n_hiddens, \n",
    "                 n_components=n_components,\n",
    "                 seed=seed, \n",
    "                 reg_lambda=reg_lambda,\n",
    "                 pilot_samples=pilot_samples,\n",
    "                 svi=svi,\n",
    "                 verbose=verbose,\n",
    "                 prior_norm=prior_norm)\n",
    "\n",
    "# train\n",
    "t = timeit.time.time()\n",
    "\n",
    "logs_C, tds_C, posteriors_C = res_C.run(n_train=n_train, \n",
    "                    proposal='discrete',\n",
    "                    moo='resample',\n",
    "                    n_null = n_null,\n",
    "                    n_rounds=n_rounds, \n",
    "                    minibatch=minibatch, \n",
    "                    epochs=epochs)\n",
    "\n",
    "print(timeit.time.time() -  t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian-proposal SNPE-C (MDN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator\n",
    "g = init_g(seed=seed)\n",
    "\n",
    "# inference object\n",
    "res_gC = infer.SNPEC(g, \n",
    "                 obs=obs_stats, \n",
    "                 n_hiddens=n_hiddens, \n",
    "                 n_components=n_components,\n",
    "                 seed=seed, \n",
    "                 reg_lambda=reg_lambda,\n",
    "                 pilot_samples=pilot_samples,\n",
    "                 svi=svi,\n",
    "                 verbose=verbose,\n",
    "                 prior_norm=prior_norm)\n",
    "\n",
    "# train\n",
    "t = timeit.time.time()\n",
    "\n",
    "logs_gC, tds_gC, posteriors_gC = res_gC.run(n_train=n_train, \n",
    "                    proposal='gaussian',\n",
    "                    n_rounds=n_rounds, \n",
    "                    minibatch=minibatch, \n",
    "                    epochs=epochs)\n",
    "\n",
    "print(timeit.time.time() -  t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## direct comparison SNPE-C against SNPE-A (both MDN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for r in range(n_rounds):\n",
    "    fig,_ = plot_pdf(posteriors_A[r],\n",
    "             pdf2=posteriors_C[r],\n",
    "             lims=[[-1,1],[-1,1]],\n",
    "             ticks=True,             \n",
    "             #pdf2=g.prior,\n",
    "             #gt=np.array([5,-5]), \n",
    "             resolution=100,\n",
    "             figsize=(16,16));\n",
    "    fig.suptitle('final posterior estimate vs MCMC samples and prior', fontsize=14)\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
