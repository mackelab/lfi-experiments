{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# blob\n",
    "\n",
    "\n",
    "- blob example as simple multivariate posterior estimation problem for convolutional MDNs\n",
    "- setup and code from kSNPE arxiv-paper\n",
    "\n",
    "\n",
    "- requires the NeuralNet.py from the dev branch of Marcel Nonnenmacher's delfi fork, mnonnenm/delfi/dev !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "import scipy.stats as stats\n",
    "\n",
    "from scipy.special import gammaln\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import delfi.generator as dg\n",
    "import delfi.distribution as dd\n",
    "from delfi.utils.viz import plot_pdf\n",
    "import delfi.inference as infer\n",
    "\n",
    "seed = 42\n",
    "M = 32  # edge dimensionality of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting Gaussian posteriors to uniform priors can be ugly. Here transform back and forth from logit-space. \n",
    "\n",
    "def expit17(x):\n",
    "        return 34. / (1. + np.exp(-x)) -17\n",
    "\n",
    "def expit5(x):\n",
    "        return 4.85 / (1. + np.exp(-x)) + 0.2\n",
    "    \n",
    "def logit17(x):\n",
    "        x = (x+17.)/34.\n",
    "        return np.log( x / (1. - x) )\n",
    "    \n",
    "def logit5(x):\n",
    "        x = (x-0.2)/4.85\n",
    "        return np.log( x / (1. - x) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from delfi.simulator.BaseSimulator import BaseSimulator\n",
    "\n",
    "\n",
    "\n",
    "## prior \n",
    "\n",
    "#p = dd.Uniform(lower = [-16, -16, 0.25 ],  # prior if *not* switching\n",
    "#               upper = [ 16,  16,    5 ])  # into scaled logit-space !\n",
    "\n",
    "p = dd.Gaussian(m = np.zeros(3), S=1.78 * np.eye(3), seed=seed)\n",
    "\n",
    "\n",
    "\n",
    "## simulator\n",
    "\n",
    "class Blob(BaseSimulator): \n",
    "\n",
    "    def __init__(self, M, N, dim=p.ndim, seed=42, sigma=None):\n",
    "        super().__init__(dim_param=dim, seed=seed)\n",
    "        self.M = M\n",
    "        self.N = N\n",
    "        \n",
    "        self.sigma = sigma\n",
    "        self.x, self.y = np.meshgrid(np.linspace(-M//2, M//2, M),\n",
    "                           np.linspace(-M//2, M//2, M))        \n",
    "\n",
    "    def gen_single(self, params):\n",
    "        \n",
    "        if self.sigma is None:\n",
    "            assert params.size == 4\n",
    "            xo, yo, gamma, sigma = params[0], params[1], params[2], params[3]\n",
    "        else: \n",
    "            assert params.size == 3\n",
    "            xo, yo, gamma, sigma = params[0], params[1], params[2], self.sigma        \n",
    "            \n",
    "        xo, yo, gamma = expit17(xo), expit17(yo), expit5(gamma)\n",
    "        \n",
    "        r = (self.x - xo)**2 + (self.y - yo)**2\n",
    "        p = 0.1 + 0.8 * np.exp(-0.5 * (r / sigma**2) ** gamma)\n",
    "        \n",
    "        return {'data' : nr.binomial(self.N, p).reshape(1,-1) / self.N }\n",
    "\n",
    "    \n",
    "    \n",
    "## summary statistics\n",
    "    \n",
    "class Summary(object): \n",
    "    # Identity + reshape\n",
    "    def calc(self, x):\n",
    "        return x[0]['data'].reshape(1, M, M)\n",
    "    \n",
    "    \n",
    "    \n",
    "## generator\n",
    "    \n",
    "g = dg.Default(model= Blob(M, N=255, sigma=2., seed=seed), prior = p, summary = Summary(), seed = seed+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars_true = np.array([ logit17(7.2), logit17(4.4), logit5(1.6) ])\n",
    "obs = g.model.gen_single(pars_true)\n",
    "obs_stats = g.summary.calc([obs])\n",
    "\n",
    "plt.imshow(obs_stats.reshape(M,M), interpolation='None')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# network architecture: 8 layer network [4x conv, 3x fully conn., 1x MoG], 20k parameters in total \n",
    "\n",
    "filter_sizes=[3,3,3,2,2]   # 5 conv ReLU layers\n",
    "n_filters=(16,16,32,32,32) # 16 to 64 filters\n",
    "pool_sizes=[1,2,2,2,1,2]     # \n",
    "n_hiddens=[50,50]     # 3 fully connected layers\n",
    "\n",
    "# N = 100k per round\n",
    "\n",
    "n_train=5000\n",
    "\n",
    "# single component (posterior at most STAs is well-approximated by single Gaussian - we also want to run more SNPE-A)\n",
    "\n",
    "n_components=1\n",
    "\n",
    "# single rounds (first round is always'amortized' and can be used with any other STA covered by the prior)\n",
    "\n",
    "n_rounds=5\n",
    "\n",
    "# new feature for CNN architectures: passing a value directly to the hidden layers (bypassing the conv layers).\n",
    "# In this case, we pass the number of spikes (single number) directly, which allows to normalize the STAs \n",
    "# and hence help out the conv layers. Without that extra input, we couldn't recover the RF gain anymore. \n",
    "n_inputs_hidden = 0\n",
    "\n",
    "# some learning-schedule parameters\n",
    "lr_decay = 0.999\n",
    "epochs=10\n",
    "minibatch=50\n",
    "\n",
    "svi=False          # large N should make this do nothing anyways\n",
    "reg_lambda=0.0   # just to make doubly sure SVI is switched off...\n",
    "\n",
    "pilot_samples=None # z-scoring only applies to extra inputs (here: firing rate) directly fed to fully connected layers\n",
    "\n",
    "prior_norm = False  # doesn't hurt. \n",
    "init_norm = False  # didn't yet figure how to best normalize initialization through conv- and ReLU- layers\n",
    "\n",
    "rank = None   # fitting only DIAGONAL covariances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf = infer.SNPEC(generator=g, obs=obs_stats, prior_norm=prior_norm, init_norm=init_norm,\n",
    "                 pilot_samples=pilot_samples, seed=seed, reg_lambda=reg_lambda, svi=svi,\n",
    "                 n_components=1, n_hiddens=n_hiddens, n_filters=n_filters, n_inputs = (1,M,M),\n",
    "                 filter_sizes=filter_sizes, pool_sizes=pool_sizes, n_inputs_hidden=n_inputs_hidden,\n",
    "                 rank=rank, verbose=True)\n",
    "\n",
    "log, trn_data, posteriors = inf.run(n_train=n_train, epochs=epochs, minibatch=minibatch, n_rounds=n_rounds,  \n",
    "                   lr_decay=lr_decay, moo='q_phi_x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print parameter numbers per layer (just weights, not biases)\n",
    "def get_shape(i):\n",
    "    return inf.network.aps[i].get_value().shape\n",
    "print([get_shape(i) for i in range(1,17,2)])\n",
    "print([np.prod(get_shape(i)) for i in range(1,17,2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in range(n_rounds):\n",
    "    \n",
    "    plt.figure(figsize=(16,3))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(log[r]['loss'])\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.semilogx(log[r]['loss'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labels_params = ['xo', 'yo', 'gamma'] \n",
    "posterior = inf.predict(obs_stats)\n",
    "posterior = dd.mixture.MoTG(ms=[x.m for x in posterior.xs],Ss=[x.S for x in posterior.xs],a = posterior.a,\n",
    "                            flags=[2,2,2],upper=[17,17,5.05],lower=[-17,-17,0.2])\n",
    "\n",
    "pars_raw = np.array( [ 7.2, 4.4, 1.6 ] )\n",
    "\n",
    "fig, _ = plot_pdf(posterior, lims=[[-10, 10], [-10, 10], [0.25, 5]], gt=pars_raw.reshape(-1),  \n",
    "                  figsize=(16,16), resolution=100,labels_params=labels_params, ticks=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
