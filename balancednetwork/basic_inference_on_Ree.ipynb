{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import delfi.distribution as dd\n",
    "import delfi.generator as dg\n",
    "import delfi.inference as infer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import time \n",
    "\n",
    "from lfimodels.balancednetwork.BalancedNetworkSimulator import BalancedNetwork\n",
    "from lfimodels.balancednetwork.BalancedNetworkStats import BalancedNetworkStats\n",
    "from lfimodels.balancednetwork.BalancedNetworkGenerator import BalancedNetworkGenerator\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the objects we need for the simulation: \n",
    "\n",
    "model, prior, summarystats, a generator to combine it all\n",
    "\n",
    "The parameter we use for the balanced network simulation is the clustering coef $R_{ee}$. For now we want this to be very close around 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_params = 1\n",
    "\n",
    "m = BalancedNetwork(dim=n_params, first_port=8010, \n",
    "                    verbose=False, n_servers=4, duration=3.)\n",
    "p = dd.Uniform(lower=[1.], upper=[5.])\n",
    "s = BalancedNetworkStats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = BalancedNetworkGenerator(model=m, prior=p, summary=s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a test by running one sample = one simulation \n",
    "\n",
    "The generator returns the params used and the correspoding stats: the theta-x tuples used by the MDN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# here we set the true params \n",
    "true_params = [[2.5]]\n",
    "# run forward model \n",
    "data = m.gen(true_params)\n",
    "# get summary stats\n",
    "stats_obs = s.calc(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(true_params, stats_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(true_params, stats_obs, 'o')\n",
    "plt.legend(['rate', 'ff', 'rho']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up inference\n",
    "res = infer.Basic(g)\n",
    "ntrain = 50\n",
    "# run with N samples, for N=100 this will take 2000s = 0.6h\n",
    "out = res.run(ntrain, epochs=1000, minibatch=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(out['trn_iter'], out['trn_val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the result: generate an observation and compare it to simulations from the posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluate the posterior at the observed data \n",
    "posterior = res.predict(stats_obs)\n",
    "# get the mean and std \n",
    "mean = posterior.xs[0].m[0]\n",
    "std = np.sqrt(posterior.xs[0].S[0][0])\n",
    "print(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up a dict for saving the results \n",
    "save_data = False \n",
    "path_to_save_folder = 'data/'\n",
    "if save_data and os.path.exists(path_to_save_folder): \n",
    "    nrounds=1\n",
    "    result_dict = dict(true_params=true_params, stats_obs=stats_obs, nrouns=nrounds, ntrain=ntrain,\n",
    "                       posterior=dict(mean=mean, std=std))\n",
    "    filename = os.path.join(path_to_save_folder, \n",
    "                           '{}_basic_ntrain{}'.format(time.time(), ntrain).replace('.', '') + '.p')\n",
    "    with open(filename, 'wb') as handle:\n",
    "        pickle.dump(result_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "theta = np.linspace(0, 5, 1000)\n",
    "post_pdf = st.norm.pdf(x=theta, loc=mean, scale=std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(theta, post_pdf, label='$\\hat{p}( theta | x=x_{obs})$')\n",
    "plt.axvline(x=true_params[0], label='true theta', linestyle='--', color='C1')\n",
    "plt.legend()\n",
    "plt.xlabel('$R_{ee}$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mackelab]",
   "language": "python",
   "name": "conda-env-mackelab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
