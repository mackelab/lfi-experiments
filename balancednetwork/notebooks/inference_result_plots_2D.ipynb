{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting inference results for multidimensional posteriors \n",
    "\n",
    "In order to use this notebook you need data files stored in a folder `lfi-experiments/balancednetwork/data`. \n",
    "\n",
    "For saving the figures you should create a folder `lfi-experiments/balancednetwork/figures`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import scipy.stats as st\n",
    "import os \n",
    "from lfimodels.balancednetwork.BalancedNetworkSimulator import BalancedNetwork\n",
    "from lfimodels.balancednetwork.BalancedNetworkStats import BalancedNetworkStats, Identity\n",
    "import delfi.distribution as dd\n",
    "\n",
    "mpl_params = {'legend.fontsize': 14,\n",
    "                      'axes.titlesize': 20,\n",
    "                      'axes.labelsize': 17,\n",
    "                      'xtick.labelsize': 12,\n",
    "                      'ytick.labelsize': 12,\n",
    "             'figure.figsize' : (15, 5)}\n",
    "\n",
    "mpl.rcParams.update(mpl_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from delfi.utils.viz import probs2contours, plot_pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and extract posterior object\n",
    "\n",
    "data file should be in `lfi-experiments/balancednetwork/data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inference_method = 'snpe'\n",
    "filename = '15162969944576585_snpe_cJieii_r3_n8000_rcl3'\n",
    "file_string = 'Jieii'\n",
    "weight_labels = [r'$J^{IE}$', r'$J^{II}$']\n",
    "dpi = 300\n",
    "\n",
    "save_figure = True\n",
    "path_to_save_folder = '../results/' + filename\n",
    "\n",
    "time_str = filename[:filename.find('_')]\n",
    "filename.find('_')\n",
    "fullname = os.path.join('../results/', filename, filename + '.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data \n",
    "assert os.path.exists(fullname), 'path not found: {}. data file should be in lfi-experiments/balancednetwork/data'.format(fullname)\n",
    "with open(fullname, 'rb') as handle:\n",
    "    result_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpack values \n",
    "true_params, stats_obs, nrounds, ntrain, seed, posterior, out, trn_data, prior, posterior_list = result_dict.values()\n",
    "dim_params = len(true_params)\n",
    "assert dim_params > 1, 'this notebook is for inference on more than 1 parameter.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract the posterior \n",
    "n_components = len(posterior.a)\n",
    "means = [posterior.xs[c].m for c in range(n_components)]\n",
    "Ss = [posterior.xs[c].S for c in range(n_components)]\n",
    "\n",
    "# mixing coefs \n",
    "mixing_coefs = posterior.a\n",
    "\n",
    "# construct posterior\n",
    "post = dd.mixture.MoG(posterior.a, ms=means, Ss=Ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(posterior.mean)\n",
    "print(true_params)\n",
    "print(Ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to true parameter \n",
    "\n",
    "We have generated the observed data ourselves so we do have the true parameter. The mean of the posterior should be close to it when evaluated for $x=x_{obs}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_flag = False\n",
    "use_custom_ranges = False\n",
    "\n",
    "# mass isolines to plot \n",
    "levels = [0.68]\n",
    "\n",
    "# get grid of sampling points\n",
    "lims = [-10., 10.]\n",
    "resolution = (lims[1] - lims[0]) / 1000\n",
    "n_steps = int((lims[1] - lims[0])/ resolution)\n",
    "theta = np.linspace(lims[0], lims[1], n_steps)    \n",
    "x, y = np.meshgrid(theta, theta)\n",
    "    \n",
    "# arrange samples in rows \n",
    "v = np.vstack((x.flatten(), y.flatten())).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plot_idx = 1\n",
    "\n",
    "for i in range(dim_params): \n",
    "    for j in range(dim_params): \n",
    "        \n",
    "        if i == j: \n",
    "            plt.subplot(dim_params, dim_params, plot_idx)\n",
    "                        \n",
    "            if not use_custom_ranges:\n",
    "                # define limits from the corresponding prior \n",
    "                lims = [prior.lower[j], prior.upper[j]]\n",
    "                theta = np.linspace(lims[0], lims[1], n_steps)\n",
    "                \n",
    "            plt.plot(theta, post.eval(x=theta.T, log=log_flag, ii=[i]), label='posterior')\n",
    "            plt.axvline(x=true_params[i], color='C1', label='true ' + weight_labels[i])\n",
    "            plt.legend(prop=dict(size=14))\n",
    "            plt.xlabel(weight_labels[i])        \n",
    "        elif i < j:                     \n",
    "            \n",
    "            if not use_custom_ranges: \n",
    "                # define limits from the corresponding prior\n",
    "                lims_i = [prior.lower[i], prior.upper[i]]\n",
    "                lims_j = [prior.lower[j], prior.upper[j]]\n",
    "                \n",
    "                x, y = np.meshgrid(np.linspace(lims_i[0], lims_i[1], n_steps), \n",
    "                                   np.linspace(lims_j[0], lims_j[1], n_steps))\n",
    "                v = np.vstack((x.flatten(), y.flatten())).T\n",
    "            else: \n",
    "                lims_i = lims \n",
    "                lims_j = lims\n",
    "            \n",
    "            z = post.eval(x=v, log=log_flag, ii=[i, j]).reshape(x.shape)\n",
    "            \n",
    "            dm = ((lims_i[1] - lims_i[0]) / 1000) * ((lims_j[1] - lims_j[0]) / 1000)\n",
    "            print('mass: ', z.sum() * dm)\n",
    "                \n",
    "            cl = probs2contours(z.flatten(), levels=levels).reshape(x.shape)\n",
    "            \n",
    "            x_mask = np.logical_and(x >= lims_i[0], x <= lims_i[1])\n",
    "            y_mask = np.logical_and(y >= lims_j[0], y <= lims_j[1])\n",
    "            z_mask = np.logical_and(x_mask, y_mask)\n",
    "            \n",
    "            size = int(np.sqrt(z_mask.sum()))\n",
    "            z_new = z.flatten()[z_mask.flatten()].reshape(size, size)\n",
    "            x_new = x.flatten()[z_mask.flatten()].reshape(size, size)\n",
    "            y_new = y.flatten()[z_mask.flatten()].reshape(size, size)\n",
    "            cl_new = cl.flatten()[z_mask.flatten()].reshape(size, size)\n",
    "            \n",
    "            plt.subplot(dim_params, dim_params, plot_idx)\n",
    "            plt.contourf(y_new, x_new, z_new)\n",
    "            plt.contour(y_new, x_new, cl_new, levels)\n",
    "#            plt.colorbar() \n",
    "            plt.plot([true_params[j]], [true_params[i]], 'o', color='C1')\n",
    "        plot_idx += 1\n",
    "plt.tight_layout()\n",
    "\n",
    "if save_figure and os.path.exists(path_to_save_folder): \n",
    "    addon = ''\n",
    "    filename = time_str + '_{}_posteriormatrix_{}_r{}_ntrain{}_e'.format(inference_method, \n",
    "                                                                         file_string, \n",
    "                                                                         nrounds, \n",
    "                                                                         ntrain) + addon + '.png'\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(path_to_save_folder, filename), dpi=dpi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot summary statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titles_short = ['ffE', 'ffI', 'rateE', 'rateI', 'kurtE', 'kurtI', 'corrE', 'corrI',\n",
    "                                    'EE', 'EI', 'II',\n",
    "                                    'EE', 'EI', 'IE', 'II',\n",
    "                                    'EE', 'EI', 'IE', 'II']\n",
    "titles = ['Fano factor E', 'Fano factor I', 'mean rate E', 'mean rate I', \n",
    "          'kurtosis E', 'kurtosis I', 'positive pairwise corr E', 'positive pairwise corr I',\n",
    "          '0 lag auto corr EE', '0 lag auto corr II', '0 lag cross corr EI',  \n",
    "          '10 lag auto corr EE', '10 lag cross corr EI', '10 lag cross corr IE', '10 lag auto corr II',\n",
    "          '20 lag auto corr EE', '20 lag cross corr EI', '20 lag cross corr IE', '20 lag auto corr II']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot stat values resulting from the initial prior sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 10))\n",
    "\n",
    "for stat_idx in range(19):\n",
    "    \n",
    "    params, stats, wtf = trn_data[0]\n",
    "    \n",
    "    plt.subplot(4, 5, stat_idx + 1)\n",
    "    plt.scatter(x=params[:, 0], y=params[:, 1], c=stats[:, stat_idx], cmap='viridis')    \n",
    "    plt.title(titles[stat_idx])\n",
    "    \n",
    "    cb = plt.colorbar(fraction=0.2, shrink=1.1, pad=0.1, aspect=10, orientation='vertical')\n",
    "    \n",
    "    #  labels \n",
    "    if stat_idx in [0, 5, 10, 15]: \n",
    "        plt.ylabel(weight_labels[1])\n",
    "    if stat_idx > 14: \n",
    "        plt.xlabel(weight_labels[0])\n",
    "    \n",
    "plt.tight_layout()\n",
    "if save_figure and os.path.exists(path_to_save_folder): \n",
    "    filename = time_str + '_{}_statsprior_{}_r{}_ntrain{}_'.format(inference_method, \n",
    "                                                                   file_string, \n",
    "                                                                   nrounds, ntrain) + '.png'\n",
    "    plt.savefig(os.path.join(path_to_save_folder, filename), dpi=dpi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot summary stats over rounds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_stats = 4\n",
    "n_rounds = 3\n",
    "step = int(nrounds / n_rounds)\n",
    "rounds = np.arange(0, nrounds, step)\n",
    "n_rounds = rounds.size\n",
    "\n",
    "plt.figure(figsize=(18, 10))\n",
    "for i in range(n_stats):\n",
    "       \n",
    "    # iterate over rounds\n",
    "    for j_idx, j in enumerate(rounds):\n",
    "        # extract round data \n",
    "        r_data = trn_data[j]\n",
    "        # get arrays \n",
    "        r_params, r_stats, r_wtf = r_data\n",
    "\n",
    "        # define colorbar norm for stats \n",
    "        stats = r_stats[:, i]\n",
    "        norm = mpl.colors.Normalize(vmin=stats.min(), vmax=stats.max())\n",
    "        \n",
    "        # add labels \n",
    "        plt.subplot(n_stats, n_rounds, (i * n_rounds) + j_idx + 1)\n",
    "        if j == 0: \n",
    "            plt.ylabel(weight_labels[1])\n",
    "        if i == 0: \n",
    "            plt.title('round {}'.format(j))\n",
    "            \n",
    "        # plot\n",
    "        plt.scatter(x=r_params[:, 0], y=r_params[:, 1], c=stats, cmap='viridis', norm=norm)\n",
    "        \n",
    "        if j_idx == (n_rounds - 1): \n",
    "            # add colorbar for every stats\n",
    "            cb = plt.colorbar(fraction=0.2, shrink=1.2, pad=0.1, aspect=10, orientation='vertical')\n",
    "            cb.set_label(titles[i], fontsize=15, rotation='vertical')\n",
    "\n",
    "        if i == (n_stats - 1): \n",
    "            plt.xlabel(weight_labels[0])\n",
    "    \n",
    "plt.tight_layout();\n",
    "if save_figure and os.path.exists(path_to_save_folder): \n",
    "    filename = time_str + '_{}_statsOverRounds_{}_r{}_ntrain{}_'.format(inference_method, \n",
    "                                                                        file_string, \n",
    "                                                                        nrounds, \n",
    "                                                                        ntrain) + addon + '.png'\n",
    "    plt.savefig(os.path.join(path_to_save_folder, filename), dpi=dpi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Posterior predictive checking: \n",
    "\n",
    "Sample from the estimated posterior and simulate with the sampled parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2\n",
    "param_names = ['wie', 'wii']\n",
    "m = BalancedNetwork(inference_params=param_names, dim=2, first_port=8100,\n",
    "                    verbose=True, n_servers=3, duration=3., parallel=True,\n",
    "                    estimate_time=False, calculate_stats=True, seed=seed)\n",
    "s = Identity(seed=seed)\n",
    "# generate observed stats from true params using the same seed \n",
    "stats_obs = s.calc_all(m.gen([true_params]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a few samples and simulate \n",
    "n_samples = 5\n",
    "params = []\n",
    "# append the mean\n",
    "params.append(post.mean)\n",
    "for i in range(n_samples): \n",
    "    params.append(post.gen())\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate \n",
    "data = m.gen(params)\n",
    "m.stop_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate summary stats\n",
    "stats = np.array(s.calc_all(data)).squeeze()\n",
    "stats_normed = ((stats - stats_obs) / stats_obs).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additionally generate 5 samples using the true params but different seeds: \n",
    "m = BalancedNetwork(inference_params=param_names, dim=2, first_port=8100,\n",
    "                    verbose=True, n_servers=3, duration=3., parallel=True,\n",
    "                    estimate_time=False, calculate_stats=True, seed=None)\n",
    "s = Identity(seed=None)\n",
    "# simulate and calc stats\n",
    "stats_obs_var = s.calc_all(m.gen(5 * [true_params]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stats_obs_var = np.array(stats_obs_var).squeeze()\n",
    "# normalize by initial stats_obs \n",
    "stats_var_normed = ((stats_obs_var - stats_obs) / stats_obs).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "titles = ['mean'] + n_samples * ['sample']\n",
    "\n",
    "for i in range(n_samples + 1): \n",
    "    if i==0: \n",
    "        plt.title('Summary stats of posterior mean and 5 samples, normalized by observed stats')\n",
    "        plt.plot(stats_normed[i, ], 'o-', label='posterior', color='C0'.format(i), lw=3., ms=8.)\n",
    "    else: \n",
    "        plt.plot(stats_normed[i, ], 'o-', color='C0'.format(i), alpha=0.5, label='_no_legend_')\n",
    "    plt.legend()\n",
    "    plt.xticks(np.arange(19), [])\n",
    "plt.grid()\n",
    "plt.ylim([-3., 3.])\n",
    "\n",
    "# plot the variability with different seeds \n",
    "for i in range(5): \n",
    "    plt.plot(stats_var_normed[i, :], '*-', alpha=.7, color='C1', \n",
    "             label='true params, different seeds' if not i else '_no_legend_')\n",
    "    \n",
    "plt.legend()\n",
    "\n",
    "    \n",
    "plt.xticks(np.arange(19), ['ffE', 'ffI', 'rateE', 'rateI', 'kurtE', 'kurtI', 'corrE', 'corrI',\n",
    "                                    'EE', 'EI', 'II',\n",
    "                                    '10 EE', '10 EI', '10 IE', '10 II',\n",
    "                                    '20 EE', '20 EI', '20 IE', '20 II'], rotation='vertical')\n",
    "\n",
    "plt.tight_layout();\n",
    "\n",
    "if save_figure and os.path.exists(path_to_save_folder): \n",
    "    addon = ''\n",
    "    filename = time_str + '_{}_predictiveChecks_{}_r{}_ntrain{}_'.format(inference_method, \n",
    "                                                                         file_string, \n",
    "                                                                         nrounds, \n",
    "                                                                         ntrain) + addon + '.png'\n",
    "    plt.savefig(os.path.join(path_to_save_folder, filename), dpi=dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mackelab]",
   "language": "python",
   "name": "conda-env-mackelab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
