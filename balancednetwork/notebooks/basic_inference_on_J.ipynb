{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import delfi.distribution as dd\n",
    "import delfi.generator as dg\n",
    "import delfi.inference as infer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import scipy.stats as st\n",
    "import time \n",
    "\n",
    "from lfimodels.balancednetwork.BalancedNetworkSimulator import BalancedNetwork\n",
    "from lfimodels.balancednetwork.BalancedNetworkStats import BalancedNetworkStats\n",
    "from lfimodels.balancednetwork.BalancedNetworkGenerator import BalancedNetworkGenerator\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the objects we need for the simulation: \n",
    "\n",
    "model, prior, summarystats, a generator to combine it all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_params = 4\n",
    "n_cores_to_use = 4\n",
    "\n",
    "m = BalancedNetwork(dim=n_params, first_port=8010, \n",
    "                    verbose=True, n_servers=n_cores_to_use, duration=3.)\n",
    "p = dd.Uniform(lower=[0.01] * n_params, upper=[0.1] * n_params)\n",
    "s = BalancedNetworkStats(n_workers=n_cores_to_use)\n",
    "g = BalancedNetworkGenerator(model=m, prior=p, summary=s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make an observation by running the parameters from the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we set the true params \n",
    "true_params = [[0.024, 0.045, 0.014, 0.057]]  # params from the paper \n",
    "# run forward model \n",
    "data = m.gen(true_params)\n",
    "# get summary stats\n",
    "stats_obs = s.calc(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(true_params, stats_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up inference\n",
    "res = infer.Basic(g, n_components=3, pilot_samples=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = 10\n",
    "# run with N samples\n",
    "out, trn_data = res.run(ntrain, epochs=1000, minibatch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(out['loss']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m.stop_server()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the result: plot the result posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the posterior at the observed data \n",
    "posterior = res.predict(stats_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a dict for saving the results \n",
    "save_data = True\n",
    "path_to_save_folder = 'data/'  # has to exist on your local path\n",
    "\n",
    "if save_data and os.path.exists(path_to_save_folder): \n",
    "    nrounds=1\n",
    "    result_dict = dict(true_params=true_params, stats_obs=stats_obs, nrouns=nrounds, ntrain=ntrain,\n",
    "                       posterior=posterior, out=out, trn_data=trn_data)\n",
    "    \n",
    "    filename = os.path.join(path_to_save_folder, \n",
    "                           '{}_basic_ntrain{}'.format(time.time(), ntrain).replace('.', '') + '.p')\n",
    "    with open(filename, 'wb') as handle:\n",
    "        pickle.dump(result_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract the posterior \n",
    "n_components = len(posterior.a)\n",
    "means = [posterior.xs[c].m for c in range(n_components)]\n",
    "Ss = [posterior.xs[c].S for c in range(n_components)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_delfi_grid_pdf(theta, delfi_obj, log=False): \n",
    "    \"\"\"\n",
    "    Get pdf of a whole grid of values \n",
    "    \"\"\"\n",
    "    x, y = np.meshgrid(theta, theta)\n",
    "    z = np.zeros_like(x)\n",
    "    for i in range(z.shape[0]): \n",
    "        # arrange the samples in rows \n",
    "        v = np.array([x[i, :], y[i, :]]).T\n",
    "        # evaluate the pdf for rows of z\n",
    "        z[i, :] = delfi_obj.eval(x=v, log=log)\n",
    "    return x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_params = n_params \n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "theta = np.linspace(0.01, 0.1, 100)\n",
    "weight_labels = ['$J^{EE}$', '$J^{EI}$', '$J^{IE}$', '$J^{II}$']\n",
    "plot_idx = 1\n",
    "for i in range(dim_params): \n",
    "    for j in range(dim_params): \n",
    "        if i==j: \n",
    "            \n",
    "            # define a 1D MoG\n",
    "            sub_means = [[means[c][i]] for c in range(n_components)]\n",
    "            sub_cov = [[[Ss[c][i, j]]] for c in range(n_components)]\n",
    "            pdf = dd.mixture.MoG(a=posterior.a, ms=sub_means, Ss=sub_cov)\n",
    "            post_pdf = pdf.eval(theta[:, np.newaxis], log=False)\n",
    "            \n",
    "            plt.subplot(dim_params, dim_params, plot_idx)            \n",
    "            plt.plot(theta, post_pdf)\n",
    "            plt.axvline(x=true_params[0][i], color='C1', label=weight_labels[i])\n",
    "            plt.legend(prop=dict(size=12))\n",
    "            \n",
    "        elif i < j:            \n",
    "            # define a 2D MoG\n",
    "            sub_means = [[posterior.xs[c].m[i], posterior.xs[c].m[j]] for c in range(n_components)]\n",
    "            sub_cov = [[[posterior.xs[c].S[i, i], posterior.xs[c].S[i, j]], \n",
    "                       [posterior.xs[c].S[j, i], posterior.xs[c].S[j, j]]] for c in range(n_components)]\n",
    "            pdf = dd.mixture.MoG(a=posterior.a, ms=sub_means, Ss=sub_cov)            \n",
    "            x, y, z = get_delfi_grid_pdf(theta, delfi_obj=pdf, log=False)\n",
    "        \n",
    "            plt.subplot(dim_params, dim_params, plot_idx)\n",
    "            plt.contourf(x, y, z)\n",
    "            plt.plot([true_params[0][i]], [true_params[0][j]], 'o', color='C1')\n",
    "        plot_idx += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mackelab]",
   "language": "python",
   "name": "conda-env-mackelab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
