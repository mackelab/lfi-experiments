{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import delfi.distribution as dd\n",
    "import delfi.generator as dg\n",
    "import delfi.inference as infer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import time \n",
    "\n",
    "from lfimodels.balancednetwork.BalancedNetworkSimulator import BalancedNetwork\n",
    "from lfimodels.balancednetwork.BalancedNetworkStats import BalancedNetworkStats\n",
    "from lfimodels.balancednetwork.BalancedNetworkGenerator import BalancedNetworkGenerator\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup delfi objects \n",
    "\n",
    "First we define the simulator model with numbers of parameters, the prior over those parameters, the summary stats and the generator that combines the those three objects. \n",
    "\n",
    "The generator also takes the proposal as an argument. This is the proposal prior from which new parameters are sampled instead of sampling from the overall prior. For now it is set to None, so that .gen() samples from the overall prior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_params = 1\n",
    "n_cores_to_use = 4\n",
    "\n",
    "m = BalancedNetwork(dim=n_params, first_port=8010, \n",
    "                    verbose=True, n_servers=n_cores_to_use, duration=3.)\n",
    "p = dd.Uniform(lower=[1.], upper=[5.])\n",
    "s = BalancedNetworkStats(n_workers=n_cores_to_use)\n",
    "g = BalancedNetworkGenerator(model=m, prior=p, summary=s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the server and make a first test run - our observation\n",
    "\n",
    "For SNPE we can define an actual observation of the data by running the simulator once. The resulting summary stats is $x_{obs}$, the underlaying parameters are the true $\\theta$ that we want to discover. \n",
    "\n",
    "When SNPE is run over more than one round, the estimated posterior after one round is evaluated at $x_{obs}$ to give the new proposal prior for the next round. Beside the use of SVI this is the main difference to the basic inference scheme. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# here we set the true params \n",
    "true_params = [[2.5]]\n",
    "# run forward model \n",
    "data = m.gen(true_params)\n",
    "# get summary stats\n",
    "stats_obs = s.calc(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(true_params, stats_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the inference method as SNPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = infer.SNPE(g, obs=stats_obs, n_components=3, pilot_samples=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run the inference machine\n",
    "ntrain = 10\n",
    "nrounds = 1\n",
    "out, trn_data = res.run(n_train=ntrain, n_rounds=nrounds, minibatch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, r in enumerate(out): \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.plot(r['loss'], label='round {}'.format(i + 1))\n",
    "plt.title('loss over iterations')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Done \n",
    "\n",
    "We now have an estimate of the posterior over the parameter $R_{ee}$ given the observed data $x_{obs}$. How can we check the performance? \n",
    "\n",
    "## Compare to true parameter \n",
    "\n",
    "We have generated the observed data ourselves so we do have the true parameter. The mean of the posterior should be close to it when evaluated for $x=x_{obs}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluate the posterior at the observed data \n",
    "posterior = res.predict(stats_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean = posterior.xs[0].m[0]\n",
    "std = np.sqrt(posterior.xs[0].S[0][0])\n",
    "print(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up a dict for saving the results \n",
    "save_data = True\n",
    "path_to_save_folder = 'data/'  # has to exist on your local path\n",
    "\n",
    "if save_data and os.path.exists(path_to_save_folder): \n",
    "    nrounds=1\n",
    "    result_dict = dict(true_params=true_params, stats_obs=stats_obs, nrouns=nrounds, ntrain=ntrain,\n",
    "                       posterior=posterior, out=out, trn_data=trn_data)\n",
    "    \n",
    "    filename = os.path.join(path_to_save_folder, \n",
    "                           '{}_snpe_ntrain{}'.format(time.time(), ntrain).replace('.', '') + '.p')\n",
    "    with open(filename, 'wb') as handle:\n",
    "        pickle.dump(result_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract the posterior \n",
    "n_components = len(posterior.a)\n",
    "means = [posterior.xs[c].m for c in range(n_components)]\n",
    "Ss = [posterior.xs[c].S for c in range(n_components)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta = np.linspace(1, 5, 1000)\n",
    "sub_means = [[means[c][0]] for c in range(n_components)]\n",
    "sub_cov = np.asarray([Ss[c] for c in range(n_components)])\n",
    "pdf = dd.mixture.MoG(a=posterior.a, ms=sub_means, Ss=sub_cov)\n",
    "post_pdf = pdf.eval(theta[:, np.newaxis], log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(theta, post_pdf, label='$\\hat{p}( theta | x=x_{obs})$')\n",
    "plt.axvline(x=true_params[0], label='true theta', linestyle='--', color='C1')\n",
    "plt.legend()\n",
    "plt.xlabel('$R_{ee}$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mackelab]",
   "language": "python",
   "name": "conda-env-mackelab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
