{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce figure 2 of Litwin-Kumar Doiran 2012\n",
    "\n",
    "Use data from the simulated balanced network to reproduce the figure 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "from utils import *\n",
    "%matplotlib inline\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specify data folder \n",
    "folder = '/Users/Jan/Dropbox/Master/mackelab/code/balanced_clustered_network/data/'\n",
    "\n",
    "# give filename for uniform and clustered data \n",
    "fn_uni = '150099112552ree10_dur100_brain1.p'\n",
    "fn_clus = '150091388063ree25_dur100_brain1.p'\n",
    "\n",
    "# filename params \n",
    "time_str = time.time()\n",
    "dur = '10s'\n",
    "\n",
    "# load data \n",
    "d_uni = load_data(fn_uni, folder)\n",
    "d_clus = load_data(fn_clus, folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assume a single long trial, use only E neurons\n",
    "# extract parameters \n",
    "\n",
    "# set time window for ff  in sec \n",
    "window_length_ff = 0.1  \n",
    "# and for rho \n",
    "window_length_rho = 0.05 \n",
    "\n",
    "# time windows for ff ocer time windows \n",
    "time_windows = np.linspace(0.025, 0.2, 8)\n",
    "\n",
    "# get the params \n",
    "params = d_uni['params']\n",
    "n_rounds = params['n_rounds']\n",
    "n_trials = params['n_trials']\n",
    "simulation_time = np.asarray(params['simulation_time'])  # remove unit\n",
    "NE = params['NE']\n",
    "NI = params['NI']\n",
    "n_clusters = 50\n",
    "\n",
    "# get the total number of neurons pairs that are in a cluster \n",
    "Nc = NE / n_clusters\n",
    "n_pairs_in_cluster = n_clusters * Nc**2\n",
    "n_random_pairs = int(np.sqrt(n_pairs_in_cluster))\n",
    "\n",
    "time_offset = 1.  # in sec\n",
    "delta_t = simulation_time - time_offset  # in sec\n",
    "recordings_length = delta_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stat_dict=dict(uniform={}, clustered={})\n",
    "keys = ['uniform', 'clustered']\n",
    "\n",
    "for idx, data in enumerate([d_uni, d_clus]): \n",
    "\n",
    "    spiketimedict = data['trial0']['spikes_E']\n",
    "\n",
    "    # rates \n",
    "    spikecounts = get_spikecounts_fixed_time_window(spiketimedict, time_offset, delta_t)\n",
    "    stat_dict[keys[idx]]['rates'] = spikecounts / delta_t\n",
    "    \n",
    "    # fano factors \n",
    "    spikecounts_over_windows_ff = get_spike_counts_over_time_windows(spiketimedict, time_offset, delta_t, \n",
    "                                                                      window_length=window_length_ff)\n",
    "    stat_dict[keys[idx]]['ff'] = calculate_fano_factor(spikecounts_over_windows_ff)\n",
    "  \n",
    "    # rho all \n",
    "    spikecounts_over_windows_rho = get_spike_counts_over_time_windows(spiketimedict, time_offset, delta_t, \n",
    "                                                              window_length=window_length_rho)\n",
    "    stat_dict[keys[idx]]['rho'] = calculate_correlation_matrix(spikecounts_over_windows_rho)\n",
    "    \n",
    "    # rho pairs is dependent on the clustering \n",
    "    if idx == 0: \n",
    "        shuffled_counts = spikecounts_over_windows_rho.copy()\n",
    "        np.random.shuffle(shuffled_counts)\n",
    "        rho_pairs = calculate_correlation_matrix(shuffled_counts[np.newaxis, :n_random_pairs, :])\n",
    "    else:\n",
    "        rho_pairs = calculate_clusterpair_correlations(spikecounts_over_windows_rho, n_clusters, Nc)\n",
    "    stat_dict[keys[idx]]['rho_pairs'] = rho_pairs\n",
    "    \n",
    "    # ff over time windows \n",
    "    ff_over_windows = np.zeros_like(time_windows)\n",
    "    for w_idx, time_window in enumerate(time_windows): \n",
    "        tmp_spikecounts = get_spike_counts_over_time_windows(spiketimedict, time_offset, delta_t, \n",
    "                                                                  window_length=time_window)\n",
    "        ff_over_windows[w_idx] = calculate_fano_factor(tmp_spikecounts).mean()\n",
    "        \n",
    "    stat_dict[keys[idx]]['ff_over_windows'] = ff_over_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize = 14\n",
    "legend_size = 13\n",
    "plt.figure(figsize=(15, 5))\n",
    "colors = ['C0', 'C1']\n",
    "for idx, key in enumerate(keys): \n",
    "    rates = stat_dict[key]['rates']\n",
    "    ff = stat_dict[key]['ff']\n",
    "    ff_over_windows = stat_dict[key]['ff_over_windows']\n",
    "\n",
    "    # plotting \n",
    "    plt.subplot(131)\n",
    "    # plot the rates \n",
    "    plt.hist(rates, bins=40, range=[0, 40], alpha=.3, lw=3.)\n",
    "    plt.axvline(np.mean(rates), linestyle='--', label='{}={}'.format(key, np.round(np.mean(rates), 2)), \n",
    "                color=colors[idx])\n",
    "    plt.title('Firing rate', fontsize=fontsize)\n",
    "    plt.legend(prop=dict(size=legend_size))  \n",
    "    plt.xlabel('Rate (spikes/sec)', fontsize=fontsize)\n",
    "    \n",
    "    # the ffs\n",
    "    plt.subplot(132)\n",
    "    plt.hist(ff, bins=40, range=[0, 5], alpha=.3, lw=3.)\n",
    "    plt.title('Fano factor, {}s windows'.format(window_length_ff), fontsize=fontsize)\n",
    "    plt.axvline(np.mean(ff), linestyle='--', label='{}={}'.format(key, np.round(np.mean(ff), 2)), \n",
    "                color=colors[idx])\n",
    "    plt.legend(prop=dict(size=legend_size))\n",
    "    plt.xlabel('Fano factor', fontsize=fontsize)\n",
    "    \n",
    "    # fanos over windows \n",
    "    plt.subplot(133)\n",
    "    plt.title('Fano factor vs window length', fontsize=fontsize)\n",
    "    plt.plot(np.round(time_windows * 1000), ff_over_windows, '-o', label='{}'.format(key))\n",
    "    plt.xlabel('Window size [ms]', fontsize=fontsize)\n",
    "    plt.ylabel('Fano factor', fontsize=fontsize)\n",
    "    plt.legend(prop=dict(size=legend_size))\n",
    "\n",
    "plt.tight_layout()\n",
    "figure_filename = '{}_figure2{}_dur{}'.format(time_str, 'a', dur).replace('.', '')\n",
    "save_figure(filename=figure_filename + '.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))    \n",
    "for idx, key in enumerate(keys):  \n",
    "    rho = stat_dict[key]['rho']\n",
    "    rho_pairs = stat_dict[key]['rho_pairs']\n",
    "\n",
    "    # the rho\n",
    "    plt.subplot(121)\n",
    "    plt.hist(rho, bins=40, range=[-1, 1], alpha=.3)\n",
    "    plt.title('Correlation all pairs', fontsize=fontsize)\n",
    "    plt.axvline(np.mean(rho), linestyle='--', label='{}={}'.format(key, np.round(np.mean(rho), 2)), \n",
    "                color=colors[idx])\n",
    "    plt.legend(prop=dict(size=legend_size))\n",
    "    plt.xlabel('Pearson r', fontsize=fontsize)\n",
    "    plt.ylabel('Count', fontsize=fontsize)\n",
    "        \n",
    "    # the rho pairs \n",
    "    plt.subplot(122)\n",
    "    plt.hist(rho_pairs, bins=40, range=[-1, 1], alpha=.3)\n",
    "    plt.title('Correlation same cluster', fontsize=fontsize)\n",
    "    plt.axvline(np.mean(rho_pairs), linestyle='--', label='{}={}'.format(key, np.round(np.mean(rho_pairs), 2)), \n",
    "                color=colors[idx])\n",
    "    plt.legend(prop=dict(size=legend_size))\n",
    "    plt.xlabel('Pearson r', fontsize=fontsize)\n",
    "#    plt.ylabel('Count', fontsize=fontsize)\n",
    "    \n",
    "plt.tight_layout()\n",
    "figure_filename = '{}_figure2{}_dur{}'.format(time_str, 'b', dur).replace('.', '')\n",
    "save_figure(filename=figure_filename + '.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:brian1]",
   "language": "python",
   "name": "conda-env-brian1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
