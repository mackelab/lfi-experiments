{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analytical broadsword approach\n",
    "\n",
    "- analytically tractable problem: Gaussian prior, Gaussian proposal, _linear-Gaussian likelihood_\n",
    "- analytically tractable MDN: linear-affine network\n",
    "- analytically tractable gradients and closed-form solution for MDN parameters for given dataset\n",
    "\n",
    "\n",
    "TO DO:\n",
    "- check gradients again\n",
    "- seems like the proposal-adjusted finite-size effective joint distribution (eq. 4, p. 11 in JakobsNotes.pdf) is badly off right now (_currently not in use_!)\n",
    "- type down the CDELFI version of the below stuff and import analytical division for direct comparison "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "prior: \n",
    "\n",
    "$p(\\theta) = \\mathcal{N}(\\theta \\ | \\ 0, \\eta^2)$\n",
    "\n",
    "proposal prior: \n",
    "\n",
    "$\\tilde{p}(\\theta) = \\mathcal{N}(\\theta \\ | \\ \\nu, \\xi^2)$\n",
    "\n",
    "simulator: \n",
    "\n",
    "$p(x \\ | \\ \\theta) =  \\mathcal{N}(x \\ | \\ \\theta, \\sigma^2)$\n",
    "\n",
    "analytic posteriors: \n",
    "\n",
    "$p(\\theta \\ | \\ x) = \\mathcal{N}(\\theta \\ | \\frac{\\eta^2}{\\eta^2 + \\sigma^2} x, \\eta^2 - \\frac{\\eta^4}{\\eta^2 + \\sigma^2})$ \n",
    "\n",
    "$\\tilde{p}(\\theta \\ | \\ x) = \\mathcal{N}(\\theta \\ | \\frac{\\xi^2}{\\xi^2 + \\sigma^2} x + \\frac{\\sigma^2}{\\xi^2 + \\sigma^2} \\nu, \\xi^2 - \\frac{\\xi^4}{\\xi^2 + \\sigma^2})$\n",
    "\n",
    "Data:\n",
    "\n",
    "$(x_n, \\theta_n) \\sim p(\\theta) p(x \\ | \\ \\theta) = \\mathcal{N}( (x_n, \\theta_n) \\ | \\ (0, \\nu), \n",
    "\\begin{pmatrix}\n",
    "\\xi^{2} + \\sigma^{2} &  \\xi^{2}  \\\\\n",
    "\\xi^{2} & \\xi^{2}  \\\\\n",
    "\\end{pmatrix})$\n",
    "\n",
    "Loss: \n",
    "\n",
    "$ \\mathcal{L}(\\phi) = \\sum_n \\frac{{p}(\\theta_n)}{\\tilde{p}(\\theta_n)} K_\\epsilon(x_n | x_0) \\ \\log q_\\phi(\\theta_n | x_n)$\n",
    "\n",
    "Model: \n",
    "\n",
    "$ q_\\phi(\\theta_n | x_n) = \\mathcal{N}(\\theta_n \\ | \\ \\mu_\\phi(x_n), \\sigma^2_\\phi(x_n))$\n",
    "\n",
    "$ (\\mu_\\phi(x), \\sigma^2_\\phi(x)) = MDN_\\phi(x) = \\begin{pmatrix} \\beta \\\\ 0 \\end{pmatrix} x + \\begin{pmatrix} \\alpha \\\\ \\gamma^2 \\end{pmatrix}$\n",
    "\n",
    "Gradients: \n",
    "\n",
    "$\\mathcal{N}_n := \\mathcal{N}(x_n, \\theta_n \\ | \\ \\mu_y, \\Sigma_y)$\n",
    "\n",
    "$\\Sigma_y = \n",
    "\\begin{pmatrix}\n",
    "\\epsilon^2  &  0  \\\\\n",
    "0 & \\left( \\eta^{-2} - \\xi^{-2} \\right)^{-1}  \\\\\n",
    "\\end{pmatrix}$\n",
    "\n",
    "\n",
    "$\\mu_y = \\begin{pmatrix} x_0  \\\\ \\frac{\\eta^2}{\\eta^2 + \\xi^2}\\nu \\end{pmatrix}$\n",
    "\n",
    "$\\frac{\\partial{}\\mathcal{L}}{\\partial{}\\alpha} = -2 \\sum_n \\mathcal{N}_n \\frac{\\theta_n - \\mu_\\phi(x_n)}{\\sigma^2_\\phi(x_n)}$\n",
    "\n",
    "$\\frac{\\partial{}\\mathcal{L}}{\\partial{}\\beta} = -2 \\sum_n \\mathcal{N}_n \\frac{\\theta_n - \\mu_\\phi(x_n)}{\\sigma^2_\\phi(x_n)} x_n$\n",
    "\n",
    "$\\frac{\\partial{}\\mathcal{L}}{\\partial{}\\gamma^2} \n",
    "= \\sum_n \\mathcal{N}_n \\left( \\frac{1}{\\sigma^2_\\phi(x_n)} \n",
    "- \\frac{\\left(\\theta_n - \\mu_\\phi(x_n) \\right)^2}{\\sigma^4_\\phi(x_n)} \\right) \n",
    "= \\frac{1}{\\gamma^2} \\sum_n \\mathcal{N}_n \\left( 1 \n",
    "- \\frac{\\left(\\theta_n - \\mu_\\phi(x_n) \\right)^2}{\\gamma^2} \\right) $\n",
    "\n",
    "Optima: \n",
    "\n",
    "$\\hat{\\alpha} = \n",
    "\\frac{\\sum_n \\mathcal{N}_n \\left(\\theta_n - \\frac{\\sum_m \\mathcal{N}_m \\theta_m x_m}{\\sum_m \\mathcal{N}_m x_m^2} x_n \\right)}{\\sum_n \\mathcal{N}_n - \\frac{\\left( \\sum_n \\mathcal{N}_n x_n \\right)^2}{\\sum_n \\mathcal{N}_n x_n^2}}$\n",
    "\n",
    "$\\hat{\\beta} = \n",
    "\\frac{\\sum_n \\mathcal{N}_n \\theta_n x_n - \\hat{\\alpha} \\sum_n \\mathcal{N}_n x_n}{\\sum_n \\mathcal{N}_n x_n^2}$\n",
    "\n",
    "$\\hat{\\gamma}^2 = \n",
    "\\frac{\\sum_n \\mathcal{N}_n \\left( \\theta_n - \\hat{\\alpha} - \\hat{\\beta} x_n \\right)^2}{\\sum_n \\mathcal{N}_n}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import delfi.distribution as dd\n",
    "import delfi.generator as dg\n",
    "import delfi.inference as infer\n",
    "import delfi.summarystats as ds\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import multivariate_normal as mvn\n",
    "\n",
    "from delfi.simulator.Gauss import Gauss\n",
    "\n",
    "def gauss_weights(params, stats, mu_y, Sig_y):\n",
    "    \n",
    "    y = np.hstack((stats, params))\n",
    "    return mvn.pdf(x=y, mean=mu_y.reshape(-1), cov=Sig_y, allow_singular=True)   \n",
    "\n",
    "def gauss_weights_eps0(params, stats, mu_y, Sig_y):\n",
    "    \"\"\" stable version in case eps^2 is giant - stats.mvn return nonsense here \"\"\"\n",
    "    \n",
    "    x = -0.5 * (params-mu_y[1])**2 / Sig_y[1,1] # would like to use mvn.pdf, but that one freaks  \n",
    "    return np.exp( x.reshape(-1) )              # out for 1D problems with negative (co-)variance\n",
    "\n",
    "\n",
    "def dL_dalpha( params, stats, normals, beta, gamma2, alphas):\n",
    "\n",
    "    return -2*(normals.reshape(-1,1) * (params.reshape(-1,1) - beta * stats.reshape(-1,1) - alphas.reshape(1,-1))/gamma2 * stats.reshape(-1,1)).sum(axis=0)\n",
    "\n",
    "\n",
    "def dL_dbeta( params, stats, normals, alpha, gamma2, betas):\n",
    "\n",
    "    return -2*(normals.reshape(-1,1) * (params.reshape(-1,1) - beta * stats.reshape(-1,1) - alphas.reshape(1,-1))/gamma2).sum(axis=0)\n",
    "\n",
    "def dL_dgamma2( params, stats, normals, alpha, beta, gamma2s):\n",
    "\n",
    "    tmp = (params.reshape(-1,1) - beta*stats.reshape(-1,1) - alpha)**2 / gamma2s.reshape(1,-1)\n",
    "    return 1/gamma2s.reshape(1,-1) * (normals.reshape(-1,1) * (1 - out)).sum(axis=0)\n",
    "    \n",
    "def alpha(params, stats, normals):\n",
    "    \n",
    "    N = normals.size    \n",
    "\n",
    "    Eo  = (normals * params).sum()\n",
    "    Eox = (normals * stats * params).sum()\n",
    "    Ex2 = (normals * stats**2).sum()\n",
    "    Ex  = (normals * stats).sum()\n",
    "    E1  = normals.sum()\n",
    "    \n",
    "    #ahat = (normals * (Ex2 * params - Eox * stats)).sum()\n",
    "    #ahat /= (E1 * Ex2 - Ex**2)\n",
    "    \n",
    "    ahat = (Eo - Eox/Ex2 * Ex) / (E1 - Ex**2/Ex2)\n",
    "    \n",
    "    return ahat\n",
    "\n",
    "def beta(params, stats, normals, ahat=None):\n",
    "\n",
    "    ahat = alpha(params, stats, normals) if ahat is None else ahat\n",
    "\n",
    "    Eox = (normals * stats * params).sum()\n",
    "    Ex2 = (normals * stats**2).sum()\n",
    "    Ex  = (normals * stats).sum()\n",
    "    \n",
    "    bhat = (Eox - ahat * Ex) / Ex2\n",
    "    \n",
    "    return bhat\n",
    "    \n",
    "def gamma2(params, stats, normals, ahat=None, bhat=None):\n",
    "\n",
    "    ahat = alpha(params, stats, normals) if ahat is None else ahat\n",
    "    bhat = beta(params, stats, normals, ahat) if bhat is None else bhat\n",
    "\n",
    "    gamma2hat = (normals*(params - ahat - bhat * stats )**2).sum() / normals.sum()\n",
    "    \n",
    "    return gamma2hat\n",
    "\n",
    "n_params = 1\n",
    "seed = 42\n",
    "\n",
    "sig2 = 1.0\n",
    "eta2 = 1.0\n",
    "eps2 = 1e20\n",
    "\n",
    "if eps2 > 1000:\n",
    "    gauss_weights = gauss_weights_eps0\n",
    "\n",
    "x0 = 0.8 * np.ones((1,1)) #_,obs = g.gen(1)\n",
    "\n",
    "assert n_params ==  1\n",
    "m = Gauss(dim=n_params, seed=seed, noise_cov=sig2)\n",
    "p = dd.Gaussian(m=0. * np.ones(n_params), \n",
    "                S=eta2 * np.eye(n_params),\n",
    "                seed=seed)\n",
    "post   = dd.Gaussian(m = np.ones(n_params) * eta2/(eta2+sig2)*x0[0], \n",
    "                     S=eta2 - eta2**2 / (eta2 + sig2) * np.eye(n_params))    \n",
    "\n",
    "#else:\n",
    "#    Sig_y = (eps2*eta2*sig2)/(eps2+eta2+sig2) * np.array([[1/eta2+1/sig2, 1/sig2],[1/sig2, 1/eps2+1/sig2]])\n",
    "#    mu_y = np.dot( Sig_y, np.array([x0**2/eps2, 0]) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from delfi.utils.progress import no_tqdm, progressbar\n",
    "\n",
    "n_fits = 100\n",
    "N = 5000\n",
    "\n",
    "ksi2s = np.array([0.48]) * eta2\n",
    "nus = 0.38 * np.ones(len(ksi2s))\n",
    "\n",
    "plt.figure(figsize=(4*len(ksi2s),8))\n",
    "n_bins = 20\n",
    "\n",
    "track_rp = True # track real posterior: if False, will compare with 'proposal-posterior'\n",
    "\n",
    "m_m, m_v, M_m, M_v, hh_m, hh_v = np.inf,np.inf,-np.inf,-np.inf,-np.inf,-np.inf\n",
    "for i in range(len(ksi2s)):\n",
    "    nu, ksi2 = nus[i], ksi2s[i]\n",
    "    ppr = dd.Gaussian(m=nu * np.ones(n_params), \n",
    "                    S=ksi2 * np.eye(n_params),\n",
    "                    seed=seed)\n",
    "    postpr = dd.Gaussian(m = np.ones(n_params) * (ksi2/(ksi2+sig2)*x0[0] + sig2/(ksi2+sig2)*nu), \n",
    "                         S=ksi2 - ksi2**2 / (ksi2 + sig2) * np.eye(n_params))\n",
    "    eta2p = 1/(1/eta2 - 1/ksi2)\n",
    "    Sig_y = np.array([[eps2,0], [0,eta2p]])    \n",
    "    mu_y = np.array([ [x0[0][0]], [eta2/(eta2-ksi2)*nu]])\n",
    "\n",
    "    s = ds.Identity()\n",
    "    g = dg.Default(model=m, prior=ppr, summary=s)\n",
    "    out_snpe   = np.zeros((n_fits,2))\n",
    "    pbar = progressbar(total=n_fits)\n",
    "    desc = 'repeated fits'\n",
    "    pbar.set_description(desc)\n",
    "    with pbar:\n",
    "        for idx_seed in range(n_fits):\n",
    "\n",
    "            #print( str(idx_seed) + '/' + str(n_fits) )\n",
    "            seed = 42 + idx_seed\n",
    "            g.model.seed = seed\n",
    "            g.prior.seed = seed\n",
    "\n",
    "            data = g.gen(N, verbose=False)\n",
    "            params, stats = data[0].reshape(-1), data[1].reshape(-1)\n",
    "\n",
    "            normals = gauss_weights(data[0], data[1], mu_y, Sig_y) if track_rp else np.ones(N)/N\n",
    "            ahat =       alpha(params, stats, normals)\n",
    "            bhat =        beta(params, stats, normals, ahat)\n",
    "            gamma2hat = gamma2(params, stats, normals, ahat, bhat)\n",
    "\n",
    "            mu_hat   = ahat + bhat * x0\n",
    "            sig2_hat = gamma2hat\n",
    "\n",
    "            out_snpe[idx_seed,:] = (mu_hat, sig2_hat)\n",
    "            pbar.update(1)\n",
    "\n",
    "    post_disp = post if track_rp else postpr\n",
    "\n",
    "    plt.subplot(len(ksi2s), 2, 2*i+1)\n",
    "    m_m, M_m = np.min((m_m, out_snpe[:,0].min())), np.max((M_m, out_snpe[:,0].max()))\n",
    "    plt.hist(out_snpe[:,0], bins=np.linspace(m_m, M_m, n_bins), normed=True)\n",
    "    hh_m = np.max((hh_m, plt.axis()[3]))\n",
    "    plt.plot([post_disp.mean, post_disp.mean], [0, hh_m], 'r', linewidth=2)\n",
    "    plt.plot(out_snpe[:,0].mean() + out_snpe[:,0].std()*np.array([-1,-1]), [0, hh_m/2], 'g', linewidth=2)\n",
    "    plt.plot(out_snpe[:,0].mean() + out_snpe[:,0].std()*np.array([0,0]), [0, hh_m/2], 'g', linewidth=2)\n",
    "    plt.plot(out_snpe[:,0].mean() + out_snpe[:,0].std()*np.array([1,1]), [0, hh_m/2], 'g', linewidth=2)\n",
    "    plt.plot(out_snpe[:,0].mean() + out_snpe[:,0].std()*np.array([-1,1]), [ hh_m/2, hh_m/2], 'g', linewidth=2)\n",
    "    plt.ylabel('xi^2/eta^2 = ' + str(ksi2/eta2) )\n",
    "    \n",
    "    plt.subplot(len(ksi2s),2, 2*i+2)\n",
    "    m_v, M_v = np.min((m_v, out_snpe[:,1].min())), np.max((M_v, out_snpe[:,1].max()))\n",
    "    plt.hist(out_snpe[:,1], bins=np.linspace(m_v, M_v, n_bins), normed=True)\n",
    "    hh_v = np.max((hh_v, plt.axis()[3]))\n",
    "    plt.plot([post_disp.std**2, post_disp.std**2], [0, hh_v], 'r', linewidth=2)\n",
    "    plt.plot(out_snpe[:,1].mean() + out_snpe[:,1].std()*np.array([-1,-1]), [0, hh_v/2], 'g', linewidth=2)\n",
    "    plt.plot(out_snpe[:,1].mean() + out_snpe[:,1].std()*np.array([0,0]), [0, hh_v/2], 'g', linewidth=2)\n",
    "    plt.plot(out_snpe[:,1].mean() + out_snpe[:,1].std()*np.array([1,1]), [0, hh_v/2], 'g', linewidth=2)\n",
    "    plt.plot(out_snpe[:,1].mean() + out_snpe[:,1].std()*np.array([-1,1]), [ hh_v/2, hh_v/2], 'g', linewidth=2)\n",
    "    #plt.ylabel('posterior variance')\n",
    "\n",
    "\n",
    "plt.subplot(len(ksi2s),2,1)\n",
    "plt.title('posterior mean')\n",
    "plt.subplot(len(ksi2s),2,2)\n",
    "plt.title('posterior variance')\n",
    "\n",
    "for i in range(len(ksi2s)):\n",
    "    plt.subplot(len(ksi2s),2, 2*i+1)\n",
    "    plt.axis([m_m, M_m, 0, hh_m])\n",
    "    plt.subplot(len(ksi2s),2, 2*i+2)\n",
    "    plt.axis([m_v, M_v, 0, hh_v])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_snpe[:,0].mean(), out_snpe[:,0].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_snpe[:,1].mean(), out_snpe[:,1].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ksi2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from delfi.utils.progress import no_tqdm, progressbar\n",
    "\n",
    "n_fits = 200\n",
    "N = 100\n",
    "\n",
    "ksi2s = np.array([0.1, 0.5, 0.9, 0.999]) * eta2\n",
    "nus = np.zeros(len(ksi2s)) * x0[0]\n",
    "\n",
    "plt.figure(figsize=(4*len(ksi2s),8))\n",
    "n_bins = 20\n",
    "\n",
    "track_rp = True # track real posterior: if False, will compare with 'proposal-posterior'\n",
    "\n",
    "m_m, m_v, M_m, M_v, hh_m, hh_v = np.inf,np.inf,-np.inf,-np.inf,-np.inf,-np.inf\n",
    "for i in range(len(ksi2s)):\n",
    "    nu, ksi2 = nus[i], ksi2s[i]\n",
    "    ppr = dd.Gaussian(m=nu * np.ones(n_params), \n",
    "                    S=ksi2 * np.eye(n_params),\n",
    "                    seed=seed)\n",
    "    postpr = dd.Gaussian(m = np.ones(n_params) * (ksi2/(ksi2+sig2)*x0[0] + sig2/(ksi2+sig2)*nu), \n",
    "                         S=ksi2 - ksi2**2 / (ksi2 + sig2) * np.eye(n_params))\n",
    "    eta2p = 1/(1/eta2 - 1/ksi2)\n",
    "    Sig_y = np.array([[eps2,0], [0,eta2p]])    \n",
    "    mu_y = np.array([ [x0[0][0]], [eta2/(eta2-ksi2)*nu]])\n",
    "\n",
    "    s = ds.Identity()\n",
    "    g = dg.Default(model=m, prior=ppr, summary=s)\n",
    "    out_snpe   = np.zeros((n_fits,2))\n",
    "    pbar = progressbar(total=n_fits)\n",
    "    desc = 'repeated fits'\n",
    "    pbar.set_description(desc)\n",
    "    with pbar:\n",
    "        for idx_seed in range(n_fits):\n",
    "\n",
    "            #print( str(idx_seed) + '/' + str(n_fits) )\n",
    "            seed = 42 + idx_seed\n",
    "            g.model.seed = seed\n",
    "            g.prior.seed = seed\n",
    "\n",
    "            data = g.gen(N, verbose=False)\n",
    "            params, stats = data[0].reshape(-1), data[1].reshape(-1)\n",
    "\n",
    "            normals = gauss_weights(data[0], data[1], mu_y, Sig_y) if track_rp else np.ones(N)/N\n",
    "            ahat =       alpha(params, stats, normals)\n",
    "            bhat =        beta(params, stats, normals, ahat)\n",
    "            gamma2hat = gamma2(params, stats, normals, ahat, bhat)\n",
    "\n",
    "            mu_hat   = ahat + bhat * x0\n",
    "            sig2_hat = gamma2hat\n",
    "\n",
    "            out_snpe[idx_seed,:] = (mu_hat, sig2_hat)\n",
    "            pbar.update(1)\n",
    "\n",
    "    post_disp = post if track_rp else postpr\n",
    "\n",
    "    plt.subplot(len(ksi2s), 2, 2*i+1)\n",
    "    m_m, M_m = np.min((m_m, out_snpe[:,0].min())), np.max((M_m, out_snpe[:,0].max()))\n",
    "    plt.hist(out_snpe[:,0], bins=np.linspace(m_m, M_m, n_bins), normed=True)\n",
    "    hh_m = np.max((hh_m, plt.axis()[3]))\n",
    "    plt.plot([post_disp.mean, post_disp.mean], [0, hh_m], 'r', linewidth=2)\n",
    "    plt.plot(out_snpe[:,0].mean() + out_snpe[:,0].std()*np.array([-1,-1]), [0, hh_m/2], 'g', linewidth=2)\n",
    "    plt.plot(out_snpe[:,0].mean() + out_snpe[:,0].std()*np.array([0,0]), [0, hh_m/2], 'g', linewidth=2)\n",
    "    plt.plot(out_snpe[:,0].mean() + out_snpe[:,0].std()*np.array([1,1]), [0, hh_m/2], 'g', linewidth=2)\n",
    "    plt.plot(out_snpe[:,0].mean() + out_snpe[:,0].std()*np.array([-1,1]), [ hh_m/2, hh_m/2], 'g', linewidth=2)\n",
    "    plt.ylabel('xi^2/eta^2 = ' + str(ksi2/eta2) )\n",
    "    \n",
    "    plt.subplot(len(ksi2s),2, 2*i+2)\n",
    "    m_v, M_v = np.min((m_v, out_snpe[:,1].min())), np.max((M_v, out_snpe[:,1].max()))\n",
    "    plt.hist(out_snpe[:,1], bins=np.linspace(m_v, M_v, n_bins), normed=True)\n",
    "    hh_v = np.max((hh_v, plt.axis()[3]))\n",
    "    plt.plot([post_disp.std**2, post_disp.std**2], [0, hh_v], 'r', linewidth=2)\n",
    "    plt.plot(out_snpe[:,1].mean() + out_snpe[:,1].std()*np.array([-1,-1]), [0, hh_v/2], 'g', linewidth=2)\n",
    "    plt.plot(out_snpe[:,1].mean() + out_snpe[:,1].std()*np.array([0,0]), [0, hh_v/2], 'g', linewidth=2)\n",
    "    plt.plot(out_snpe[:,1].mean() + out_snpe[:,1].std()*np.array([1,1]), [0, hh_v/2], 'g', linewidth=2)\n",
    "    plt.plot(out_snpe[:,1].mean() + out_snpe[:,1].std()*np.array([-1,1]), [ hh_v/2, hh_v/2], 'g', linewidth=2)\n",
    "    #plt.ylabel('posterior variance')\n",
    "\n",
    "\n",
    "plt.subplot(len(ksi2s),2,1)\n",
    "plt.title('posterior mean')\n",
    "plt.subplot(len(ksi2s),2,2)\n",
    "plt.title('posterior variance')\n",
    "\n",
    "for i in range(len(ksi2s)):\n",
    "    plt.subplot(len(ksi2s),2, 2*i+1)\n",
    "    plt.axis([m_m, M_m, 0, hh_m])\n",
    "    plt.subplot(len(ksi2s),2, 2*i+2)\n",
    "    plt.axis([m_v, M_v, 0, hh_v])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# numerically check $\\frac{\\partial}{\\partial{}\\alpha}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beta_ = eta2/(eta2+sig2)\n",
    "gamma2_ = post.std**2\n",
    "alphas = np.linspace(-0.02, -0.01, 100000)\n",
    "\n",
    "out = -2*(normals.reshape(-1,1) * (params.reshape(-1,1) - beta_ * stats.reshape(-1,1) - alphas.reshape(1,-1))/gamma2_).sum(axis=0)\n",
    "plt.plot(alphas, out)\n",
    "plt.show()\n",
    "\n",
    "alpha_hat = np.array(alpha(params, stats, normals))\n",
    "out_hat = -2*(normals.reshape(-1,1) * (params.reshape(-1,1) - beta_ * stats.reshape(-1,1) - alpha_hat)/gamma2_).sum(axis=0)\n",
    "\n",
    "\n",
    "alphas[np.argmin(np.abs(out))], alpha_hat, out_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# numerically check $\\frac{\\partial}{\\partial{}\\beta}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha_ = 0.\n",
    "gamma2_ = post.std**2\n",
    "betas = np.linspace(0., 1., 1000)\n",
    "out = -2*(normals.reshape(-1,1) * (params.reshape(-1,1) - betas.reshape(1,-1) * stats.reshape(-1,1) - alpha_)/gamma2_ * stats.reshape(-1,1)).sum(axis=0)\n",
    "plt.plot(betas, out)\n",
    "plt.show()\n",
    "\n",
    "beta_hat = beta(params, stats, normals, ahat=alpha_)\n",
    "out_hat = -2*(normals.reshape(-1,1) * (params.reshape(-1,1) - beta_hat * stats.reshape(-1,1) - alpha_)/gamma2_ * stats.reshape(-1,1)).sum(axis=0)\n",
    "\n",
    "\n",
    "betas[np.argmin(np.abs(out))], beta_hat, out_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# numerically check $\\frac{\\partial}{\\partial{}\\gamma^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alpha_ = 0.\n",
    "beta_ = eta2/(eta2+sig2)\n",
    "gamma2s = np.linspace(0.2, 2, 50)\n",
    "tmp = (params.reshape(-1,1) - beta_*stats.reshape(-1,1) - alpha_)**2 / gamma2s.reshape(1,-1)\n",
    "out = 1/gamma2s.reshape(-1,) * (normals.reshape(-1,1) * (1 - tmp)).sum(axis=0)\n",
    "\n",
    "gamma2_hat = gamma2(params, stats, normals, ahat=alpha_, bhat=beta_)\n",
    "tmp_ = (params.reshape(-1,1) - beta_*stats.reshape(-1,1) - alpha_)**2 / gamma2_hat\n",
    "out_hat = 1/gamma2_hat * (normals.reshape(-1,1) * (1 - tmp_)).sum(axis=0)\n",
    "\n",
    "\n",
    "plt.plot(gamma2s, out)\n",
    "plt.show()\n",
    "\n",
    "gamma2s[np.argmin(np.abs(out))], gamma2_hat, out_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gamma2hat = gamma2(params, stats, normals, 0, 0.4)\n",
    "ahat, bhat, gamma2hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.hist(out_snpe[:,1], bins=np.linspace(out_snpe[:,1].min(), out_snpe[:,1].max(), 10))\n",
    "plt.show()\n",
    "\n",
    "out_snpe[:,1].mean(), out_snpe[:,1].std()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
